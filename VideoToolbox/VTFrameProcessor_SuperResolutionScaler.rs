//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
#[cfg(feature = "objc2")]
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-foundation")]
use objc2_foundation::*;

use crate::*;

/// Configuration value you set to prioritize quality or performance.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationqualityprioritization?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationQualityPrioritization(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationQualityPrioritization {
    #[doc(alias = "VTSuperResolutionScalerConfigurationQualityPrioritizationNormal")]
    pub const Normal: Self = Self(1);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationQualityPrioritization {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationQualityPrioritization {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Available algorithm revisions.
///
/// A new enum case with a higher revision number is added when the processing algorithm is updated.
/// The ``VTSuperResolutionScalerConfiguration/defaultRevision`` property provides the default algorithm revision.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationrevision?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationRevision(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationRevision {
    #[doc(alias = "VTSuperResolutionScalerConfigurationRevision1")]
    pub const Revision1: Self = Self(1);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationRevision {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationRevision {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Available super-resolution processor input types.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationinputtype?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationInputType(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationInputType {
    #[doc(alias = "VTSuperResolutionScalerConfigurationInputTypeVideo")]
    pub const Video: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerConfigurationInputTypeImage")]
    pub const Image: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationInputType {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationInputType {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Available super-resolution processor model status types.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationmodelstatus?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationModelStatus(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationModelStatus {
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusDownloadRequired")]
    pub const DownloadRequired: Self = Self(0);
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusDownloading")]
    pub const Downloading: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusReady")]
    pub const Ready: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationModelStatus {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationModelStatus {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Indicates the order of input frames.
///
/// When submitting ``VTSuperResolutionScalerParameters`` to the processor, you need to provide one of these values based on
/// how the input frames are related to each other.
///
/// Use ``VTSuperResolutionScalerParametersSubmissionModeSequential`` to indicate that the current submission follows
/// presentation time order without jumps or skips, when compared to previous submissions. This value provides better
/// processor performance than other values.
///
/// Use ``VTSuperResolutionScalerParametersSubmissionModeRandom`` to indicate that the current submission has no relation
/// to the previous submission. Typically, this indicates a jump or skip in the frame sequence. The processor clears
/// internal caches when it receives this value in ``VTFrameProcessor/processWithParameters`` function call.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerparameterssubmissionmode?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerParametersSubmissionMode(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerParametersSubmissionMode {
    #[doc(alias = "VTSuperResolutionScalerParametersSubmissionModeRandom")]
    pub const Random: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerParametersSubmissionModeSequential")]
    pub const Sequential: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerParametersSubmissionMode {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerParametersSubmissionMode {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

#[cfg(feature = "objc2")]
extern_class!(
    /// Configuration that you use to set up the super-resolution processor.
    ///
    /// This configuration enables the super-resolution processor on a `VTFrameProcessor` session.
    ///
    /// > Important: The super-resolution processor may require ML models which the framework needs to download in order to
    /// operate. Before calling ``VTFrameProcessor/startSessionWithConfiguration:error:`` with an instance of this class,
    /// it is important that you verify that the necessary models are present by checking ``configurationModelStatus``.
    /// If models are not available, you can trigger model download using the ``downloadConfigurationModelWithCompletionHandler:``
    /// method. Best practice is to confirm availability of models and drive download with user awareness and interaction
    /// before engaging workflows that need this processor.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfiguration?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "objc2")]
    pub struct VTSuperResolutionScalerConfiguration;
);

#[cfg(feature = "objc2")]
unsafe impl Send for VTSuperResolutionScalerConfiguration {}

#[cfg(feature = "objc2")]
unsafe impl Sync for VTSuperResolutionScalerConfiguration {}

#[cfg(feature = "objc2")]
extern_conformance!(
    unsafe impl NSObjectProtocol for VTSuperResolutionScalerConfiguration {}
);

#[cfg(all(feature = "VTFrameProcessorConfiguration", feature = "objc2"))]
extern_conformance!(
    unsafe impl VTFrameProcessorConfiguration for VTSuperResolutionScalerConfiguration {}
);

#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfiguration {
    extern_methods!(
        /// Creates a new super-resolution scaler processor configuration.
        ///
        /// This processor increases resolution of an image or video.
        /// Returns `nil` if dimensions are out of range or revision is unsupported.
        ///
        /// - Parameters:
        /// - frameWidth: Width of source frame in pixels. With ``VTSuperResolutionScalerConfigurationInputTypeVideo``,
        /// maximum width is 1920 on macOS and 1440 on iOS. With ``VTSuperResolutionScalerConfigurationInputTypeImage``,
        /// maximum width is 1920.
        /// - frameHeight: Height of source frame in pixels. With ``VTSuperResolutionScalerConfigurationInputTypeVideo``,
        /// maximum height is 1080. With ``VTSuperResolutionScalerConfigurationInputTypeImage``, maximum height is 1920 on
        /// macOS and 1080 on iOS.
        /// - scaleFactor: Indicates the scale factor between input and output.
        /// - inputType: Indicates the type of input, either video or image.
        /// - usePrecomputedFlow: Boolean value to indicate that you provide optical flow; if false, this configuration
        /// computes the optical flow on the fly.
        /// - qualityPrioritization: A level you use to prioritize quality or performance; for more information about
        /// supported levels, see ``VTSuperResolutionScalerConfigurationQualityPrioritization``.
        /// - revision: The specific algorithm or configuration revision you use to perform the request.
        #[unsafe(method(initWithFrameWidth:frameHeight:scaleFactor:inputType:usePrecomputedFlow:qualityPrioritization:revision:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithFrameWidth_frameHeight_scaleFactor_inputType_usePrecomputedFlow_qualityPrioritization_revision(
            this: Allocated<Self>,
            frame_width: NSInteger,
            frame_height: NSInteger,
            scale_factor: NSInteger,
            input_type: VTSuperResolutionScalerConfigurationInputType,
            use_precomputed_flow: bool,
            quality_prioritization: VTSuperResolutionScalerConfigurationQualityPrioritization,
            revision: VTSuperResolutionScalerConfigurationRevision,
        ) -> Option<Retained<Self>>;

        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// Width of source frame in pixels.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(frameWidth))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameWidth(&self) -> NSInteger;

        /// Height of source frame in pixels.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(frameHeight))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameHeight(&self) -> NSInteger;

        /// Indicates the type of input.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(inputType))]
        #[unsafe(method_family = none)]
        pub unsafe fn inputType(&self) -> VTSuperResolutionScalerConfigurationInputType;

        /// Indicates that you provide optical flow.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(usesPrecomputedFlow))]
        #[unsafe(method_family = none)]
        pub unsafe fn usesPrecomputedFlow(&self) -> bool;

        /// Indicates the scale factor between input and output.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(scaleFactor))]
        #[unsafe(method_family = none)]
        pub unsafe fn scaleFactor(&self) -> NSInteger;

        /// A parameter to control quality and performance levels.
        ///
        /// For more information about supported levels, see ``VTSuperResolutionScalerConfigurationQualityPrioritization``.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(qualityPrioritization))]
        #[unsafe(method_family = none)]
        pub unsafe fn qualityPrioritization(
            &self,
        ) -> VTSuperResolutionScalerConfigurationQualityPrioritization;

        /// The specific algorithm or configuration revision you use to perform the request.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(revision))]
        #[unsafe(method_family = none)]
        pub unsafe fn revision(&self) -> VTSuperResolutionScalerConfigurationRevision;

        #[cfg(feature = "objc2-foundation")]
        /// Provides the collection of currently supported algorithms or configuration revisions for the class of configuration.
        ///
        /// A property you use to introspect at runtime which revisions are available for each configuration.
        #[unsafe(method(supportedRevisions))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportedRevisions() -> Retained<NSIndexSet>;

        /// Provides the default revision of a specific algorithm or configuration.
        #[unsafe(method(defaultRevision))]
        #[unsafe(method_family = none)]
        pub unsafe fn defaultRevision() -> VTSuperResolutionScalerConfigurationRevision;

        #[cfg(feature = "objc2-foundation")]
        /// Available supported pixel formats for source frames for current configuration.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(frameSupportedPixelFormats))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameSupportedPixelFormats(&self) -> Retained<NSArray<NSNumber>>;

        #[cfg(feature = "objc2-foundation")]
        /// Pixel buffer attributes dictionary that describes requirements for pixel buffers which represent source frames and reference frames.
        ///
        /// Use ``CVPixelBufferCreateResolvedAttributesDictionary`` to combine this dictionary with your pixel buffer attributes dictionary.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(sourcePixelBufferAttributes))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourcePixelBufferAttributes(
            &self,
        ) -> Retained<NSDictionary<NSString, AnyObject>>;

        #[cfg(feature = "objc2-foundation")]
        /// Pixel buffer attributes dictionary that describes requirements for pixel buffers which represent destination frames.
        ///
        /// Use ``CVPixelBufferCreateResolvedAttributesDictionary`` to combine this dictionary with your pixel buffer attributes dictionary.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(destinationPixelBufferAttributes))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationPixelBufferAttributes(
            &self,
        ) -> Retained<NSDictionary<NSString, AnyObject>>;

        /// Reports the download status of models that the system needs for the current configuration.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(configurationModelStatus))]
        #[unsafe(method_family = none)]
        pub unsafe fn configurationModelStatus(
            &self,
        ) -> VTSuperResolutionScalerConfigurationModelStatus;

        #[cfg(all(feature = "block2", feature = "objc2-foundation"))]
        /// Downloads models that the system needs for the current configuration.
        ///
        /// This method downloads model assets required for the current configuration in background. You should call this method
        /// if ``configurationModelStatus`` is ``VTSuperResolutionScalerConfigurationModelStatusDownloadRequired``. After this
        /// method is called, you can query ``configurationModelPercentageAvailable`` to determine progress of model asset
        /// download process. If the download fails, the completion handler is invoked with an `NSError`, and the
        /// ``configurationModelStatus`` goes back to ``VTSuperResolutionScalerConfigurationModelStatusDownloadRequired``. If
        /// the download succeeds, the completion handler is invoked with `nil` NSError.
        #[unsafe(method(downloadConfigurationModelWithCompletionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn downloadConfigurationModelWithCompletionHandler(
            &self,
            completion_handler: &block2::DynBlock<dyn Fn(*mut NSError)>,
        );

        /// Returns a floating point value between 0.0 and 1.0 indicating the percentage of required model assets that have been downloaded.
        ///
        /// This property is not atomic.
        ///
        /// # Safety
        ///
        /// This might not be thread-safe.
        #[unsafe(method(configurationModelPercentageAvailable))]
        #[unsafe(method_family = none)]
        pub unsafe fn configurationModelPercentageAvailable(&self) -> c_float;

        /// Reports whether the system supports this processor.
        #[unsafe(method(isSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isSupported() -> bool;

        #[cfg(feature = "objc2-foundation")]
        /// Reports the set of supported scale factors to use when initializing a super-resolution scaler configuration.
        #[unsafe(method(supportedScaleFactors))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportedScaleFactors() -> Retained<NSArray<NSNumber>>;
    );
}

#[cfg(feature = "objc2")]
extern_class!(
    /// An object that contains both input and output parameters that the super-resolution processor needs to run on a frame.
    ///
    /// Use this object in the `processWithParameters` call of the `VTFrameProcessor` class. The output parameter for this class is `destinationFrame`, where the processor returns the output frame (as `VTFrameProcessorFrame`) back to you once `processWithParameters` completes.
    ///
    /// `VTSuperResolutionScalerParameters` are frame-level parameters.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerparameters?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "objc2")]
    pub struct VTSuperResolutionScalerParameters;
);

#[cfg(feature = "objc2")]
extern_conformance!(
    unsafe impl NSObjectProtocol for VTSuperResolutionScalerParameters {}
);

#[cfg(all(feature = "VTFrameProcessorParameters", feature = "objc2"))]
extern_conformance!(
    unsafe impl VTFrameProcessorParameters for VTSuperResolutionScalerParameters {}
);

#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerParameters {
    extern_methods!(
        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Creates a new super-resolution scaler parameters instance.
        ///
        /// Returns `nil` if `sourceFrame` or `destinationFrame` is `nil`, or if `sourceFrame` and reference frames have different pixel formats.
        ///
        /// - Parameters:
        /// - sourceFrame: Current source frame; must be non `nil`.
        /// - previousFrame: The previous source frame in presentation time order. For the first frame you can set this to `nil`.
        /// - previousOutputFrame: The previous output frame in presentation time order. For the first frame you can set this to `nil`.
        /// - opticalFlow: Optional `VTFrameProcessorOpticalFlow` object that contains forward and backward optical flow between the `sourceFrame` and `previousFrame`. You only need this if optical flow is pre-computed.
        /// - submissionMode: Provides a hint to let the processor know whether you are submitting frames in presentation
        /// sequence. For more information about supported modes see ``VTSuperResolutionScalerParametersSubmissionMode``.
        /// - destinationFrame: User-allocated pixel buffer that receives the results.
        #[unsafe(method(initWithSourceFrame:previousFrame:previousOutputFrame:opticalFlow:submissionMode:destinationFrame:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithSourceFrame_previousFrame_previousOutputFrame_opticalFlow_submissionMode_destinationFrame(
            this: Allocated<Self>,
            source_frame: &VTFrameProcessorFrame,
            previous_frame: Option<&VTFrameProcessorFrame>,
            previous_output_frame: Option<&VTFrameProcessorFrame>,
            optical_flow: Option<&VTFrameProcessorOpticalFlow>,
            submission_mode: VTSuperResolutionScalerParametersSubmissionMode,
            destination_frame: &VTFrameProcessorFrame,
        ) -> Option<Retained<Self>>;

        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Current source frame, which must be non `nil`.
        #[unsafe(method(sourceFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFrame(&self) -> Retained<VTFrameProcessorFrame>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Previous source frame in presentation time order, which is `nil` for the first frame.
        #[unsafe(method(previousFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn previousFrame(&self) -> Option<Retained<VTFrameProcessorFrame>>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Previous output frame in presentation time order, which is `nil` for the first frame.
        #[unsafe(method(previousOutputFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn previousOutputFrame(&self) -> Option<Retained<VTFrameProcessorFrame>>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Optional object that contains forward and backward optical flow with the previous frame.
        ///
        /// You only need this if optical flow is pre-computed. For the first frame this is `nil`.
        #[unsafe(method(opticalFlow))]
        #[unsafe(method_family = none)]
        pub unsafe fn opticalFlow(&self) -> Option<Retained<VTFrameProcessorOpticalFlow>>;

        /// Ordering of the input frames in this submission relative to the previous submission.
        #[unsafe(method(submissionMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn submissionMode(&self) -> VTSuperResolutionScalerParametersSubmissionMode;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Destination frame that contains user-allocated pixel buffer that receives the results.
        #[unsafe(method(destinationFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationFrame(&self) -> Retained<VTFrameProcessorFrame>;
    );
}
