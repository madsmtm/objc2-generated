//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
#[cfg(feature = "objc2")]
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-foundation")]
use objc2_foundation::*;

use crate::*;

/// Quality prioritization levels to favor quality or performance.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationqualityprioritization?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationQualityPrioritization(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationQualityPrioritization {
    #[doc(alias = "VTSuperResolutionScalerConfigurationQualityPrioritizationNormal")]
    pub const Normal: Self = Self(1);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationQualityPrioritization {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationQualityPrioritization {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// List of existing algorithm revisions with the highest being the latest. Clients can read defaultRevision property to find the default revision.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationrevision?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationRevision(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationRevision {
    #[doc(alias = "VTSuperResolutionScalerConfigurationRevision1")]
    pub const Revision1: Self = Self(1);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationRevision {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationRevision {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// List of SuperResolution  input types.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationinputtype?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationInputType(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationInputType {
    #[doc(alias = "VTSuperResolutionScalerConfigurationInputTypeVideo")]
    pub const Video: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerConfigurationInputTypeImage")]
    pub const Image: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationInputType {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationInputType {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// List of SuperResolution  input types.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfigurationmodelstatus?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerConfigurationModelStatus(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfigurationModelStatus {
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusDownloadRequired")]
    pub const DownloadRequired: Self = Self(0);
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusDownloading")]
    pub const Downloading: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerConfigurationModelStatusReady")]
    pub const Ready: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerConfigurationModelStatus {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerConfigurationModelStatus {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Hint to let the processor know whether frames are being submitted in presenatation sequence, allowing performance optimizations based on previous processing requests
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerparameterssubmissionmode?language=objc)
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTSuperResolutionScalerParametersSubmissionMode(pub NSInteger);
#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerParametersSubmissionMode {
    #[doc(alias = "VTSuperResolutionScalerParametersSubmissionModeRandom")]
    pub const Random: Self = Self(1);
    #[doc(alias = "VTSuperResolutionScalerParametersSubmissionModeSequential")]
    pub const Sequential: Self = Self(2);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTSuperResolutionScalerParametersSubmissionMode {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTSuperResolutionScalerParametersSubmissionMode {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

#[cfg(feature = "objc2")]
extern_class!(
    /// Configuration that is used to set up the SuperResolution Processor.
    ///
    ///
    /// This configuration enables the SuperResolution on a VTFrameProcessing session.  IMPORTANT: The VTSuperResolutionScaler processor may require ML models which need to be downloaded by the framework in order to operate.  Before using calling startSessionWithConfiguration with a VTSuperResolutionScalerConfiguration, it is important that you verify that the necessary models are present by checking the configurationModelStatus on the configuration object.  If models are not available, model download can be triggered using the downloadConfigurationModelWithCompletionHandler method on the configuration object.  Best practice is to confirm availability of models and drive download with user awareness and interaction before engaging workflows where the processor is needed.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerconfiguration?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "objc2")]
    pub struct VTSuperResolutionScalerConfiguration;
);

#[cfg(feature = "objc2")]
unsafe impl Send for VTSuperResolutionScalerConfiguration {}

#[cfg(feature = "objc2")]
unsafe impl Sync for VTSuperResolutionScalerConfiguration {}

#[cfg(feature = "objc2")]
extern_conformance!(
    unsafe impl NSObjectProtocol for VTSuperResolutionScalerConfiguration {}
);

#[cfg(all(feature = "VTFrameProcessorConfiguration", feature = "objc2"))]
extern_conformance!(
    unsafe impl VTFrameProcessorConfiguration for VTSuperResolutionScalerConfiguration {}
);

#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerConfiguration {
    extern_methods!(
        /// Creates a new VTSuperResolutionScalerConfiguration with specified flow width and height.
        ///
        /// init will return nil if dimensions are out of range or revision is unsupported.
        ///
        /// Parameter `frameWidth`: Width of source frame in pixels. Maximum value is 8192 for macOS, and 4096 for iOS.
        ///
        /// Parameter `frameHeight`: Height of source frame in pixels. Maximum value is 4320 for macOS, and 2160 for iOS.
        ///
        /// Parameter `scaleFactor`: Indicates the scale factor between input and output.
        ///
        /// Parameter `inputType`: Indicates the type of input (video / image ).
        ///
        /// Parameter `usePrecomputedFlow`: Boolean value to indicate that Optical Flow will be provided by the user, if false this configuration will compute the optical flow on the fly.
        ///
        /// Parameter `qualityPrioritization`: Used to control quality and performance levels. See VTSuperResolutionScalerConfigurationQualityPrioritization for more info.
        ///
        /// Parameter `revision`: The specific algorithm or configuration revision that is to be used to perform the request.
        #[unsafe(method(initWithFrameWidth:frameHeight:scaleFactor:inputType:usePrecomputedFlow:qualityPrioritization:revision:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithFrameWidth_frameHeight_scaleFactor_inputType_usePrecomputedFlow_qualityPrioritization_revision(
            this: Allocated<Self>,
            frame_width: NSInteger,
            frame_height: NSInteger,
            scale_factor: NSInteger,
            input_type: VTSuperResolutionScalerConfigurationInputType,
            use_precomputed_flow: bool,
            quality_prioritization: VTSuperResolutionScalerConfigurationQualityPrioritization,
            revision: VTSuperResolutionScalerConfigurationRevision,
        ) -> Option<Retained<Self>>;

        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// Width of source frame in pixels.
        #[unsafe(method(frameWidth))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameWidth(&self) -> NSInteger;

        /// Height of source frame in pixels.
        #[unsafe(method(frameHeight))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameHeight(&self) -> NSInteger;

        /// Indicates the type of input.
        #[unsafe(method(inputType))]
        #[unsafe(method_family = none)]
        pub unsafe fn inputType(&self) -> VTSuperResolutionScalerConfigurationInputType;

        /// Indicates that caller will provide optical flow.
        #[unsafe(method(usesPrecomputedFlow))]
        #[unsafe(method_family = none)]
        pub unsafe fn usesPrecomputedFlow(&self) -> bool;

        /// Indicates the scale factor between input and output.
        #[unsafe(method(scaleFactor))]
        #[unsafe(method_family = none)]
        pub unsafe fn scaleFactor(&self) -> NSInteger;

        /// parameter used to control quality and performance levels. See VTSuperResolutionScalerConfigurationQualityPrioritization for more info.
        #[unsafe(method(qualityPrioritization))]
        #[unsafe(method_family = none)]
        pub unsafe fn qualityPrioritization(
            &self,
        ) -> VTSuperResolutionScalerConfigurationQualityPrioritization;

        /// The specific algorithm or configuration revision that is to be used to perform the request.
        #[unsafe(method(revision))]
        #[unsafe(method_family = none)]
        pub unsafe fn revision(&self) -> VTSuperResolutionScalerConfigurationRevision;

        #[cfg(feature = "objc2-foundation")]
        /// Provides the collection of currently-supported algorithm or configuration revisions for the class of configuration.
        ///
        /// This property allows clients to introspect at runtime what revisions are available for each configuration.
        #[unsafe(method(supportedRevisions))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportedRevisions() -> Retained<NSIndexSet>;

        /// Provides the default revision of a particular algorithm or configuration.
        #[unsafe(method(defaultRevision))]
        #[unsafe(method_family = none)]
        pub unsafe fn defaultRevision() -> VTSuperResolutionScalerConfigurationRevision;

        #[cfg(feature = "objc2-foundation")]
        /// list of source frame supported pixel formats for current configuration
        #[unsafe(method(frameSupportedPixelFormats))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameSupportedPixelFormats(&self) -> Retained<NSArray<NSNumber>>;

        #[cfg(feature = "objc2-foundation")]
        /// returns a pixelBufferAttributes dictionary describing requirements for pixelBuffers used as source frames and reference frames.
        #[unsafe(method(sourcePixelBufferAttributes))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourcePixelBufferAttributes(
            &self,
        ) -> Retained<NSDictionary<NSString, AnyObject>>;

        #[cfg(feature = "objc2-foundation")]
        /// returns a pixelBufferAttributes dictionary describing requirements for pixelBuffers used as destination frames.
        #[unsafe(method(destinationPixelBufferAttributes))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationPixelBufferAttributes(
            &self,
        ) -> Retained<NSDictionary<NSString, AnyObject>>;

        /// reports the download status of models required to use VTSuperResolutionScaler for the current configuration.
        #[unsafe(method(configurationModelStatus))]
        #[unsafe(method_family = none)]
        pub unsafe fn configurationModelStatus(
            &self,
        ) -> VTSuperResolutionScalerConfigurationModelStatus;

        #[cfg(all(feature = "block2", feature = "objc2-foundation"))]
        /// This interface requests that models associated with the VTSuperResolutionScalerConfiguration be downloaded.
        ///
        ///
        /// This interface can be used to download model assets required for the current VTSuperResolutionScalerConfiguration if the state is currently VTSuperResolutionScalerConfigurationModelStatusDownloadRequired.  The processorModelStatus class property can be queried to see if models are all already present.  If a download has been initiated, processorModelPercentageAvailable can be queried to determine what percentage of the model models are avialable.
        /// If the download fails, the completion handler will return an NSError, and the status will go back to VTSuperResolutionScalerConfigurationModelStatusDownloadRequired.  If the download succeeds, the NSError return value will be nil.
        #[unsafe(method(downloadConfigurationModelWithCompletionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn downloadConfigurationModelWithCompletionHandler(
            &self,
            completion_handler: &block2::DynBlock<dyn Fn(*mut NSError)>,
        );

        /// Returns a floating point value between 0.0 and 1.0 indicating the percentage of required model assets that have been downloaded.
        #[unsafe(method(configurationModelPercentageAvailable))]
        #[unsafe(method_family = none)]
        pub unsafe fn configurationModelPercentageAvailable(&self) -> c_float;

        /// reports whether this processor is supported
        #[unsafe(method(isSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isSupported() -> bool;

        #[cfg(feature = "objc2-foundation")]
        /// reports the set of supported scale factors that can be used when initializing a VTSuperResolutionScalerConfiguration.
        #[unsafe(method(supportedScaleFactors))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportedScaleFactors() -> Retained<NSArray<NSNumber>>;
    );
}

#[cfg(feature = "objc2")]
extern_class!(
    /// VTSuperResolutionScalerParameters object contains both input and output parameters needed to run the SuperResolution processor on a frame. This object is used in the processWithParameters call of VTFrameProcessor class. The output parameter for this class is destinationFrame where the output frame is returned (as VTFrameProcessorFrame) back to the caller function once the processWithParameters completes.
    ///
    ///
    /// VTSuperResolutionScalerParameters are frame level parameters.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtsuperresolutionscalerparameters?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "objc2")]
    pub struct VTSuperResolutionScalerParameters;
);

#[cfg(feature = "objc2")]
extern_conformance!(
    unsafe impl NSObjectProtocol for VTSuperResolutionScalerParameters {}
);

#[cfg(all(feature = "VTFrameProcessorParameters", feature = "objc2"))]
extern_conformance!(
    unsafe impl VTFrameProcessorParameters for VTSuperResolutionScalerParameters {}
);

#[cfg(feature = "objc2")]
impl VTSuperResolutionScalerParameters {
    extern_methods!(
        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Creates a new VTSuperResolutionScalerParameters .
        ///
        /// init will return nil if sourceFrame or destinationFrame is nil, sourceFrame and reference frames  are different pixelFormats.
        ///
        /// Parameter `sourceFrame`: Current source frame. Must be non nil.
        ///
        /// Parameter `previousFrame`: The Previous source frame in presentation time order. For the first frame this can be set to nil.
        ///
        /// Parameter `previousOutputFrame`: The Previous output frame in presentation time order. For the first frame this can be set to nil.
        ///
        /// Parameter `opticalFlow`: Optional VTFrameProcessorOpticalFlow object that contains forward and backward optical flow between sourceFrame and previousFrame frame. Only needed if optical flow is pre-computed.
        ///
        /// Parameter `submissionMode`: Set to VTSuperResolutionScalerParametersSubmissionModeSequential to indicate that current submission follow presentation time order without jump or skip when compared to previous submission. VTSuperResolutionScalerParametersSubmissionModeSequential will yield better performance. Set to VTSuperResolutionScalerParametersSubmissionModeRandom to indicate a skip or a jump in frame sequence.
        ///
        /// Parameter `destinationFrame`: User allocated pixel buffer that will receive the results.
        #[unsafe(method(initWithSourceFrame:previousFrame:previousOutputFrame:opticalFlow:submissionMode:destinationFrame:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithSourceFrame_previousFrame_previousOutputFrame_opticalFlow_submissionMode_destinationFrame(
            this: Allocated<Self>,
            source_frame: &VTFrameProcessorFrame,
            previous_frame: Option<&VTFrameProcessorFrame>,
            previous_output_frame: Option<&VTFrameProcessorFrame>,
            optical_flow: Option<&VTFrameProcessorOpticalFlow>,
            submission_mode: VTSuperResolutionScalerParametersSubmissionMode,
            destination_frame: &VTFrameProcessorFrame,
        ) -> Option<Retained<Self>>;

        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// sourceFrame Current source frame. Must be non nil
        #[unsafe(method(sourceFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFrame(&self) -> Retained<VTFrameProcessorFrame>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Previous source frame in presentation time order. For the first frame this will be nil.
        #[unsafe(method(previousFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn previousFrame(&self) -> Option<Retained<VTFrameProcessorFrame>>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Previous output frame in presentation time order. For the first frame this will be nil.
        #[unsafe(method(previousOutputFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn previousOutputFrame(&self) -> Option<Retained<VTFrameProcessorFrame>>;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// Optional VTFrameProcessorOpticalFlow object that contains forward and backward optical flow with the previous frame. Only needed if optical flow is pre-computed. For the first frame this will be nil.
        #[unsafe(method(opticalFlow))]
        #[unsafe(method_family = none)]
        pub unsafe fn opticalFlow(&self) -> Option<Retained<VTFrameProcessorOpticalFlow>>;

        /// A VTSuperResolutionScalerSubmissionMode value describing the processing request in this Parameters object .
        #[unsafe(method(submissionMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn submissionMode(&self) -> VTSuperResolutionScalerParametersSubmissionMode;

        #[cfg(feature = "VTFrameProcessorFrame")]
        /// VTFrameProcessorFrame that contains user allocated pixel buffer that will receive the results.
        #[unsafe(method(destinationFrame))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationFrame(&self) -> Retained<VTFrameProcessorFrame>;
    );
}
