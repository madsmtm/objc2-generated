//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::cell::UnsafeCell;
use core::ffi::*;
use core::marker::{PhantomData, PhantomPinned};
use core::ptr::NonNull;
#[cfg(feature = "objc2")]
use objc2::__framework_prelude::*;
use objc2_core_foundation::*;
#[cfg(feature = "objc2-core-video")]
use objc2_core_video::*;

use crate::*;

/// Directives for the motion estimation session and the motion estimation processor passed from the client into
/// motionEstimationFrameFlags parameter of VTMotionEstimationSessionEstimateMotionVectors.
///
///
/// A hint to the motion estimation session that the client will reuse the currentBuffer as referenceBuffer in the next call
/// to VTMotionEstimationSessionEstimateMotionVectors. Using this flag allows the motion estimation processor to make some
/// optimizations.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtmotionestimationframeflags?language=objc)
// NS_OPTIONS
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTMotionEstimationFrameFlags(pub u32);
bitflags::bitflags! {
    impl VTMotionEstimationFrameFlags: u32 {
        #[doc(alias = "kVTMotionEstimationFrameFlags_CurrentBufferWillBeNextReferenceBuffer")]
        const CurrentBufferWillBeNextReferenceBuffer = 1<<0;
    }
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTMotionEstimationFrameFlags {
    const ENCODING: Encoding = u32::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTMotionEstimationFrameFlags {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Directives for the client passed into the VTMotionEstimationOutputHandler from the
/// motion estimation session or the motion estimation processor.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtmotionestimationinfoflags?language=objc)
// NS_OPTIONS
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct VTMotionEstimationInfoFlags(pub u32);
bitflags::bitflags! {
    impl VTMotionEstimationInfoFlags: u32 {
        #[doc(alias = "kVTMotionEstimationInfoFlags_Reserved0")]
        const Reserved0 = 1<<0;
    }
}

#[cfg(feature = "objc2")]
unsafe impl Encode for VTMotionEstimationInfoFlags {
    const ENCODING: Encoding = u32::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for VTMotionEstimationInfoFlags {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// A reference to a Video Toolbox Motion Estimation Session.
///
/// A motion estimation session supports two CVPixelBuffers of the same size and type,
/// and returns motion vectors in the form of a CVPixelBuffer. The session is a
/// reference-counted CF object. To create a motion estimation session, call
/// VTMotionEstimationSessionCreate; then you can optionally configure the session using
/// VTSessionSetProperty; then to create motion estimations, call
/// VTMotionEstimationSessionCreateMotionEstimation. When you are done with the session,
/// you should call VTMotionEstimationSessionInvalidate to tear it down and CFRelease to
/// release your object reference.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtmotionestimationsession?language=objc)
#[repr(C)]
pub struct VTMotionEstimationSession {
    inner: [u8; 0],
    _p: UnsafeCell<PhantomData<(*const UnsafeCell<()>, PhantomPinned)>>,
}

cf_type!(
    unsafe impl VTMotionEstimationSession {}
);
#[cfg(feature = "objc2")]
cf_objc2_type!(
    unsafe impl RefEncode<"OpaqueVTMotionEstimationSession"> for VTMotionEstimationSession {}
);

unsafe impl ConcreteType for VTMotionEstimationSession {
    /// Get the CFTypeID for a VTMotionEstimationSession.
    ///
    /// Get the CFTypeID for a VTMotionEstimationSession.
    #[doc(alias = "VTMotionEstimationSessionGetTypeID")]
    #[inline]
    fn type_id() -> CFTypeID {
        extern "C-unwind" {
            fn VTMotionEstimationSessionGetTypeID() -> CFTypeID;
        }
        unsafe { VTMotionEstimationSessionGetTypeID() }
    }
}

impl VTMotionEstimationSession {
    /// Creates a session for creating CVPixelBuffer of motion vectors from two CVPixelBuffers.
    ///
    /// The function creates a session for transferring images between CVPixelBuffers.
    ///
    /// Parameter `allocator`: An allocator for the session.  Pass NULL to use the default allocator.
    ///
    /// Parameter `motionVectorProcessorSelectionOptions`: Available creation Options:
    /// kVTMotionEstimationSessionCreationOption_MotionVectorSize CFNumber 16 or 4.
    /// The size of the block of pixels 16x16 or 4x4. Default is 16x16.
    /// kVTMotionEstimationSessionCreationOption_UseMultiPassSearch can be supplied with kCFBooleanTrue to provide higher quality motion estimation.
    /// True motion achieves higher quality by running the motion estimator in multiple passes. The default is kCFBooleanFalse.
    /// kVTMotionEstimationSessionCreationOption_Label CFString
    /// This option assigns a label for logging and resource tracking.
    ///
    /// Parameter `width`: The width of frames, in pixels.
    ///
    /// Parameter `height`: The height of frames in pixels.
    ///
    /// Parameter `motionEstimationSessionOut`: Points to a variable to receive the new pixel transfer session.
    #[doc(alias = "VTMotionEstimationSessionCreate")]
    #[inline]
    pub unsafe fn create(
        allocator: Option<&CFAllocator>,
        motion_vector_processor_selection_options: Option<&CFDictionary>,
        width: u32,
        height: u32,
        motion_estimation_session_out: NonNull<*mut VTMotionEstimationSession>,
    ) -> OSStatus {
        extern "C-unwind" {
            fn VTMotionEstimationSessionCreate(
                allocator: Option<&CFAllocator>,
                motion_vector_processor_selection_options: Option<&CFDictionary>,
                width: u32,
                height: u32,
                motion_estimation_session_out: NonNull<*mut VTMotionEstimationSession>,
            ) -> OSStatus;
        }
        unsafe {
            VTMotionEstimationSessionCreate(
                allocator,
                motion_vector_processor_selection_options,
                width,
                height,
                motion_estimation_session_out,
            )
        }
    }

    /// Copy the expected attributes for source pixel buffers
    ///
    /// The function provides a cf dictionary of attributes that must be released. This is
    /// routine is for clients to query the VTMotionEstimationSession for the native source
    /// attributes. If a client provides an input  CVPixelBuffer that is not compatible with the
    /// the attributes returned by this function, VTMotionEstimationSession will automatically
    /// convert the input pixel buffer into a compatible pixel buffer for processing.
    ///
    /// Parameter `session`: The motion estimation session.
    ///
    /// Parameter `attributesOut`: Points to a variable to receive the attributes dictionary.
    #[doc(alias = "VTMotionEstimationSessionCopySourcePixelBufferAttributes")]
    #[inline]
    pub unsafe fn copy_source_pixel_buffer_attributes(
        self: &VTMotionEstimationSession,
        attributes_out: NonNull<*const CFDictionary>,
    ) -> OSStatus {
        extern "C-unwind" {
            fn VTMotionEstimationSessionCopySourcePixelBufferAttributes(
                motion_estimation_session: &VTMotionEstimationSession,
                attributes_out: NonNull<*const CFDictionary>,
            ) -> OSStatus;
        }
        unsafe { VTMotionEstimationSessionCopySourcePixelBufferAttributes(self, attributes_out) }
    }

    /// Tears down a motion estimation session.
    ///
    /// When you are done with a motion estimation session you created, call VTMotionEstimationSessionInvalidate
    /// to tear it down and then CFRelease to release your object reference. When a motion estimation session's
    /// retain count reaches zero, it is automatically invalidated, but since sessions may be retained by multiple
    /// parties, it can be hard to predict when this will happen. Calling VTMotionEstimationSessionInvalidate
    /// ensures a deterministic, orderly teardown.
    #[doc(alias = "VTMotionEstimationSessionInvalidate")]
    #[inline]
    pub unsafe fn invalidate(self: &VTMotionEstimationSession) {
        extern "C-unwind" {
            fn VTMotionEstimationSessionInvalidate(session: &VTMotionEstimationSession);
        }
        unsafe { VTMotionEstimationSessionInvalidate(self) }
    }
}

/// Block invoked when frame processing is complete.
///
/// When the client requests a motion estimation, the client passes in a callback block to be called
/// for that result of that request. If the VTMotionEstimationSessionCreateMotionEstimation call returns
/// an error, the block will not be called.
///
/// Parameter `status`: noErr if processing request was successful; an error code if motion estimation was not successful.
///
/// Parameter `infoFlags`: A bit field containing information about the processing operation.
///
/// Parameter `additionalInfo`: Additional processing information about the processing operation that can not fit in infoFlags.
/// Currently, this is expected to be NULL.
///
/// Parameter `motionVectorPixelBuffer`: A CVPixelBuffer containing the motion vector information, if processing request was successful;
/// otherwise, NULL.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/videotoolbox/vtmotionestimationoutputhandler?language=objc)
#[cfg(all(feature = "block2", feature = "objc2-core-video"))]
pub type VTMotionEstimationOutputHandler = *mut block2::DynBlock<
    dyn Fn(OSStatus, VTMotionEstimationInfoFlags, *const CFDictionary, *mut CVPixelBuffer),
>;

impl VTMotionEstimationSession {
    /// Given two CVPixelBuffers, creates a CVPixelBuffer representing the motion estimate.
    ///
    /// The motion estimation session will compare the reference frame to the current frame, and
    /// generate motion vectors in the form of a CVPixelBuffer.
    ///
    /// Parameter `session`: The motion estimation session.
    ///
    /// Parameter `referenceImage`: The reference image.
    ///
    /// Parameter `currentImage`: The current image.
    ///
    /// Parameter `motionEstimationFrameFlags`: A bit field with per-frame options.  See kVTMotionEstimationFrameFlags_CurrentBufferWillBeNextReferenceBuffer.
    ///
    /// Parameter `additionalFrameOptions`: A way to pass additional information that will not fit in motionEstimationFrameFlags; currently expected to be NULL.
    ///
    /// Parameter `outputHandler`: The block to be called when the processing request is completed.  If the
    /// VTMotionEstimationSessionCreateMotionEstimation call returns an error, the block will not
    /// be called.
    ///
    /// Returns: If the call was successful, noErr; otherwise an error code, such as kVTMotionEstimationNotSupportedErr.
    #[doc(alias = "VTMotionEstimationSessionEstimateMotionVectors")]
    #[cfg(all(feature = "block2", feature = "objc2-core-video"))]
    #[inline]
    pub unsafe fn estimate_motion_vectors(
        self: &VTMotionEstimationSession,
        reference_image: &CVPixelBuffer,
        current_image: &CVPixelBuffer,
        motion_estimation_frame_flags: VTMotionEstimationFrameFlags,
        additional_frame_options: Option<&CFDictionary>,
        output_handler: VTMotionEstimationOutputHandler,
    ) -> OSStatus {
        extern "C-unwind" {
            fn VTMotionEstimationSessionEstimateMotionVectors(
                session: &VTMotionEstimationSession,
                reference_image: &CVPixelBuffer,
                current_image: &CVPixelBuffer,
                motion_estimation_frame_flags: VTMotionEstimationFrameFlags,
                additional_frame_options: Option<&CFDictionary>,
                output_handler: VTMotionEstimationOutputHandler,
            ) -> OSStatus;
        }
        unsafe {
            VTMotionEstimationSessionEstimateMotionVectors(
                self,
                reference_image,
                current_image,
                motion_estimation_frame_flags,
                additional_frame_options,
                output_handler,
            )
        }
    }

    /// Directs the motion estimation session to emit all pending frames and waits for completion.
    ///
    /// Directs the motion estimation session to emit all pending frames, then waits for all outstanding
    /// requests to complete, then returns.
    #[doc(alias = "VTMotionEstimationSessionCompleteFrames")]
    #[inline]
    pub unsafe fn complete_frames(self: &VTMotionEstimationSession) -> OSStatus {
        extern "C-unwind" {
            fn VTMotionEstimationSessionCompleteFrames(
                session: &VTMotionEstimationSession,
            ) -> OSStatus;
        }
        unsafe { VTMotionEstimationSessionCompleteFrames(self) }
    }
}

extern "C-unwind" {
    #[deprecated = "renamed to `VTMotionEstimationSession::create`"]
    pub fn VTMotionEstimationSessionCreate(
        allocator: Option<&CFAllocator>,
        motion_vector_processor_selection_options: Option<&CFDictionary>,
        width: u32,
        height: u32,
        motion_estimation_session_out: NonNull<*mut VTMotionEstimationSession>,
    ) -> OSStatus;
}

extern "C-unwind" {
    #[deprecated = "renamed to `VTMotionEstimationSession::copy_source_pixel_buffer_attributes`"]
    pub fn VTMotionEstimationSessionCopySourcePixelBufferAttributes(
        motion_estimation_session: &VTMotionEstimationSession,
        attributes_out: NonNull<*const CFDictionary>,
    ) -> OSStatus;
}

extern "C-unwind" {
    #[deprecated = "renamed to `VTMotionEstimationSession::invalidate`"]
    pub fn VTMotionEstimationSessionInvalidate(session: &VTMotionEstimationSession);
}

extern "C-unwind" {
    #[cfg(all(feature = "block2", feature = "objc2-core-video"))]
    #[deprecated = "renamed to `VTMotionEstimationSession::estimate_motion_vectors`"]
    pub fn VTMotionEstimationSessionEstimateMotionVectors(
        session: &VTMotionEstimationSession,
        reference_image: &CVPixelBuffer,
        current_image: &CVPixelBuffer,
        motion_estimation_frame_flags: VTMotionEstimationFrameFlags,
        additional_frame_options: Option<&CFDictionary>,
        output_handler: VTMotionEstimationOutputHandler,
    ) -> OSStatus;
}

extern "C-unwind" {
    #[deprecated = "renamed to `VTMotionEstimationSession::complete_frames`"]
    pub fn VTMotionEstimationSessionCompleteFrames(session: &VTMotionEstimationSession)
        -> OSStatus;
}
