//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// The Cocoa interface to speech recognition in macOS.
    ///
    /// ## Overview
    ///
    /// [`NSSpeechRecognizer`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer) provides a “command and control” style of voice recognition system, where the command phrases must be defined prior to listening, in contrast to a dictation system where the recognized text is unconstrained. Through an [`NSSpeechRecognizer`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer) instance, Cocoa apps can use the speech recognition engine built into macOS to recognize spoken commands. With speech recognition, users can accomplish complex tasks with spoken commands—for example, “Move pawn B2 to B4” and “Take back move.”
    ///
    /// The [`NSSpeechRecognizer`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer) class has a property that lets you specify which spoken words should be recognized as commands ([`commands`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer/commands)) and methods that let you start and stop listening ([`startListening`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer/startlistening()) and [`stopListening`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer/stoplistening())). When the speech recognition facility recognizes one of the designated commands, [`NSSpeechRecognizer`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer) invokes the delegation method [`speechRecognizer:didRecognizeCommand:`](https://developer.apple.com/documentation/appkit/nsspeechrecognizerdelegate/speechrecognizer(_:didrecognizecommand:)), allowing the delegate to perform the command.
    ///
    /// Speech recognition is just one of the macOS speech technologies. The speech synthesis technology allows applications to “pronounce” written text in U.S. English and over 25 other languages, with a number of different voices and dialects for each language  ([`NSSpeechSynthesizer`](https://developer.apple.com/documentation/appkit/nsspeechsynthesizer) is the Cocoa interface to this technology). Both speech technologies provide benefits for all users, and are particularly useful to those users who have difficulties seeing the screen or using the mouse and keyboard. By incorporating speech into your application, you can provide a concurrent mode of interaction for your users: In macOS, your software can accept input and provide output without requiring users to change their working context.
    ///
    ///
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct NSSpeechRecognizer;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for NSSpeechRecognizer {}
);

impl NSSpeechRecognizer {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub fn init(this: Allocated<Self>) -> Option<Retained<Self>>;

        #[unsafe(method(startListening))]
        #[unsafe(method_family = none)]
        pub fn startListening(&self);

        #[unsafe(method(stopListening))]
        #[unsafe(method_family = none)]
        pub fn stopListening(&self);

        #[unsafe(method(delegate))]
        #[unsafe(method_family = none)]
        pub fn delegate(
            &self,
            mtm: MainThreadMarker,
        ) -> Option<Retained<ProtocolObject<dyn NSSpeechRecognizerDelegate>>>;

        /// Setter for [`delegate`][Self::delegate].
        ///
        /// This is a [weak property][objc2::topics::weak_property].
        #[unsafe(method(setDelegate:))]
        #[unsafe(method_family = none)]
        pub fn setDelegate(
            &self,
            delegate: Option<&ProtocolObject<dyn NSSpeechRecognizerDelegate>>,
        );

        #[unsafe(method(commands))]
        #[unsafe(method_family = none)]
        pub fn commands(&self) -> Option<Retained<NSArray<NSString>>>;

        /// Setter for [`commands`][Self::commands].
        ///
        /// This is [copied][objc2_foundation::NSCopying::copy] when set.
        #[unsafe(method(setCommands:))]
        #[unsafe(method_family = none)]
        pub fn setCommands(&self, commands: Option<&NSArray<NSString>>);

        #[unsafe(method(displayedCommandsTitle))]
        #[unsafe(method_family = none)]
        pub fn displayedCommandsTitle(&self) -> Option<Retained<NSString>>;

        /// Setter for [`displayedCommandsTitle`][Self::displayedCommandsTitle].
        ///
        /// This is [copied][objc2_foundation::NSCopying::copy] when set.
        #[unsafe(method(setDisplayedCommandsTitle:))]
        #[unsafe(method_family = none)]
        pub fn setDisplayedCommandsTitle(&self, displayed_commands_title: Option<&NSString>);

        #[unsafe(method(listensInForegroundOnly))]
        #[unsafe(method_family = none)]
        pub fn listensInForegroundOnly(&self) -> bool;

        /// Setter for [`listensInForegroundOnly`][Self::listensInForegroundOnly].
        #[unsafe(method(setListensInForegroundOnly:))]
        #[unsafe(method_family = none)]
        pub fn setListensInForegroundOnly(&self, listens_in_foreground_only: bool);

        #[unsafe(method(blocksOtherRecognizers))]
        #[unsafe(method_family = none)]
        pub fn blocksOtherRecognizers(&self) -> bool;

        /// Setter for [`blocksOtherRecognizers`][Self::blocksOtherRecognizers].
        #[unsafe(method(setBlocksOtherRecognizers:))]
        #[unsafe(method_family = none)]
        pub fn setBlocksOtherRecognizers(&self, blocks_other_recognizers: bool);
    );
}

/// Methods declared on superclass `NSObject`.
impl NSSpeechRecognizer {
    extern_methods!(
        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub fn new() -> Retained<Self>;
    );
}

impl DefaultRetained for NSSpeechRecognizer {
    #[inline]
    fn default_retained() -> Retained<Self> {
        Self::new()
    }
}

extern_protocol!(
    /// A set of optional methods implemented by delegates of [`NSSpeechRecognizer`](https://developer.apple.com/documentation/appkit/nsspeechrecognizer) objects.
    pub unsafe trait NSSpeechRecognizerDelegate: NSObjectProtocol + MainThreadOnly {
        #[optional]
        #[unsafe(method(speechRecognizer:didRecognizeCommand:))]
        #[unsafe(method_family = none)]
        fn speechRecognizer_didRecognizeCommand(
            &self,
            sender: &NSSpeechRecognizer,
            command: &NSString,
        );
    }
);
