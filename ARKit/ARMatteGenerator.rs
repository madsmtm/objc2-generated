//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ptr::NonNull;
#[cfg(feature = "objc2")]
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-metal")]
use objc2_metal::*;

use crate::*;

/// A resolution for a matte texture.
///
/// ## Overview
///
/// You generate a matte texture every frame, specifying whether its resolution is the full size or half of the camera image.
///
///
/// The resolution at which the matte is to be generated.
///
/// The matte generated per frame can be full resolution of the captured camera image or half resolution. The caller chooses one of the options from ARMatteResolution during initialization.
// NS_ENUM
#[cfg(feature = "objc2")]
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, Default)]
pub struct ARMatteResolution(pub NSInteger);
#[cfg(feature = "objc2")]
impl ARMatteResolution {
    /// An option that specifies the full camera image resolution.
    #[doc(alias = "ARMatteResolutionFull")]
    pub const Full: Self = Self(0);
    /// An option that specifies half of the camera image resolution.
    #[doc(alias = "ARMatteResolutionHalf")]
    pub const Half: Self = Self(1);
}

#[cfg(feature = "objc2")]
unsafe impl Encode for ARMatteResolution {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

#[cfg(feature = "objc2")]
unsafe impl RefEncode for ARMatteResolution {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

#[cfg(feature = "objc2")]
extern_class!(
    /// An object that creates matte textures you use to occlude your app’s virtual content with people, that ARKit recognizes in the camera feed.
    ///
    /// ## Overview
    ///
    /// Use this class when you want full control over occluding your app’s virtual content, based on people ARKit recognizes in the camera feed.
    ///
    /// <div class="warning">
    ///
    /// ### Note
    ///  Apps using one of the standard renderers  (`ARView` or [`ARSCNView`](https://developer.apple.com/documentation/arkit/arscnview)) don’t need this class to effect people occlusion. See [`frameSemantics`](https://developer.apple.com/documentation/arkit/arconfiguration/framesemantics-swift.property) for more information.
    ///
    ///
    ///
    /// </div>
    /// To assist your custom renderer with people occlusion, matte generator processes alpha and depth information in a frame’s [`segmentationBuffer`](https://developer.apple.com/documentation/arkit/arframe/segmentationbuffer) and [`estimatedDepthData`](https://developer.apple.com/documentation/arkit/arframe/estimateddepthdata) to provide you with matte and depth textures. You use these textures to layer people on top of your app’s virtual content.
    ///
    ///
    /// An object designed to generate either full resolution or half resolution matte given the ARFrame.
    ///
    /// The caller initializes the object once and calls the alpha matte generation API for every ARFrame with the captured image and segmentation stencil.
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "objc2")]
    pub struct ARMatteGenerator;
);

#[cfg(feature = "objc2")]
extern_conformance!(
    unsafe impl NSObjectProtocol for ARMatteGenerator {}
);

#[cfg(feature = "objc2")]
impl ARMatteGenerator {
    extern_methods!(
        #[cfg(feature = "objc2-metal")]
        /// Initializes an instance of ARMatteGenerator.
        ///
        ///
        /// For efficient creation of alpha mattes in real time it is recommended to instantiate this object only once and to generate an alpha matte for every incoming frame.
        ///
        /// See: ARFrame
        ///
        /// See: -[ARMatteGenerator generateMatteFromFrame:commandBuffer:]
        ///
        /// Parameter `device`: The device the filter will run on.
        ///
        /// Parameter `matteResolution`: The resolution at which the matte is to be generated. Set using one of the values from 'ARMatteResolution'.
        ///
        /// See: ARMatteResolution
        ///
        /// Returns: Instance of ARMatteGenerator.
        #[unsafe(method(initWithDevice:matteResolution:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice_matteResolution(
            this: Allocated<Self>,
            device: &ProtocolObject<dyn MTLDevice>,
            matte_resolution: ARMatteResolution,
        ) -> Retained<Self>;

        #[cfg(all(feature = "ARFrame", feature = "objc2-metal"))]
        /// Generates alpha matte at either full resolution or half the resolution of the captured image.
        ///
        ///
        /// Parameter `frame`: Current ARFrame containing camera image and segmentation stencil. The caller is to ensure that a valid segmentation buffer is present.
        ///
        /// Parameter `commandBuffer`: Metal command buffer for encoding matting related operations. The command buffer is committed by the caller externally.
        ///
        /// Returns: Alpha matte MTLTexture for the given ARFrame at full resolution or half resolution as chosen by the  caller during initialization.
        #[unsafe(method(generateMatteFromFrame:commandBuffer:))]
        #[unsafe(method_family = none)]
        pub unsafe fn generateMatteFromFrame_commandBuffer(
            &self,
            frame: &ARFrame,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
        ) -> Retained<ProtocolObject<dyn MTLTexture>>;

        #[cfg(all(feature = "ARFrame", feature = "objc2-metal"))]
        /// Generates dilated depth at the resolution of the segmentation stencil.
        ///
        /// The caller can use depth information when compositing a virtual object with the captured scene. This API returns the dilated linear depth to the caller. The reprojection of this depth to the caller's scene space is carried out externally.
        ///
        /// Parameter `frame`: Current ARFrame containing camera image and estimated depth buffer. The caller is to ensure that a valid depth buffer is present.
        ///
        /// Parameter `commandBuffer`: Metal command buffer for encoding depth dilation operations. The command buffer is committed by the caller externally.
        ///
        /// Returns: Dilated depth MTLTexture for the given ARFrame at the segmentation stencil resolution. The texture consists of a single channel and is of type float16.
        #[unsafe(method(generateDilatedDepthFromFrame:commandBuffer:))]
        #[unsafe(method_family = none)]
        pub unsafe fn generateDilatedDepthFromFrame_commandBuffer(
            &self,
            frame: &ARFrame,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
        ) -> Retained<ProtocolObject<dyn MTLTexture>>;

        /// Unavailable
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}
