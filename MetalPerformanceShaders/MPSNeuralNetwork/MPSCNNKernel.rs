//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
use objc2_foundation::*;
use objc2_metal::*;

use crate::*;

extern_class!(
    /// Dependencies: This depends on Metal.framework
    ///
    /// Describes a convolution neural network kernel.
    ///
    /// A MPSCNNKernel consumes one MPSImage and produces one MPSImage.
    ///
    /// The region overwritten in the destination MPSImage is described
    /// by the clipRect.  The top left corner of the region consumed (ignoring
    /// adjustments for filter size -- e.g. convolution filter size) is given
    /// by the offset. The size of the region consumed is a function of the
    /// clipRect size and any subsampling caused by pixel strides at work,
    /// e.g. MPSCNNPooling.strideInPixelsX/Y.  Where the offset + clipRect
    /// would cause a {x,y} pixel address not in the image to be read, the
    /// edgeMode is used to determine what value to read there.
    ///
    /// The Z/depth component of the offset, clipRect.origin and clipRect.size
    /// indexes which images to use. If the MPSImage contains only a single image
    /// then these should be offset.z = 0, clipRect.origin.z = 0
    /// and clipRect.size.depth = 1. If the MPSImage contains multiple images,
    /// clipRect.size.depth refers to number of images to process. Both source
    /// and destination MPSImages must have at least this many images. offset.z
    /// refers to starting source image index. Thus offset.z + clipRect.size.depth must
    /// be
    /// <
    /// = source.numberOfImages. Similarly, clipRect.origin.z refers to starting
    /// image index in destination. So clipRect.origin.z + clipRect.size.depth must be
    /// <
    /// = destination.numberOfImage.
    ///
    /// destinationFeatureChannelOffset property can be used to control where the MPSKernel will
    /// start writing in feature channel dimension. For example, if the destination image has
    /// 64 channels, and MPSKernel outputs 32 channels, by default channels 0-31 of destination
    /// will be populated by MPSKernel. But if we want this MPSKernel to populate channel 32-63
    /// of the destination, we can set destinationFeatureChannelOffset = 32.
    /// A good example of this is concat (concatenation) operation in Tensor Flow. Suppose
    /// we have a src = w x h x Ni which goes through CNNConvolution_0 which produces
    /// output O0 = w x h x N0 and CNNConvolution_1 which produces output O1 = w x h x N1 followed
    /// by concatenation which produces O = w x h x (N0 + N1). We can achieve this by creating
    /// an MPSImage with dimensions O = w x h x (N0 + N1) and using this as destination of
    /// both convolutions as follows
    /// CNNConvolution0: destinationFeatureChannelOffset = 0, this will output N0 channels starting at
    /// channel 0 of destination thus populating [0,N0-1] channels.
    /// CNNConvolution1: destinationFeatureChannelOffset = N0, this will output N1 channels starting at
    /// channel N0 of destination thus populating [N0,N0+N1-1] channels.
    ///
    /// A MPSCNNKernel can be saved to disk / network using NSCoders such as NSKeyedArchiver.
    /// When decoding, the system default MTLDevice will be chosen unless the NSCoder adopts
    /// the
    /// <MPSDeviceProvider
    /// > protocol.  To accomplish this you will likely need to subclass your
    /// unarchiver to add this method.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/metalperformanceshaders/mpscnnkernel?language=objc)
    #[unsafe(super(MPSKernel, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
    pub struct MPSCNNKernel;
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCoding for MPSCNNKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCopying for MPSCNNKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
unsafe impl CopyingHelper for MPSCNNKernel {
    type Result = Self;
}

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSObjectProtocol for MPSCNNKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSSecureCoding for MPSCNNKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNKernel {
    extern_methods!(
        /// Standard init with default properties per filter type
        ///
        /// Parameter `device`: The device that the filter will be used on. May not be NULL.
        ///
        /// Returns: A pointer to the newly initialized object. This will fail, returning
        /// nil if the device is not supported. Devices must be
        /// MTLFeatureSet_iOS_GPUFamily2_v1 or later.
        #[unsafe(method(initWithDevice:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice(
            this: Allocated<Self>,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Retained<Self>;

        #[cfg(feature = "MPSCoreTypes")]
        /// The position of the destination clip rectangle origin relative to the source buffer.
        ///
        /// The offset is defined to be the position of clipRect.origin in source coordinates.
        /// Default: {0,0,0}, indicating that the top left corners of the clipRect and source image align.
        /// offset.z is the index of starting source image in batch processing mode.
        ///
        /// See Also:
        /// MetalPerformanceShaders.hsubsubsection_mpsoffset
        #[unsafe(method(offset))]
        #[unsafe(method_family = none)]
        pub unsafe fn offset(&self) -> MPSOffset;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`offset`][Self::offset].
        #[unsafe(method(setOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setOffset(&self, offset: MPSOffset);

        /// An optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.
        ///
        /// A MTLRegion that indicates which part of the destination to overwrite. If the clipRect does not lie
        /// completely within the destination image, the intersection between clip rectangle and destination bounds is
        /// used.   Default: MPSRectNoClip (MPSKernel::MPSRectNoClip) indicating the entire image.
        /// clipRect.origin.z is the index of starting destination image in batch processing mode. clipRect.size.depth
        /// is the number of images to process in batch processing mode.
        ///
        /// See Also:
        /// MetalPerformanceShaders.hsubsubsection_clipRect
        #[unsafe(method(clipRect))]
        #[unsafe(method_family = none)]
        pub unsafe fn clipRect(&self) -> MTLRegion;

        /// Setter for [`clipRect`][Self::clipRect].
        #[unsafe(method(setClipRect:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setClipRect(&self, clip_rect: MTLRegion);

        /// The number of channels in the destination MPSImage to skip before writing output.
        ///
        /// This is the starting offset into the destination image in the feature channel dimension
        /// at which destination data is written.
        /// This allows an application to pass a subset of all the channels in MPSImage as output of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel outputs 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as output, we can set destinationFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel outputs N channels,
        /// the destination image MUST have at least destinationFeatureChannelOffset + N channels. Using a destination
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution outputs 32 channels, and the destination has 64 channels, then it is an error to set
        /// destinationFeatureChannelOffset > 32.
        #[unsafe(method(destinationFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`destinationFeatureChannelOffset`][Self::destinationFeatureChannelOffset].
        #[unsafe(method(setDestinationFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationFeatureChannelOffset(
            &self,
            destination_feature_channel_offset: NSUInteger,
        );

        /// The number of channels in the source MPSImage to skip before reading the input.
        ///
        /// This is the starting offset into the source image in the feature channel dimension
        /// at which source data is read. Unit: feature channels
        /// This allows an application to read a subset of all the channels in MPSImage as input of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel needs to read 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as input, we can set sourceFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel inputs N channels,
        /// the source image MUST have at least sourceFeatureChannelOffset + N channels. Using a source
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution inputs 32 channels, and the source has 64 channels, then it is an error to set
        /// sourceFeatureChannelOffset > 32.
        #[unsafe(method(sourceFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`sourceFeatureChannelOffset`][Self::sourceFeatureChannelOffset].
        #[unsafe(method(setSourceFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceFeatureChannelOffset(
            &self,
            source_feature_channel_offset: NSUInteger,
        );

        /// The maximum number of channels in the source MPSImage to use
        ///
        /// Most filters can insert a slice operation into the filter for free.
        /// Use this to limit the size of the feature channel slice taken from
        /// the input image. If the value is too large, it is truncated to be
        /// the remaining size in the image after the sourceFeatureChannelOffset
        /// is taken into account.  Default: ULONG_MAX
        #[unsafe(method(sourceFeatureChannelMaxCount))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFeatureChannelMaxCount(&self) -> NSUInteger;

        /// Setter for [`sourceFeatureChannelMaxCount`][Self::sourceFeatureChannelMaxCount].
        #[unsafe(method(setSourceFeatureChannelMaxCount:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceFeatureChannelMaxCount(
            &self,
            source_feature_channel_max_count: NSUInteger,
        );

        #[cfg(feature = "MPSCoreTypes")]
        /// The MPSImageEdgeMode to use when texture reads stray off the edge of an image
        ///
        /// Most MPSKernel objects can read off the edge of the source image. This can happen
        /// because of a negative offset property, because the offset + clipRect.size is larger
        /// than the source image or because the filter looks at neighboring pixels, such as a
        /// Convolution filter.   Default:  MPSImageEdgeModeZero.
        ///
        /// See Also:
        /// MetalPerformanceShaders.hsubsubsection_edgemode
        /// Note: For
        /// MPSCNNPoolingAveragespecifying edge mode
        /// MPSImageEdgeModeClampis interpreted as a "shrink-to-edge" operation, which shrinks the effective
        /// filtering window to remain within the source image borders.
        #[unsafe(method(edgeMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn edgeMode(&self) -> MPSImageEdgeMode;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`edgeMode`][Self::edgeMode].
        #[unsafe(method(setEdgeMode:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setEdgeMode(&self, edge_mode: MPSImageEdgeMode);

        /// The width of the MPSCNNKernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Warning: This property was lowered to this class in ios/tvos 11
        /// The property may not be available on iOS/tvOS 10 for
        /// all subclasses of MPSCNNKernel
        #[unsafe(method(kernelWidth))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelWidth(&self) -> NSUInteger;

        /// The height of the MPSCNNKernel filter window
        ///
        /// This is the vertical diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Warning: This property was lowered to this class in ios/tvos 11
        /// The property may not be available on iOS/tvOS 10 for
        /// all subclasses of MPSCNNKernel
        #[unsafe(method(kernelHeight))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelHeight(&self) -> NSUInteger;

        /// The downsampling (or upsampling if a backwards filter) factor in the horizontal dimension
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        ///
        /// Warning: This property was lowered to this class in ios/tvos 11
        /// The property may not be available on iOS/tvOS 10 for
        /// all subclasses of MPSCNNKernel
        #[unsafe(method(strideInPixelsX))]
        #[unsafe(method_family = none)]
        pub unsafe fn strideInPixelsX(&self) -> NSUInteger;

        /// The downsampling (or upsampling if a backwards filter) factor in the vertical dimension
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        ///
        /// Warning: This property was lowered to this class in ios/tvos 11
        /// The property may not be available on iOS/tvOS 10 for
        /// all subclasses of MPSCNNKernel
        #[unsafe(method(strideInPixelsY))]
        #[unsafe(method_family = none)]
        pub unsafe fn strideInPixelsY(&self) -> NSUInteger;

        /// Stride in source coordinates from one kernel tap to the next in the X dimension.
        #[unsafe(method(dilationRateX))]
        #[unsafe(method_family = none)]
        pub unsafe fn dilationRateX(&self) -> NSUInteger;

        /// Stride in source coordinates from one kernel tap to the next in the Y dimension.
        #[unsafe(method(dilationRateY))]
        #[unsafe(method_family = none)]
        pub unsafe fn dilationRateY(&self) -> NSUInteger;

        /// YES if the filter operates backwards.
        ///
        /// This influences how strideInPixelsX/Y should be interpreted.
        /// Most filters either have stride 1 or are reducing, meaning that
        /// the result image is smaller than the original by roughly a factor
        /// of the stride.  A few "backward" filters (e.g convolution transpose) are intended
        /// to "undo" the effects of an earlier forward filter, and so
        /// enlarge the image. The stride is in the destination coordinate frame
        /// rather than the source coordinate frame.
        #[unsafe(method(isBackwards))]
        #[unsafe(method_family = none)]
        pub unsafe fn isBackwards(&self) -> bool;

        /// Returns true if the -encode call modifies the state object it accepts.
        #[unsafe(method(isStateModified))]
        #[unsafe(method_family = none)]
        pub unsafe fn isStateModified(&self) -> bool;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// The padding method used by the filter
        ///
        /// This influences how the destination image is sized and how
        /// the offset into the source image is set.  It is used by the
        /// -encode methods that return a MPSImage from the left hand side.
        #[unsafe(method(padding))]
        #[unsafe(method_family = none)]
        pub unsafe fn padding(&self) -> Retained<ProtocolObject<dyn MPSNNPadding>>;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// Setter for [`padding`][Self::padding].
        #[unsafe(method(setPadding:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPadding(&self, padding: &ProtocolObject<dyn MPSNNPadding>);

        #[cfg(feature = "MPSImage")]
        /// Method to allocate the result image for -encodeToCommandBuffer:sourceImage:
        ///
        /// Default: MPSTemporaryImage.defaultAllocator
        #[unsafe(method(destinationImageAllocator))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageAllocator(
            &self,
        ) -> Retained<ProtocolObject<dyn MPSImageAllocator>>;

        #[cfg(feature = "MPSImage")]
        /// Setter for [`destinationImageAllocator`][Self::destinationImageAllocator].
        #[unsafe(method(setDestinationImageAllocator:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationImageAllocator(
            &self,
            destination_image_allocator: &ProtocolObject<dyn MPSImageAllocator>,
        );

        /// NSSecureCoding compatability
        ///
        /// While the standard NSSecureCoding/NSCoding method
        /// -initWithCoder: should work, since the file can't
        /// know which device your data is allocated on, we
        /// have to guess and may guess incorrectly.  To avoid
        /// that problem, use initWithCoder:device instead.
        ///
        /// Parameter `aDecoder`: The NSCoder subclass with your serialized MPSKernel
        ///
        /// Parameter `device`: The MTLDevice on which to make the MPSKernel
        ///
        /// Returns: A new MPSKernel object, or nil if failure.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:device:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder_device(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Option<Retained<Self>>;

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImage`: A valid MPSImage object containing the source image.
        ///
        /// Parameter `destinationImage`: A valid MPSImage to be overwritten by result image. destinationImage may not alias sourceImage.
        #[unsafe(method(encodeToCommandBuffer:sourceImage:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImage_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImage,
            destination_image: &MPSImage,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a MPSCNNKernel with a destination state into a command Buffer.
        ///
        /// This is typically used during training. The state is commonly a MPSNNGradientState.
        /// Please see -resultStateForSourceImages:SourceStates: and batch+temporary variants.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImage`: A valid MPSImage object containing the source image.
        ///
        /// Parameter `destinationState`: A state to be overwritten by additional state information.
        ///
        /// Parameter `destinationImage`: A valid MPSImage to be overwritten by result image. destinationImage may not alias sourceImage.
        #[unsafe(method(encodeToCommandBuffer:sourceImage:destinationState:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImage_destinationState_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImage,
            destination_state: &MPSState,
            destination_image: &MPSImage,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImages`: A valid MPSImage object containing the source images.
        ///
        /// Parameter `destinationImages`: A valid MPSImage to be overwritten by result images.
        /// destinationImages may not alias sourceImages, even at different
        /// indices.
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:destinationImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages_destinationImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &MPSImageBatch,
            destination_images: &MPSImageBatch,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a MPSCNNKernel with a destination state into a command Buffer.
        ///
        /// This is typically used during training. The state is commonly a MPSNNGradientState.
        /// Please see -resultStateForSourceImages:SourceStates:destinationImage and batch+temporary variants.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImages`: A valid MPSImage object containing the source images.
        ///
        /// Parameter `destinationStates`: A list of states to be overwritten by results
        ///
        /// Parameter `destinationImages`: A valid MPSImage to be overwritten by result images.
        /// destinationImages may not alias sourceImages, even at different
        /// indices.
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages_destinationStates_destinationImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &MPSImageBatch,
            destination_states: Option<&MPSStateBatch>,
            destination_images: &MPSImageBatch,
        );

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture to hold the result and return it.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImage`: A MPSImage to use as the source images for the filter.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:sourceImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImage,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture and state to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImage`: A MPSImage to use as the source images for the filter.
        ///
        /// Parameter `outState`: A new state object is returned here.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:sourceImage:destinationState:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImage_destinationState_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImage,
            out_state: &mut Option<Retained<MPSState>>,
            is_temporary: bool,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture to hold the result and return it.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImages`: A MPSImages to use as the source images for the filter.
        ///
        /// Returns: An array of MPSImages or MPSTemporaryImages allocated per the destinationImageAllocator
        /// containing the output of the graph. The offset property will be adjusted to reflect the
        /// offset used during the encode. The returned images will be automatically released when
        /// the command buffer completes. If you want to keep them around for longer, retain the images.
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &MPSImageBatch,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a MPSImageBatch and MPSStateBatch to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        /// Usage:
        ///
        /// ```text
        ///                   MPSStateBatch * outStates = nil;    // autoreleased
        ///                   MPSImageBatch * result = [k encodeBatchToCommandBuffer: cmdBuf
        ///                                                             sourceImages: sourceImages
        ///                                                        destinationStates: &outStates ];
        /// ```
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImages`: A MPSImages to use as the source images for the filter.
        ///
        /// Parameter `outStates`: A pointer to storage to hold a MPSStateBatch* where output states are returned
        ///
        /// Returns: An array of MPSImages or MPSTemporaryImages allocated per the destinationImageAllocator
        /// containing the output of the graph. The offset property will be adjusted to reflect the
        /// offset used during the encode. The returned images will be automatically released when
        /// the command buffer completes. If you want to keep them around for longer, retain the images.
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages_destinationStates_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &MPSImageBatch,
            out_states: &mut Option<Retained<MPSStateBatch>>,
            is_temporary: bool,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate any MPSState objects that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the source image.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION:
        /// The kernel must have all properties set to values that will ultimately be
        /// passed to the -encode call that writes to the state, before
        /// -resultStateForSourceImages:sourceStates:destinationImage: is called or behavior is undefined.
        /// Please note that -destinationImageDescriptorForSourceImages:sourceStates:
        /// will alter some of these properties automatically based on the padding policy.
        /// If you intend to call that to make the destination image, then you should
        /// call that before -resultStateForSourceImages:sourceStates:destinationImage:. This will ensure the
        /// properties used in the encode call and in the destination image creation
        /// match those used to configure the state.
        ///
        /// The following order is recommended:
        ///
        /// // Configure MPSCNNKernel properties first
        /// kernel.edgeMode = MPSImageEdgeModeZero;
        /// kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
        /// ...
        ///
        /// // ALERT: will change MPSCNNKernel properties
        /// MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
        /// sourceStates: states];
        /// MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
        /// imageDescriptor: d];
        ///
        /// // Now that all properties are configured properly, we can make the result state
        /// // and call encode.
        /// MPSState * __nullable destState = [kernel resultStateForSourceImage: source
        /// sourceStates: states
        /// destinationImage: dest];
        ///
        /// // This form of -encode will be declared by the MPSCNNKernel subclass
        /// [kernel encodeToCommandBuffer: cmdBuf
        /// sourceImage: source
        /// destinationState: destState
        /// destinationImage: dest ];
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `sourceImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Parameter `destinationImage`: The destination image for the encode call
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(resultStateForSourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateForSourceImage_sourceStates_destinationImage(
            &self,
            source_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(resultStateBatchForSourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateBatchForSourceImage_sourceStates_destinationImage(
            &self,
            source_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a temporary MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate any MPSState objects that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the command buffer.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION:
        /// The kernel must have all properties set to values that will ultimately be
        /// passed to the -encode call that writes to the state, before
        /// -resultStateForSourceImages:sourceStates:destinationImage: is called or behavior is undefined.
        /// Please note that -destinationImageDescriptorForSourceImages:sourceStates:destinationImage:
        /// will alter some of these properties automatically based on the padding policy.
        /// If you intend to call that to make the destination image, then you should
        /// call that before -resultStateForSourceImages:sourceStates:destinationImage:.  This will ensure the
        /// properties used in the encode call and in the destination image creation
        /// match those used to configure the state.
        ///
        /// The following order is recommended:
        ///
        /// // Configure MPSCNNKernel properties first
        /// kernel.edgeMode = MPSImageEdgeModeZero;
        /// kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
        /// ...
        ///
        /// // ALERT: will change MPSCNNKernel properties
        /// MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
        /// sourceStates: states];
        /// MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
        /// imageDescriptor: d];
        ///
        /// // Now that all properties are configured properly, we can make the result state
        /// // and call encode.
        /// MPSState * __nullable destState = [kernel temporaryResultStateForCommandBuffer: cmdBuf
        /// sourceImage: source
        /// sourceStates: states];
        ///
        /// // This form of -encode will be declared by the MPSCNNKernel subclass
        /// [kernel encodeToCommandBuffer: cmdBuf
        /// sourceImage: source
        /// destinationState: destState
        /// destinationImage: dest ];
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer to allocate the temporary storage against
        /// The state will only be valid on this command buffer.
        ///
        /// Parameter `sourceImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Parameter `destinationImage`: The destination image for the encode call
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(temporaryResultStateForCommandBuffer:sourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateForCommandBuffer_sourceImage_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(temporaryResultStateBatchForCommandBuffer:sourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateBatchForCommandBuffer_sourceImage_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        /// Returns YES if the same state is used for every operation in a batch
        ///
        /// If NO, then each image in a MPSImageBatch will need a corresponding
        /// (and different) state to go with it. Set to YES to avoid allocating
        /// redundant state in the case when the same state is used all the time.
        /// Default: NO
        #[unsafe(method(isResultStateReusedAcrossBatch))]
        #[unsafe(method_family = none)]
        pub unsafe fn isResultStateReusedAcrossBatch(&self) -> bool;

        /// Returns YES if the filter must be run over the entire batch before its
        /// results may be used
        ///
        /// Nearly all filters do not need to see the entire batch all at once and can
        /// operate correctly with partial batches. This allows the graph to
        /// strip-mine the problem, processing the graph top to bottom on a subset
        /// of the batch at a time, dramatically reducing memory usage. As the full
        /// nominal working set for a graph is often so large that it may not fit
        /// in memory, sub-batching may be required forward progress.
        ///
        /// Batch normalization statistics on the other hand must complete the batch
        /// before the statistics may be used to normalize the images in the batch
        /// in the ensuing normalization filter. Consequently, batch normalization statistics
        /// requests the graph insert a batch barrier following it by returning
        /// YES from -appendBatchBarrier. This tells the graph to complete the batch
        /// before any dependent filters can start. Note that the filter itself may
        /// still be subject to sub-batching in its operation. All filters must be able to
        /// function without seeing the entire batch in a single -encode call. Carry
        /// over state that is accumulated across sub-batches is commonly carried in
        /// a shared MPSState containing a MTLBuffer. See -isResultStateReusedAcrossBatch.
        ///
        /// Caution: on most supported devices, the working set may be so large
        /// that the graph may be forced to throw away and recalculate most
        /// intermediate images in cases where strip-mining can not occur because
        /// -appendBatchBarrier returns YES. A single batch barrier can commonly
        /// cause a memory size increase and/or performance reduction by many fold
        /// over the entire graph.  Filters of this variety should be avoided.
        ///
        /// Default: NO
        #[unsafe(method(appendBatchBarrier))]
        #[unsafe(method_family = none)]
        pub unsafe fn appendBatchBarrier(&self) -> bool;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Get a suggested destination image descriptor for a source image
        ///
        /// Your application is certainly free to pass in any destinationImage
        /// it likes to encodeToCommandBuffer:sourceImage:destinationImage,
        /// within reason. This is the basic design for iOS 10. This method
        /// is therefore not required.
        ///
        /// However, calculating the MPSImage size and MPSCNNKernel properties
        /// for each filter can be tedious and complicated work, so this method
        /// is made available to automate the process. The application may
        /// modify the properties of the descriptor before a MPSImage is made from
        /// it, so long as the choice is sensible for the kernel in question.
        /// Please see individual kernel descriptions for restrictions.
        ///
        /// The expected timeline for use is as follows:
        ///
        /// 1) This method is called:
        /// a) The default MPS padding calculation is applied. It
        /// uses the MPSNNPaddingMethod of the .padding property to
        /// provide a consistent addressing scheme over the graph.
        /// It creates the MPSImageDescriptor and adjusts the .offset
        /// property of the MPSNNKernel. When using a MPSNNGraph, the
        /// padding is set using the MPSNNFilterNode as a proxy.
        ///
        /// b) This method may be overridden by MPSCNNKernel subclass
        /// to achieve any customization appropriate to the object type.
        ///
        /// c) Source states are then applied in order. These may modify the
        /// descriptor and may update other object properties. See:
        /// -destinationImageDescriptorForSourceImages:sourceStates:
        /// forKernel:suggestedDescriptor:  This is the typical way
        /// in which MPS may attempt to influence the operation of
        /// its kernels.
        ///
        /// d) If the .padding property has a custom padding policy method
        /// of the same name, it is called. Similarly, it may also adjust
        /// the descriptor and any MPSCNNKernel properties. This is the
        /// typical way in which your application may attempt to influence
        /// the operation of the MPS kernels.
        ///
        /// 2) A result is returned from this method and the caller
        /// may further adjust the descriptor and kernel properties
        /// directly.
        ///
        /// 3) The caller uses the descriptor to make a new MPSImage to
        /// use as the destination image for the -encode call in step 5.
        ///
        /// 4) The caller calls -resultStateForSourceImage:sourceStates:destinationImage:
        /// to make any result states needed for the kernel. If there isn't
        /// one, it will return nil. A variant is available to return a
        /// temporary state instead.
        ///
        /// 5) a -encode method is called to encode the kernel.
        ///
        /// The entire process 1-5 is more simply achieved by just calling an -encode...
        /// method that returns a MPSImage out the left hand sid of the method. Simpler
        /// still, use the MPSNNGraph to coordinate the entire process from end to end.
        /// Opportunities to influence the process are of course reduced, as (2) is no longer
        /// possible with either method. Your application may opt to use the five step method
        /// if it requires greater customization as described, or if it would like to estimate
        /// storage in advance based on the sum of MPSImageDescriptors before processing
        /// a graph. Storage estimation is done by using the MPSImageDescriptor to create
        /// a MPSImage (without passing it a texture), and then call -resourceSize. As long
        /// as the MPSImage is not used in an encode call and the .texture property is not
        /// invoked, the underlying MTLTexture is not created.
        ///
        /// No destination state or destination image is provided as an argument to this
        /// function because it is expected they will be made / configured after this
        /// is called. This method is expected to auto-configure important object properties
        /// that may be needed in the ensuing destination image and state creation steps.
        ///
        ///
        /// Parameter `sourceImages`: A array of source images that will be passed into the -encode call
        /// Since MPSCNNKernel is a unary kernel, it is an array of length 1.
        ///
        /// Parameter `sourceStates`: An optional array of source states that will be passed into the -encode call
        ///
        /// Returns: an image descriptor allocated on the autorelease pool
        #[unsafe(method(destinationImageDescriptorForSourceImages:sourceStates:))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageDescriptorForSourceImages_sourceStates(
            &self,
            source_images: &NSArray<MPSImage>,
            source_states: Option<&NSArray<MPSState>>,
        ) -> Retained<MPSImageDescriptor>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// The size of extra MPS heap storage allocated while the kernel is encoding
        ///
        /// This is best effort and just describes things that are likely to end up on the MPS heap. It does not
        /// describe all allocation done by the -encode call.  It is intended for use with high water calculations
        /// for MTLHeap sizing. Allocations are typically for temporary storage needed for multipass algorithms.
        /// This interface should not be used to detect multipass algorithms.
        #[unsafe(method(encodingStorageSizeForSourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodingStorageSizeForSourceImage_sourceStates_destinationImage(
            &self,
            source_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: Option<&MPSImage>,
        ) -> NSUInteger;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// The size of extra MPS heap storage allocated while the kernel is encoding a batch
        ///
        /// This is best effort and just describes things that are likely to end up on the MPS heap. It does not
        /// describe all allocation done by the -encode call.  It is intended for use with high water calculations
        /// for MTLHeap sizing. Allocations are typically for temporary storage needed for multipass algorithms.
        /// This interface should not be used to detect multipass algorithms.
        #[unsafe(method(batchEncodingStorageSizeForSourceImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn batchEncodingStorageSizeForSourceImage_sourceStates_destinationImage(
            &self,
            source_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: Option<&MPSImageBatch>,
        ) -> NSUInteger;
    );
}

/// Methods declared on superclass `MPSKernel`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNKernel {
    extern_methods!(
        /// Called by NSCoder to decode MPSKernels
        ///
        /// This isn't the right interface to decode a MPSKernel, but
        /// it is the one that NSCoder uses. To enable your NSCoder
        /// (e.g. NSKeyedUnarchiver) to set which device to use
        /// extend the object to adopt the MPSDeviceProvider
        /// protocol. Otherwise, the Metal system default device
        /// will be used.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
        ) -> Option<Retained<Self>>;
    );
}

/// Methods declared on superclass `NSObject`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNKernel {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// Dependencies: This depends on Metal.framework
    ///
    /// Describes a convolution neural network kernel.
    ///
    /// A MPSCNNKernel consumes two MPSImages, primary and secondary, and produces one MPSImage.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/metalperformanceshaders/mpscnnbinarykernel?language=objc)
    #[unsafe(super(MPSKernel, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
    pub struct MPSCNNBinaryKernel;
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCoding for MPSCNNBinaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCopying for MPSCNNBinaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
unsafe impl CopyingHelper for MPSCNNBinaryKernel {
    type Result = Self;
}

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSObjectProtocol for MPSCNNBinaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSSecureCoding for MPSCNNBinaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNBinaryKernel {
    extern_methods!(
        /// Standard init with default properties per filter type
        ///
        /// Parameter `device`: The device that the filter will be used on. May not be NULL.
        ///
        /// Returns: A pointer to the newly initialized object. This will fail, returning
        /// nil if the device is not supported. Devices must be
        /// MTLFeatureSet_iOS_GPUFamily2_v1 or later.
        #[unsafe(method(initWithDevice:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice(
            this: Allocated<Self>,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Retained<Self>;

        #[cfg(feature = "MPSCoreTypes")]
        /// The position of the destination clip rectangle origin relative to the primary source buffer.
        ///
        /// The offset is defined to be the position of clipRect.origin in source coordinates.
        /// Default: {0,0,0}, indicating that the top left corners of the clipRect and primary source image align.
        /// offset.z is the index of starting source image in batch processing mode.
        ///
        /// See Also:
        /// subsubsection_mpsoffset
        #[unsafe(method(primaryOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryOffset(&self) -> MPSOffset;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`primaryOffset`][Self::primaryOffset].
        #[unsafe(method(setPrimaryOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimaryOffset(&self, primary_offset: MPSOffset);

        #[cfg(feature = "MPSCoreTypes")]
        /// The position of the destination clip rectangle origin relative to the secondary source buffer.
        ///
        /// The offset is defined to be the position of clipRect.origin in source coordinates.
        /// Default: {0,0,0}, indicating that the top left corners of the clipRect and secondary source image align.
        /// offset.z is the index of starting source image in batch processing mode.
        ///
        /// See Also:
        /// subsubsection_mpsoffset
        #[unsafe(method(secondaryOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryOffset(&self) -> MPSOffset;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`secondaryOffset`][Self::secondaryOffset].
        #[unsafe(method(setSecondaryOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondaryOffset(&self, secondary_offset: MPSOffset);

        /// An optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.
        ///
        /// A MTLRegion that indicates which part of the destination to overwrite. If the clipRect does not lie
        /// completely within the destination image, the intersection between clip rectangle and destination bounds is
        /// used.   Default: MPSRectNoClip (MPSKernel::MPSRectNoClip) indicating the entire image.
        /// clipRect.origin.z is the index of starting destination image in batch processing mode. clipRect.size.depth
        /// is the number of images to process in batch processing mode.
        ///
        /// See Also:
        /// subsubsection_clipRect
        #[unsafe(method(clipRect))]
        #[unsafe(method_family = none)]
        pub unsafe fn clipRect(&self) -> MTLRegion;

        /// Setter for [`clipRect`][Self::clipRect].
        #[unsafe(method(setClipRect:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setClipRect(&self, clip_rect: MTLRegion);

        /// The number of channels in the destination MPSImage to skip before writing output.
        ///
        /// This is the starting offset into the destination image in the feature channel dimension
        /// at which destination data is written.
        /// This allows an application to pass a subset of all the channels in MPSImage as output of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel outputs 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as output, we can set destinationFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel outputs N channels,
        /// destination image MUST have at least destinationFeatureChannelOffset + N channels. Using a destination
        /// image with insufficient number of feature channels result in an error.
        /// E.g. if the MPSCNNConvolution outputs 32 channels, and destination has 64 channels, then it is an error to set
        /// destinationFeatureChannelOffset > 32.
        #[unsafe(method(destinationFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`destinationFeatureChannelOffset`][Self::destinationFeatureChannelOffset].
        #[unsafe(method(setDestinationFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationFeatureChannelOffset(
            &self,
            destination_feature_channel_offset: NSUInteger,
        );

        /// The number of channels in the primary source MPSImage to skip before reading the input.
        ///
        /// This is the starting offset into the primary source image in the feature channel dimension
        /// at which source data is read. Unit: feature channels
        /// This allows an application to read a subset of all the channels in MPSImage as input of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel needs to read 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as input, we can set primarySourceFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel inputs N channels,
        /// the source image MUST have at least primarySourceFeatureChannelOffset + N channels. Using a source
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution inputs 32 channels, and the source has 64 channels, then it is an error to set
        /// primarySourceFeatureChannelOffset > 32.
        #[unsafe(method(primarySourceFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn primarySourceFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`primarySourceFeatureChannelOffset`][Self::primarySourceFeatureChannelOffset].
        #[unsafe(method(setPrimarySourceFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimarySourceFeatureChannelOffset(
            &self,
            primary_source_feature_channel_offset: NSUInteger,
        );

        /// The number of channels in the secondary source MPSImage to skip before reading the input.
        ///
        /// This is the starting offset into the secondary source image in the feature channel dimension
        /// at which source data is read. Unit: feature channels
        /// This allows an application to read a subset of all the channels in MPSImage as input of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel needs to read 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as input, we can set secondarySourceFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel inputs N channels,
        /// the source image MUST have at least primarySourceFeatureChannelOffset + N channels. Using a source
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution inputs 32 channels, and the source has 64 channels, then it is an error to set
        /// primarySourceFeatureChannelOffset > 32.
        #[unsafe(method(secondarySourceFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondarySourceFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`secondarySourceFeatureChannelOffset`][Self::secondarySourceFeatureChannelOffset].
        #[unsafe(method(setSecondarySourceFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondarySourceFeatureChannelOffset(
            &self,
            secondary_source_feature_channel_offset: NSUInteger,
        );

        /// The maximum number of channels in the primary source MPSImage to use
        ///
        /// Most filters can insert a slice operation into the filter for free.
        /// Use this to limit the size of the feature channel slice taken from
        /// the input image. If the value is too large, it is truncated to be
        /// the remaining size in the image after the sourceFeatureChannelOffset
        /// is taken into account.  Default: ULONG_MAX
        #[unsafe(method(primarySourceFeatureChannelMaxCount))]
        #[unsafe(method_family = none)]
        pub unsafe fn primarySourceFeatureChannelMaxCount(&self) -> NSUInteger;

        /// Setter for [`primarySourceFeatureChannelMaxCount`][Self::primarySourceFeatureChannelMaxCount].
        #[unsafe(method(setPrimarySourceFeatureChannelMaxCount:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimarySourceFeatureChannelMaxCount(
            &self,
            primary_source_feature_channel_max_count: NSUInteger,
        );

        /// The maximum number of channels in the secondary source MPSImage to use
        ///
        /// Most filters can insert a slice operation into the filter for free.
        /// Use this to limit the size of the feature channel slice taken from
        /// the input image. If the value is too large, it is truncated to be
        /// the remaining size in the image after the sourceFeatureChannelOffset
        /// is taken into account.  Default: ULONG_MAX
        #[unsafe(method(secondarySourceFeatureChannelMaxCount))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondarySourceFeatureChannelMaxCount(&self) -> NSUInteger;

        /// Setter for [`secondarySourceFeatureChannelMaxCount`][Self::secondarySourceFeatureChannelMaxCount].
        #[unsafe(method(setSecondarySourceFeatureChannelMaxCount:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondarySourceFeatureChannelMaxCount(
            &self,
            secondary_source_feature_channel_max_count: NSUInteger,
        );

        #[cfg(feature = "MPSCoreTypes")]
        /// The MPSImageEdgeMode to use when texture reads stray off the edge of the primary source image
        ///
        /// Most MPSKernel objects can read off the edge of the source image. This can happen
        /// because of a negative offset property, because the offset + clipRect.size is larger
        /// than the source image or because the filter looks at neighboring pixels, such as a
        /// Convolution filter.   Default:  MPSImageEdgeModeZero.
        ///
        /// See Also:
        /// subsubsection_edgemode
        #[unsafe(method(primaryEdgeMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryEdgeMode(&self) -> MPSImageEdgeMode;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`primaryEdgeMode`][Self::primaryEdgeMode].
        #[unsafe(method(setPrimaryEdgeMode:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimaryEdgeMode(&self, primary_edge_mode: MPSImageEdgeMode);

        #[cfg(feature = "MPSCoreTypes")]
        /// The MPSImageEdgeMode to use when texture reads stray off the edge of the primary source image
        ///
        /// Most MPSKernel objects can read off the edge of the source image. This can happen
        /// because of a negative offset property, because the offset + clipRect.size is larger
        /// than the source image or because the filter looks at neighboring pixels, such as a
        /// Convolution filter.   Default:  MPSImageEdgeModeZero.
        ///
        /// See Also:
        /// subsubsection_edgemode
        #[unsafe(method(secondaryEdgeMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryEdgeMode(&self) -> MPSImageEdgeMode;

        #[cfg(feature = "MPSCoreTypes")]
        /// Setter for [`secondaryEdgeMode`][Self::secondaryEdgeMode].
        #[unsafe(method(setSecondaryEdgeMode:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondaryEdgeMode(&self, secondary_edge_mode: MPSImageEdgeMode);

        /// The width of the MPSCNNBinaryKernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        #[unsafe(method(primaryKernelWidth))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryKernelWidth(&self) -> NSUInteger;

        /// The height of the MPSCNNBinaryKernel filter window
        ///
        /// This is the vertical diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        #[unsafe(method(primaryKernelHeight))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryKernelHeight(&self) -> NSUInteger;

        /// The width of the MPSCNNBinaryKernel filter window for the second image source
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNBinaryKernel does not have a filter window, then
        /// 1 will be returned.
        #[unsafe(method(secondaryKernelWidth))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryKernelWidth(&self) -> NSUInteger;

        /// The height of the MPSCNNBinaryKernel filter window for the second image source
        ///
        /// This is the vertical diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNBinaryKernel does not have a filter window, then
        /// 1 will be returned.
        #[unsafe(method(secondaryKernelHeight))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryKernelHeight(&self) -> NSUInteger;

        /// The downsampling (or upsampling if a backwards filter) factor in the horizontal dimension
        /// for the primary source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        #[unsafe(method(primaryStrideInPixelsX))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryStrideInPixelsX(&self) -> NSUInteger;

        /// Setter for [`primaryStrideInPixelsX`][Self::primaryStrideInPixelsX].
        #[unsafe(method(setPrimaryStrideInPixelsX:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimaryStrideInPixelsX(&self, primary_stride_in_pixels_x: NSUInteger);

        /// The downsampling (or upsampling if a backwards filter) factor in the vertical dimension
        /// for the primary source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        #[unsafe(method(primaryStrideInPixelsY))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryStrideInPixelsY(&self) -> NSUInteger;

        /// Setter for [`primaryStrideInPixelsY`][Self::primaryStrideInPixelsY].
        #[unsafe(method(setPrimaryStrideInPixelsY:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPrimaryStrideInPixelsY(&self, primary_stride_in_pixels_y: NSUInteger);

        /// The downsampling (or upsampling if a backwards filter) factor in the horizontal dimension
        /// for the secondary source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        #[unsafe(method(secondaryStrideInPixelsX))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryStrideInPixelsX(&self) -> NSUInteger;

        /// Setter for [`secondaryStrideInPixelsX`][Self::secondaryStrideInPixelsX].
        #[unsafe(method(setSecondaryStrideInPixelsX:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondaryStrideInPixelsX(&self, secondary_stride_in_pixels_x: NSUInteger);

        /// The downsampling (or upsampling if a backwards filter) factor in the vertical dimension
        /// for the secondary source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        #[unsafe(method(secondaryStrideInPixelsY))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryStrideInPixelsY(&self) -> NSUInteger;

        /// Setter for [`secondaryStrideInPixelsY`][Self::secondaryStrideInPixelsY].
        #[unsafe(method(setSecondaryStrideInPixelsY:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSecondaryStrideInPixelsY(&self, secondary_stride_in_pixels_y: NSUInteger);

        /// Stride in source coordinates from one kernel tap to the next in the X dimension.
        #[unsafe(method(primaryDilationRateX))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryDilationRateX(&self) -> NSUInteger;

        /// Stride in source coordinates from one kernel tap to the next in the Y dimension.
        #[unsafe(method(primaryDilationRateY))]
        #[unsafe(method_family = none)]
        pub unsafe fn primaryDilationRateY(&self) -> NSUInteger;

        /// Stride in source coordinates from one kernel tap to the next in the X dimension.
        ///
        /// As applied to the secondary source image.
        #[unsafe(method(secondaryDilationRateX))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryDilationRateX(&self) -> NSUInteger;

        /// Stride in source coordinates from one kernel tap to the next in the Y dimension.
        ///
        /// As applied to the secondary source image.
        #[unsafe(method(secondaryDilationRateY))]
        #[unsafe(method_family = none)]
        pub unsafe fn secondaryDilationRateY(&self) -> NSUInteger;

        /// YES if the filter operates backwards.
        ///
        /// This influences how strideInPixelsX/Y should be interpreted.
        #[unsafe(method(isBackwards))]
        #[unsafe(method_family = none)]
        pub unsafe fn isBackwards(&self) -> bool;

        /// Returns true if the -encode call modifies the state object it accepts.
        #[unsafe(method(isStateModified))]
        #[unsafe(method_family = none)]
        pub unsafe fn isStateModified(&self) -> bool;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// The padding method used by the filter
        ///
        /// This influences how strideInPixelsX/Y should be interpreted.
        /// Default:  MPSNNPaddingMethodAlignCentered | MPSNNPaddingMethodAddRemainderToTopLeft | MPSNNPaddingMethodSizeSame
        /// Some object types (e.g. MPSCNNFullyConnected) may override this default with something appropriate to its operation.
        #[unsafe(method(padding))]
        #[unsafe(method_family = none)]
        pub unsafe fn padding(&self) -> Retained<ProtocolObject<dyn MPSNNPadding>>;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// Setter for [`padding`][Self::padding].
        #[unsafe(method(setPadding:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPadding(&self, padding: &ProtocolObject<dyn MPSNNPadding>);

        #[cfg(feature = "MPSImage")]
        /// Method to allocate the result image for -encodeToCommandBuffer:sourceImage:
        ///
        /// Default: MPSTemporaryImage.defaultAllocator
        #[unsafe(method(destinationImageAllocator))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageAllocator(
            &self,
        ) -> Retained<ProtocolObject<dyn MPSImageAllocator>>;

        #[cfg(feature = "MPSImage")]
        /// Setter for [`destinationImageAllocator`][Self::destinationImageAllocator].
        #[unsafe(method(setDestinationImageAllocator:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationImageAllocator(
            &self,
            destination_image_allocator: &ProtocolObject<dyn MPSImageAllocator>,
        );

        /// NSSecureCoding compatability
        ///
        /// While the standard NSSecureCoding/NSCoding method
        /// -initWithCoder: should work, since the file can't
        /// know which device your data is allocated on, we
        /// have to guess and may guess incorrectly.  To avoid
        /// that problem, use initWithCoder:device instead.
        ///
        /// Parameter `aDecoder`: The NSCoder subclass with your serialized MPSKernel
        ///
        /// Parameter `device`: The MTLDevice on which to make the MPSKernel
        ///
        /// Returns: A new MPSKernel object, or nil if failure.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:device:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder_device(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Option<Retained<Self>>;

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `primaryImage`: A valid MPSImage object containing the primary source image.
        ///
        /// Parameter `secondaryImage`: A valid MPSImage object containing the secondary source image.
        ///
        /// Parameter `destinationImage`: A valid MPSImage to be overwritten by result image. destinationImage may not alias primarySourceImage or secondarySourceImage.
        #[unsafe(method(encodeToCommandBuffer:primaryImage:secondaryImage:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_primaryImage_secondaryImage_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
            destination_image: &MPSImage,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method. Multiple images are processed concurrently.
        /// All images must have MPSImage.numberOfImages = 1.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `primaryImages`: An array of MPSImage objects containing the primary source images.
        ///
        /// Parameter `secondaryImages`: An array MPSImage objects containing the secondary source images.
        ///
        /// Parameter `destinationImages`: An array of MPSImage objects to contain the result images.
        /// destinationImages may not alias primarySourceImages or secondarySourceImages
        /// in any manner.
        #[unsafe(method(encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_primaryImages_secondaryImages_destinationImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_images: &MPSImageBatch,
            secondary_images: &MPSImageBatch,
            destination_images: &MPSImageBatch,
        );

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture to hold the result and return it.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property.  See discussion in MPSNeuralNetworkTypes.h.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `primaryImage`: A MPSImages to use as the primary source images for the filter.
        ///
        /// Parameter `secondaryImage`: A MPSImages to use as the secondary source images for the filter.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:primaryImage:secondaryImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_primaryImage_secondaryImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create textures to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeBatchToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property.  See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `primaryImage`: A MPSImages to use as the primary source images for the filter.
        ///
        /// Parameter `secondaryImage`: A MPSImages to use as the secondary source images for the filter.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeBatchToCommandBuffer:primaryImages:secondaryImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_primaryImages_secondaryImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImageBatch,
            secondary_image: &MPSImageBatch,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture and state to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `primaryImage`: A MPSImage to use as the source images for the filter.
        ///
        /// Parameter `secondaryImage`: A MPSImage to use as the source images for the filter.
        ///
        /// Parameter `outState`: The address of location to write the pointer to the result state of the operation
        ///
        /// Parameter `isTemporary`: YES if the outState should be a temporary object
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:primaryImage:secondaryImage:destinationState:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_primaryImage_secondaryImage_destinationState_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
            out_state: &mut Option<Retained<MPSState>>,
            is_temporary: bool,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture and state to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `primaryImages`: A MPSImage to use as the source images for the filter.
        ///
        /// Parameter `secondaryImages`: A MPSImage to use as the source images for the filter.
        ///
        /// Parameter `outState`: A new state object is returned here.
        ///
        /// Parameter `isTemporary`: YES if the outState should be a temporary object
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeBatchToCommandBuffer:primaryImages:secondaryImages:destinationStates:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_primaryImages_secondaryImages_destinationStates_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_images: &MPSImageBatch,
            secondary_images: &MPSImageBatch,
            out_state: &mut Option<Retained<MPSStateBatch>>,
            is_temporary: bool,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate a MPSState object (if any) that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the source image.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION: the result state should be made after the kernel properties are
        /// configured for the -encode call that will write to the state, and
        /// after -destinationImageDescriptorForSourceImages:sourceStates:
        /// is called (if it is called). Otherwise, behavior is undefined.
        /// Please see the description of
        /// -[MPSCNNKernel resultStateForSourceImage:sourceStates:destinationImage:] for more.
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `primaryImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `secondaryImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(resultStateForPrimaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateForPrimaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(resultStateBatchForPrimaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateBatchForPrimaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            primary_image: &MPSImageBatch,
            secondary_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a temporary MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate any MPSState objects that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the command buffer.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION: the result state should be made after the kernel properties are
        /// configured for the -encode call that will write to the state, and
        /// after -destinationImageDescriptorForSourceImages:sourceStates:
        /// is called (if it is called). Otherwise, behavior is undefined.
        /// Please see the description of
        /// -[MPSCNNKernel resultStateForSourceImage:sourceStates:destinationImage] for more.
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer to allocate the temporary storage against
        /// The state will only be valid on this command buffer.
        ///
        /// Parameter `primaryImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `secondaryImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(temporaryResultStateForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateForCommandBuffer_primaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(temporaryResultStateBatchForCommandBuffer:primaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateBatchForCommandBuffer_primaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            primary_image: &MPSImageBatch,
            secondary_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        /// Returns YES if the same state is used for every operation in a batch
        ///
        /// If NO, then each image in a MPSImageBatch will need a corresponding
        /// (and different) state to go with it. Set to YES to avoid allocating
        /// redundant state in the case when the same state is used all the time.
        /// Default: NO
        #[unsafe(method(isResultStateReusedAcrossBatch))]
        #[unsafe(method_family = none)]
        pub unsafe fn isResultStateReusedAcrossBatch(&self) -> bool;

        /// Returns YES if the filter must be run over the entire batch before its
        /// results may be considered complete
        ///
        /// The MPSNNGraph may split batches into sub-batches to save memory. However,
        /// some filters, like batch statistics calculations, need to operate over
        /// the entire batch to calculate a valid result, in this case, the mean and
        /// variance per channel over the set of images.
        ///
        /// In such cases, the accumulated result is commonly stored in a MPSState
        /// containing a MTLBuffer. (MTLTextures may not be able to be read from
        /// and written to in the same filter on some devices.) -isResultStateReusedAcrossBatch
        /// is set to YES, so that the state is allocated once and passed in for each
        /// sub-batch and the filter accumulates its results into it, one sub-batch
        /// at a time. Note that sub-batches may frequently be as small as 1.
        ///
        /// Default: NO
        #[unsafe(method(appendBatchBarrier))]
        #[unsafe(method_family = none)]
        pub unsafe fn appendBatchBarrier(&self) -> bool;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Get a suggested destination image descriptor for a source image
        ///
        /// Your application is certainly free to pass in any destinationImage
        /// it likes to encodeToCommandBuffer:sourceImage:destinationImage,
        /// within reason. This is the basic design for iOS 10. This method
        /// is therefore not required.
        ///
        /// However, calculating the MPSImage size and MPSCNNBinaryKernel properties
        /// for each filter can be tedious and complicated work, so this method
        /// is made available to automate the process. The application may
        /// modify the properties of the descriptor before a MPSImage is made from
        /// it, so long as the choice is sensible for the kernel in question.
        /// Please see individual kernel descriptions for restrictions.
        ///
        /// The expected timeline for use is as follows:
        ///
        /// 1) This method is called:
        /// a) The default MPS padding calculation is applied. It
        /// uses the MPSNNPaddingMethod of the .padding property to
        /// provide a consistent addressing scheme over the graph.
        /// It creates the MPSImageDescriptor and adjusts the .offset
        /// property of the MPSNNKernel. When using a MPSNNGraph, the
        /// padding is set using the MPSNNFilterNode as a proxy.
        ///
        /// b) This method may be overridden by MPSCNNBinaryKernel subclass
        /// to achieve any customization appropriate to the object type.
        ///
        /// c) Source states are then applied in order. These may modify the
        /// descriptor and may update other object properties. See:
        /// -destinationImageDescriptorForSourceImages:sourceStates:
        /// forKernel:suggestedDescriptor:  This is the typical way
        /// in which MPS may attempt to influence the operation of
        /// its kernels.
        ///
        /// d) If the .padding property has a custom padding policy method
        /// of the same name, it is called. Similarly, it may also adjust
        /// the descriptor and any MPSCNNBinaryKernel properties. This is the
        /// typical way in which your application may attempt to influence
        /// the operation of the MPS kernels.
        ///
        /// 2) A result is returned from this method and the caller
        /// may further adjust the descriptor and kernel properties
        /// directly.
        ///
        /// 3) The caller uses the descriptor to make a new MPSImage to
        /// use as the destination image for the -encode call in step 5.
        ///
        /// 4) The caller calls -resultStateForSourceImage:sourceStates:destinationImage:
        /// to make any result states needed for the kernel. If there isn't
        /// one, it will return nil. A variant is available to return a
        /// temporary state instead.
        ///
        /// 5) a -encode method is called to encode the kernel.
        ///
        /// The entire process 1-5 is more simply achieved by just calling an -encode...
        /// method that returns a MPSImage out the left hand sid of the method. Simpler
        /// still, use the MPSNNGraph to coordinate the entire process from end to end.
        /// Opportunities to influence the process are of course reduced, as (2) is no longer
        /// possible with either method. Your application may opt to use the five step method
        /// if it requires greater customization as described, or if it would like to estimate
        /// storage in advance based on the sum of MPSImageDescriptors before processing
        /// a graph. Storage estimation is done by using the MPSImageDescriptor to create
        /// a MPSImage (without passing it a texture), and then call -resourceSize. As long
        /// as the MPSImage is not used in an encode call and the .texture property is not
        /// invoked, the underlying MTLTexture is not created.
        ///
        /// No destination state or destination image is provided as an argument to this
        /// function because it is expected they will be made / configured after this
        /// is called. This method is expected to auto-configure important object properties
        /// that may be needed in the ensuing destination image and state creation steps.
        ///
        ///
        /// Parameter `sourceImages`: A array of source images that will be passed into the -encode call
        /// Since MPSCNNBinaryKernel is a binary kernel, it is an array of length 2.
        ///
        /// Parameter `sourceStates`: An optional array of source states that will be passed into the -encode call
        ///
        /// Returns: an image descriptor allocated on the autorelease pool
        #[unsafe(method(destinationImageDescriptorForSourceImages:sourceStates:))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageDescriptorForSourceImages_sourceStates(
            &self,
            source_images: &NSArray<MPSImage>,
            source_states: Option<&NSArray<MPSState>>,
        ) -> Retained<MPSImageDescriptor>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// The size of extra MPS heap storage allocated while the kernel is encoding
        ///
        /// This is best effort and just describes things that are likely to end up on the MPS heap. It does not
        /// describe all allocation done by the -encode call.  It is intended for use with high water calculations
        /// for MTLHeap sizing. Allocations are typically for temporary storage needed for multipass algorithms.
        /// This interface should not be used to detect multipass algorithms.
        #[unsafe(method(encodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodingStorageSizeForPrimaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            primary_image: &MPSImage,
            secondary_image: &MPSImage,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: Option<&MPSImage>,
        ) -> NSUInteger;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// The size of extra MPS heap storage allocated while the kernel is encoding a batch
        ///
        /// This is best effort and just describes things that are likely to end up on the MPS heap. It does not
        /// describe all allocation done by the -encode call.  It is intended for use with high water calculations
        /// for MTLHeap sizing. Allocations are typically for temporary storage needed for multipass algorithms.
        /// This interface should not be used to detect multipass algorithms.
        #[unsafe(method(batchEncodingStorageSizeForPrimaryImage:secondaryImage:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn batchEncodingStorageSizeForPrimaryImage_secondaryImage_sourceStates_destinationImage(
            &self,
            primary_image: &MPSImageBatch,
            secondary_image: &MPSImageBatch,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: Option<&MPSImageBatch>,
        ) -> NSUInteger;
    );
}

/// Methods declared on superclass `MPSKernel`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNBinaryKernel {
    extern_methods!(
        /// Called by NSCoder to decode MPSKernels
        ///
        /// This isn't the right interface to decode a MPSKernel, but
        /// it is the one that NSCoder uses. To enable your NSCoder
        /// (e.g. NSKeyedUnarchiver) to set which device to use
        /// extend the object to adopt the MPSDeviceProvider
        /// protocol. Otherwise, the Metal system default device
        /// will be used.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
        ) -> Option<Retained<Self>>;
    );
}

/// Methods declared on superclass `NSObject`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNBinaryKernel {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// Gradient kernels are the backwards pass of a MPSCNNKernel
    /// used during training to calculate gradient back propagation.
    /// These take as arguments the gradient result from the next filter
    /// and the source image for the forward version of the filter.
    /// There is also a MPSNNGradientState passed from MPSCNNKernel
    /// to MPSCNNGradientKernel that contains information about the
    /// MPSCNNKernel parameters at the time it encoded and possibly
    /// also additional MTLResources to enable it to do its job.
    ///
    /// ```text
    ///           Training graph (partial):
    ///
    ///               ---> input image ---------> MPSCNNKernel ------>  resultImage ------>-->-->-->.
    ///                              \                  |                                           |
    ///                               '------.    MPSNNGradientState                         loss estimation
    ///                                       \         |                                           |
    ///                                        V        V                                           V
    ///               <--- result gradient <- MPSCNNGradientKernel <---  input gradient <--<--<--<---'
    ///
    ///               In general operation, starting with the input image, the sequence of events is:
    ///               1a)  Invoke padding policy to find result size for MPSCNNKernel.  This
    ///                    also configures some MPSCNNKernel parameters such as offset.
    ///               1b)  Use the MPSImageDescriptor from 1a to make resultImage.
    ///               1c)  Call MPSCNNKernel -encode...
    ///               2) stages 1a-c are repeated for other forward passes in the inference portion of the graph
    ///               3) We estimate the loss resulting from the whole inference computation so far (see MPSCNNLoss.h>
    ///               4) stages 5a-c are repeated for corresponding backward gradient passes in the graph
    ///               5a) Invoke padding policy on the MPSCNNGradientKernel shown above. This sets the
    ///                   MPSCNNGradientKernel parameters to correspond with those in the forward pass
    ///               5b) The result gradient for the MPSCNNGradientKernel is created from the MPSImageDescriptor from 5a
    ///               5c) Call MPSCNNGradientKernel -encode with the input image, input gradient, result gradient and MPSNNGradientState
    ///               6) pass the result gradient on to leftward gradient passes.
    /// ```
    ///
    /// For MPSCNNKernels that are trained, there may be other accompanying training kernels that
    /// need to be called in addition to the gradient kernel to update convolution weights or batch
    /// normalization parameters, for example. Steps 1a-c and 5a-c can be combined in a single -encode
    /// call. These return the result image or gradient out the left hand side.
    ///
    /// For purposes of inheritance the gradient image is the MPSCNNBinaryKernel primary image
    /// and the source image is the MPSCNNBinaryKernel secondary image. Various secondary properties
    /// such as kernel size are copies of the forward inference pass parameters of similar name
    /// are set automatically when -[MPSCNNGradientKernel destinationImageDescriptorForSourceImages:sourceStates:]
    /// is called.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/metalperformanceshaders/mpscnngradientkernel?language=objc)
    #[unsafe(super(MPSCNNBinaryKernel, MPSKernel, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
    pub struct MPSCNNGradientKernel;
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCoding for MPSCNNGradientKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCopying for MPSCNNGradientKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
unsafe impl CopyingHelper for MPSCNNGradientKernel {
    type Result = Self;
}

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSObjectProtocol for MPSCNNGradientKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSSecureCoding for MPSCNNGradientKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNGradientKernel {
    extern_methods!(
        /// Standard init with default properties per filter type
        ///
        /// Parameter `device`: The device that the filter will be used on. May not be NULL.
        ///
        /// Returns: A pointer to the newly initialized object. This will fail, returning
        /// nil if the device is not supported. Devices must be
        /// MTLFeatureSet_iOS_GPUFamily2_v1 or later.
        #[unsafe(method(initWithDevice:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice(
            this: Allocated<Self>,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Retained<Self>;

        /// NSSecureCoding compatability
        ///
        /// While the standard NSSecureCoding/NSCoding method
        /// -initWithCoder: should work, since the file can't
        /// know which device your data is allocated on, we
        /// have to guess and may guess incorrectly.  To avoid
        /// that problem, use initWithCoder:device instead.
        ///
        /// Parameter `aDecoder`: The NSCoder subclass with your serialized MPSKernel
        ///
        /// Parameter `device`: The MTLDevice on which to make the MPSKernel
        ///
        /// Returns: A new MPSKernel object, or nil if failure.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:device:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder_device(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Option<Retained<Self>>;

        /// Offset in the kernel reference frame to position the kernel in the X dimension
        ///
        /// In some cases, the input gradient must be upsampled with zero insertion
        /// to account for things like strides in the forward MPSCNNKernel pass.
        /// As such, the offset, which describes a X,Y offset in the source coordinate
        /// space is insufficient to fully describe the offset applied to a kernel.
        /// The kernel offset is the offset after upsampling. Both the source offset
        /// and kernel offset are additive:  effective offset = source offset * stride + kernel offset.
        /// The offset is applied to the (upsampled) source gradient
        #[unsafe(method(kernelOffsetX))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelOffsetX(&self) -> NSInteger;

        /// Setter for [`kernelOffsetX`][Self::kernelOffsetX].
        #[unsafe(method(setKernelOffsetX:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setKernelOffsetX(&self, kernel_offset_x: NSInteger);

        /// Offset in the kernel reference frame to position the kernel in the Y dimension
        ///
        /// In some cases, the input gradient must be upsampled with zero insertion
        /// to account for things like strides in the forward MPSCNNKernel pass.
        /// As such, the offset, which describes a X,Y offset in the source coordinate
        /// space is insufficient to fully describe the offset applied to a kernel.
        /// The kernel offset is the offset after upsampling. Both the source offset
        /// and kernel offset are additive:  effective offset = source offset * stride + kernel offset.
        /// The offset is applied to the (upsampled) source gradient
        #[unsafe(method(kernelOffsetY))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelOffsetY(&self) -> NSInteger;

        /// Setter for [`kernelOffsetY`][Self::kernelOffsetY].
        #[unsafe(method(setKernelOffsetY:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setKernelOffsetY(&self, kernel_offset_y: NSInteger);

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a gradient filter and return a gradient
        ///
        /// During training, gradient filters are used to calculate the gradient
        /// associated with the loss for each feature channel in the forward pass
        /// source image. For those nodes that are trainable, these are then used
        /// to refine the value used in the trainable parameter. They consume
        /// a source gradient image which contains the gradients corresponding
        /// with the forward pass destination image, and calculate the gradients
        /// corresponding to the forward pass source image.
        ///
        /// A gradient filter consumes a MPSNNGradientState object which captured
        /// various forward pass properties such as offset and edgeMode at the time
        /// the forward pass was encoded. These are transferred to the MPSCNNBinaryKernel
        /// secondary image properties automatically when this method creates its
        /// destination image.
        ///
        ///
        /// Parameter `commandBuffer`: The MTLCommandBuffer on which to encode
        ///
        /// Parameter `sourceGradient`: The gradient image from the "next" filter in the graph (in the inference direction)
        ///
        /// Parameter `sourceImage`: The image used as source image by the forward inference pass
        ///
        /// Parameter `gradientState`: The MPSNNGradientState or MPSNNBinaryGradientState subclass produced by the forward
        /// inference pass
        ///
        /// Returns: The result gradient from the gradient filter
        #[unsafe(method(encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceGradient_sourceImage_gradientState(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_gradient: &MPSImage,
            source_image: &MPSImage,
            gradient_state: &MPSState,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a gradient filter and return a gradient
        ///
        /// During training, gradient filters are used to calculate the gradient
        /// associated with the loss for each feature channel in the forward pass
        /// source image. For those nodes that are trainable, these are then used
        /// to refine the value used in the trainable parameter. They consume
        /// a source gradient image which contains the gradients corresponding
        /// with the forward pass destination image, and calculate the gradients
        /// corresponding to the forward pass source image.
        ///
        /// A gradient filter consumes a MPSNNGradientState object which captured
        /// various forward pass properties such as offset and edgeMode at the time
        /// the forward pass was encoded. These are transferred to the MPSCNNBinaryKernel
        /// secondary image properties automatically when you use -[MPSCNNGradientKernel
        /// destinationImageDescriptorForSourceImages:sourceStates:]. If you do not call
        /// this method, then you are responsible for configuring all of the primary and
        /// secondary image properties in MPSCNNBinaryKernel. Please see class description
        /// for expected ordering of operations.
        ///
        ///
        /// Parameter `commandBuffer`: The MTLCommandBuffer on which to encode
        ///
        /// Parameter `sourceGradient`: The gradient image from the "next" filter in the graph
        ///
        /// Parameter `sourceImage`: The image used as source image from the forward pass
        ///
        /// Parameter `gradientState`: The MPSNNGradientState and MPSNNBinaryGradientState subclass produced by the
        /// forward pass
        ///
        /// Parameter `destinationGradient`: The MPSImage into which to write the filter result
        #[unsafe(method(encodeToCommandBuffer:sourceGradient:sourceImage:gradientState:destinationGradient:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceGradient_sourceImage_gradientState_destinationGradient(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_gradient: &MPSImage,
            source_image: &MPSImage,
            gradient_state: &MPSState,
            destination_gradient: &MPSImage,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a gradient filter and return a gradient
        ///
        /// During training, gradient filters are used to calculate the gradient
        /// associated with the loss for each feature channel in the forward pass
        /// source image. For those nodes that are trainable, these are then used
        /// to refine the value used in the trainable parameter. They consume
        /// a source gradient image which contains the gradients corresponding
        /// with the forward pass destination image, and calculate the gradients
        /// corresponding to the forward pass source image.
        ///
        /// A gradient filter consumes a MPSNNGradientState object which captured
        /// various forward pass properties such as offset and edgeMode at the time
        /// the forward pass was encoded. These are transferred to the MPSCNNBinaryKernel
        /// secondary image properties automatically when this method creates its
        /// destination image.
        ///
        /// Parameter `commandBuffer`: The MTLCommandBuffer on which to encode
        ///
        /// Parameter `sourceGradients`: The gradient images from the "next" filter in the graph
        ///
        /// Parameter `sourceImages`: The images used as source image from the forward pass
        ///
        /// Parameter `gradientStates`: The MPSNNGradientState or MPSNNBinaryGradientState subclass produced by the
        /// forward pass
        #[unsafe(method(encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceGradients_sourceImages_gradientStates(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_gradients: &MPSImageBatch,
            source_images: &MPSImageBatch,
            gradient_states: &MPSStateBatch,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a gradient filter and return a gradient
        ///
        /// During training, gradient filters are used to calculate the gradient
        /// associated with the loss for each feature channel in the forward pass
        /// source image. For those nodes that are trainable, these are then used
        /// to refine the value used in the trainable parameter. They consume
        /// a source gradient image which contains the gradients corresponding
        /// with the forward pass destination image, and calculate the gradients
        /// corresponding to the forward pass source image.
        ///
        /// A gradient filter consumes a MPSNNGradientState object which captured
        /// various forward pass properties such as offset and edgeMode at the time
        /// the forward pass was encoded. These are transferred to the MPSCNNBinaryKernel
        /// secondary image properties automatically when you use -[MPSCNNGradientKernel
        /// destinationImageDescriptorForSourceImages:sourceStates:]. If you do not call
        /// this method, then you are responsible for configuring all of the primary and
        /// secondary image properties in MPSCNNBinaryKernel. Please see class description
        /// for expected ordering of operations.
        ///
        /// Parameter `commandBuffer`: The MTLCommandBuffer on which to encode
        ///
        /// Parameter `sourceGradients`: The gradient images from the "next" filter in the graph
        ///
        /// Parameter `sourceImages`: The image used as source images from the forward pass
        ///
        /// Parameter `gradientStates`: An array of the MPSNNGradientState or MPSNNBinaryGradientState subclass
        /// produced by the forward pass
        ///
        /// Parameter `destinationGradients`: The MPSImages into which to write the filter result
        #[unsafe(method(encodeBatchToCommandBuffer:sourceGradients:sourceImages:gradientStates:destinationGradients:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceGradients_sourceImages_gradientStates_destinationGradients(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_gradients: &MPSImageBatch,
            source_images: &MPSImageBatch,
            gradient_states: &MPSStateBatch,
            destination_gradients: &MPSImageBatch,
        );
    );
}

/// Methods declared on superclass `MPSKernel`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNGradientKernel {
    extern_methods!(
        /// Called by NSCoder to decode MPSKernels
        ///
        /// This isn't the right interface to decode a MPSKernel, but
        /// it is the one that NSCoder uses. To enable your NSCoder
        /// (e.g. NSKeyedUnarchiver) to set which device to use
        /// extend the object to adopt the MPSDeviceProvider
        /// protocol. Otherwise, the Metal system default device
        /// will be used.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
        ) -> Option<Retained<Self>>;
    );
}

/// Methods declared on superclass `NSObject`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNGradientKernel {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// Dependencies: This depends on Metal.framework
    ///
    /// Describes a  neural network kernel with multiple image sources.
    ///
    /// A MPSCNNKernel consumes multiple MPSImages, possibly a MPSState, and produces one MPSImage.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/metalperformanceshaders/mpscnnmultiarykernel?language=objc)
    #[unsafe(super(MPSKernel, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
    pub struct MPSCNNMultiaryKernel;
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCoding for MPSCNNMultiaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSCopying for MPSCNNMultiaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
unsafe impl CopyingHelper for MPSCNNMultiaryKernel {
    type Result = Self;
}

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSObjectProtocol for MPSCNNMultiaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
extern_conformance!(
    unsafe impl NSSecureCoding for MPSCNNMultiaryKernel {}
);

#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNMultiaryKernel {
    extern_methods!(
        /// Standard init with default properties per filter type
        ///
        /// Parameter `device`: The device that the filter will be used on. May not be NULL.
        ///
        /// Parameter `sourceCount`: The number of source images or MPSImageBatches
        ///
        /// Returns: A pointer to the newly initialized object. This will fail, returning
        /// nil if the device is not supported. Devices must be
        /// MTLFeatureSet_iOS_GPUFamily2_v1 or later.
        #[unsafe(method(initWithDevice:sourceCount:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice_sourceCount(
            this: Allocated<Self>,
            device: &ProtocolObject<dyn MTLDevice>,
            source_count: NSUInteger,
        ) -> Retained<Self>;

        // -initWithDevice: (unavailable)

        /// The number of source images accepted by the kernel
        #[unsafe(method(sourceCount))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceCount(&self) -> NSUInteger;

        /// An optional clip rectangle to use when writing data. Only the pixels in the rectangle will be overwritten.
        ///
        /// A MTLRegion that indicates which part of the destination to overwrite. If the clipRect does not lie
        /// completely within the destination image, the intersection between clip rectangle and destination bounds is
        /// used.   Default: MPSRectNoClip (MPSKernel::MPSRectNoClip) indicating the entire image.
        /// clipRect.origin.z is the index of starting destination image in batch processing mode. clipRect.size.depth
        /// is the number of images to process in batch processing mode.
        ///
        /// See Also:
        /// subsubsection_clipRect
        #[unsafe(method(clipRect))]
        #[unsafe(method_family = none)]
        pub unsafe fn clipRect(&self) -> MTLRegion;

        /// Setter for [`clipRect`][Self::clipRect].
        #[unsafe(method(setClipRect:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setClipRect(&self, clip_rect: MTLRegion);

        /// The number of channels in the destination MPSImage to skip before writing output.
        ///
        /// This is the starting offset into the destination image in the feature channel dimension
        /// at which destination data is written.
        /// This allows an application to pass a subset of all the channels in MPSImage as output of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel outputs 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as output, we can set destinationFeatureChannelOffset = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel outputs N channels,
        /// destination image MUST have at least destinationFeatureChannelOffset + N channels. Using a destination
        /// image with insufficient number of feature channels result in an error.
        /// E.g. if the MPSCNNConvolution outputs 32 channels, and destination has 64 channels, then it is an error to set
        /// destinationFeatureChannelOffset > 32.
        #[unsafe(method(destinationFeatureChannelOffset))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationFeatureChannelOffset(&self) -> NSUInteger;

        /// Setter for [`destinationFeatureChannelOffset`][Self::destinationFeatureChannelOffset].
        #[unsafe(method(setDestinationFeatureChannelOffset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationFeatureChannelOffset(
            &self,
            destination_feature_channel_offset: NSUInteger,
        );

        /// YES if the filter operates backwards.
        ///
        /// This influences how strideInPixelsX/Y should be interpreted.
        #[unsafe(method(isBackwards))]
        #[unsafe(method_family = none)]
        pub unsafe fn isBackwards(&self) -> bool;

        /// Returns true if the -encode call modifies the state object it accepts.
        #[unsafe(method(isStateModified))]
        #[unsafe(method_family = none)]
        pub unsafe fn isStateModified(&self) -> bool;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// The padding method used by the filter
        ///
        /// This influences how strideInPixelsX/Y should be interpreted.
        /// Default:  MPSNNPaddingMethodAlignCentered | MPSNNPaddingMethodAddRemainderToTopLeft | MPSNNPaddingMethodSizeSame
        /// Some object types (e.g. MPSCNNFullyConnected) may override this default with something appropriate to its operation.
        #[unsafe(method(padding))]
        #[unsafe(method_family = none)]
        pub unsafe fn padding(&self) -> Retained<ProtocolObject<dyn MPSNNPadding>>;

        #[cfg(feature = "MPSNeuralNetworkTypes")]
        /// Setter for [`padding`][Self::padding].
        #[unsafe(method(setPadding:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPadding(&self, padding: &ProtocolObject<dyn MPSNNPadding>);

        #[cfg(feature = "MPSImage")]
        /// Method to allocate the result image for -encodeToCommandBuffer:sourceImage:
        ///
        /// Default: MPSTemporaryImage.defaultAllocator
        #[unsafe(method(destinationImageAllocator))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageAllocator(
            &self,
        ) -> Retained<ProtocolObject<dyn MPSImageAllocator>>;

        #[cfg(feature = "MPSImage")]
        /// Setter for [`destinationImageAllocator`][Self::destinationImageAllocator].
        #[unsafe(method(setDestinationImageAllocator:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDestinationImageAllocator(
            &self,
            destination_image_allocator: &ProtocolObject<dyn MPSImageAllocator>,
        );

        #[cfg(feature = "MPSCoreTypes")]
        /// The positon of the destination clip rectangle origin relative to each source buffer
        ///
        /// The offset is defined to be the position of clipRect.origin in source coordinates.
        /// Default: {0,0,0}, indicating that the top left corners of the clipRect and source image align.
        /// offset.z is the index of starting source image in batch processing mode.
        ///
        /// Parameter `index`: The index of the source image described by the offset
        ///
        /// Returns: A MPSOffset for that image
        #[unsafe(method(offsetAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn offsetAtIndex(&self, index: NSUInteger) -> MPSOffset;

        #[cfg(feature = "MPSCoreTypes")]
        /// Set the positon of the destination clip rectangle origin relative to each source buffer
        ///
        /// The offset is defined to be the position of clipRect.origin in source coordinates.
        /// Default: {0,0,0}, indicating that the top left corners of the clipRect and source image align.
        /// offset.z is the index of starting source image in batch processing mode.
        ///
        /// Parameter `offset`: The new offset
        ///
        /// Parameter `index`: The index of the source image described by the offset
        #[unsafe(method(setOffset:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setOffset_atIndex(&self, offset: MPSOffset, index: NSUInteger);

        /// The number of channels in the source MPSImage to skip before reading the input.
        ///
        /// This is the starting offset into the  source image in the feature channel dimension
        /// at which source data is read. Unit: feature channels
        /// This allows an application to read a subset of all the channels in MPSImage as input of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel needs to read 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as input, we can set sourceFeatureChannelOffset[0] = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel inputs N channels,
        /// the source image MUST have at least primarySourceFeatureChannelOffset + N channels. Using a source
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution inputs 32 channels, and the source has 64 channels, then it is an error to set
        /// primarySourceFeatureChannelOffset > 32.
        ///
        /// Parameter `index`: The index of the source image that the feature channel offset describes
        ///
        /// Returns: The source feature channel offset
        #[unsafe(method(sourceFeatureChannelOffsetAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFeatureChannelOffsetAtIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the number of channels in the source MPSImage to skip before reading the input.
        ///
        /// This is the starting offset into the  source image in the feature channel dimension
        /// at which source data is read. Unit: feature channels
        /// This allows an application to read a subset of all the channels in MPSImage as input of MPSKernel.
        /// E.g. Suppose MPSImage has 24 channels and a MPSKernel needs to read 8 channels. If
        /// we want channels 8 to 15 of this MPSImage to be used as input, we can set sourceFeatureChannelOffset[0] = 8.
        /// Note that this offset applies independently to each image when the MPSImage
        /// is a container for multiple images and the MPSCNNKernel is processing multiple images (clipRect.size.depth > 1).
        /// The default value is 0 and any value specifed shall be a multiple of 4. If MPSKernel inputs N channels,
        /// the source image MUST have at least primarySourceFeatureChannelOffset + N channels. Using a source
        /// image with insufficient number of feature channels will result in an error.
        /// E.g. if the MPSCNNConvolution inputs 32 channels, and the source has 64 channels, then it is an error to set
        /// primarySourceFeatureChannelOffset > 32.
        ///
        /// Parameter `index`: The index of the source image that the feature channel offset describes
        ///
        /// Parameter `offset`: The source feature channel offset
        #[unsafe(method(setSourceFeatureChannelOffset:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceFeatureChannelOffset_atIndex(
            &self,
            offset: NSUInteger,
            index: NSUInteger,
        );

        /// The maximum number of channels in the source MPSImage to use
        ///
        /// Most filters can insert a slice operation into the filter for free.
        /// Use this to limit the size of the feature channel slice taken from
        /// the input image. If the value is too large, it is truncated to be
        /// the remaining size in the image after the sourceFeatureChannelOffset
        /// is taken into account.  Default: ULONG_MAX
        ///
        /// Parameter `index`: The index of the source image to which the max count refers
        ///
        /// Returns: The source feature channel max count
        #[unsafe(method(sourceFeatureChannelMaxCountAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFeatureChannelMaxCountAtIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the maximum number of channels in the source MPSImage to use
        ///
        /// Most filters can insert a slice operation into the filter for free.
        /// Use this to limit the size of the feature channel slice taken from
        /// the input image. If the value is too large, it is truncated to be
        /// the remaining size in the image after the sourceFeatureChannelOffset
        /// is taken into account.  Default: ULONG_MAX
        ///
        /// Parameter `count`: The new source feature channel max count
        ///
        /// Parameter `index`: The index of the source image to which the max count refers
        #[unsafe(method(setSourceFeatureChannelMaxCount:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceFeatureChannelMaxCount_atIndex(
            &self,
            count: NSUInteger,
            index: NSUInteger,
        );

        #[cfg(feature = "MPSCoreTypes")]
        /// The MPSImageEdgeMode to use when texture reads stray off the edge of the primary source image
        ///
        /// Most MPSKernel objects can read off the edge of the source image. This can happen
        /// because of a negative offset property, because the offset + clipRect.size is larger
        /// than the source image or because the filter looks at neighboring pixels, such as a
        /// Convolution filter.   Default:  MPSImageEdgeModeZero.
        ///
        /// See Also:
        /// subsubsection_edgemode
        /// Parameter `index`: The index of the source image to which the edge mode refers
        ///
        /// Returns: The edge mode for that source image
        #[unsafe(method(edgeModeAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn edgeModeAtIndex(&self, index: NSUInteger) -> MPSImageEdgeMode;

        #[cfg(feature = "MPSCoreTypes")]
        /// Set the MPSImageEdgeMode to use when texture reads stray off the edge of the primary source image
        ///
        /// Most MPSKernel objects can read off the edge of the source image. This can happen
        /// because of a negative offset property, because the offset + clipRect.size is larger
        /// than the source image or because the filter looks at neighboring pixels, such as a
        /// Convolution filter.   Default:  MPSImageEdgeModeZero.
        ///
        /// See Also:
        /// subsubsection_edgemode
        /// Parameter `edgeMode`: The new edge mode to use
        ///
        /// Parameter `index`: The index of the source image to which the edge mode refers
        #[unsafe(method(setEdgeMode:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setEdgeMode_atIndex(&self, edge_mode: MPSImageEdgeMode, index: NSUInteger);

        /// The width of the kernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Parameter `index`: The index of the source image to which the kernel width refers
        #[unsafe(method(kernelWidthAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelWidthAtIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the width of the kernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Parameter `width`: The new width
        ///
        /// Parameter `index`: The index of the source image to which the kernel width refers
        #[unsafe(method(setKernelWidth:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setKernelWidth_atIndex(&self, width: NSUInteger, index: NSUInteger);

        /// The height of the kernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Parameter `index`: The index of the source image to which the kernel width refers
        #[unsafe(method(kernelHeightAtIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn kernelHeightAtIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the height of the kernel filter window
        ///
        /// This is the horizontal diameter of the region read by the filter for each
        /// result pixel. If the MPSCNNKernel does not have a filter window, then
        /// 1 will be returned.
        ///
        /// Parameter `height`: The new width
        ///
        /// Parameter `index`: The index of the source image to which the kernel width refers
        #[unsafe(method(setKernelHeight:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setKernelHeight_atIndex(&self, height: NSUInteger, index: NSUInteger);

        /// The downsampling factor in the horizontal dimension for the source image
        ///
        /// Parameter `index`: The index of the source Image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        ///
        /// Returns: The stride
        #[unsafe(method(strideInPixelsXatIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn strideInPixelsXatIndex(&self, index: NSUInteger) -> NSUInteger;

        /// The downsampling factor in the horizontal dimension for the source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.  Default: 1
        ///
        /// Parameter `index`: The index of the source Image
        ///
        /// Parameter `stride`: The stride for the source image
        #[unsafe(method(setStrideInPixelsX:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setStrideInPixelsX_atIndex(&self, stride: NSUInteger, index: NSUInteger);

        /// The downsampling factor in the vertical dimension for the source image
        ///
        /// Parameter `index`: The index of the source Image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.
        ///
        /// Returns: The stride
        #[unsafe(method(strideInPixelsYatIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn strideInPixelsYatIndex(&self, index: NSUInteger) -> NSUInteger;

        /// The downsampling factor in the vertical dimension for the source image
        ///
        /// If the filter does not do up or downsampling, 1 is returned.  Default: 1
        ///
        /// Parameter `index`: The index of the source Image
        ///
        /// Parameter `stride`: The stride for the source image
        #[unsafe(method(setStrideInPixelsY:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setStrideInPixelsY_atIndex(&self, stride: NSUInteger, index: NSUInteger);

        /// Stride in source coordinates from one kernel tap to the next in the X dimension.
        ///
        /// Parameter `index`: The index of the source image to which the dilation rate applies
        ///
        /// Returns: The dilation rate
        #[unsafe(method(dilationRateXatIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn dilationRateXatIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the stride in source coordinates from one kernel tap to the next in the X dimension.
        ///
        /// Parameter `index`: The index of the source image to which the dilation rate applies
        ///
        /// Parameter `dilationRate`: The dilation rate
        #[unsafe(method(setDilationRateX:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDilationRateX_atIndex(&self, dilation_rate: NSUInteger, index: NSUInteger);

        /// Stride in source coordinates from one kernel tap to the next in the Y dimension.
        ///
        /// Parameter `index`: The index of the source image to which the dilation rate applies
        ///
        /// Returns: The dilation rate
        #[unsafe(method(dilationRateYatIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn dilationRateYatIndex(&self, index: NSUInteger) -> NSUInteger;

        /// Set the stride in source coordinates from one kernel tap to the next in the Y dimension.
        ///
        /// Parameter `index`: The index of the source image to which the dilation rate applies
        ///
        /// Parameter `dilationRate`: The dilation rate
        #[unsafe(method(setDilationRateY:atIndex:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDilationRateY_atIndex(&self, dilation_rate: NSUInteger, index: NSUInteger);

        /// NSSecureCoding compatability
        ///
        /// While the standard NSSecureCoding/NSCoding method
        /// -initWithCoder: should work, since the file can't
        /// know which device your data is allocated on, we
        /// have to guess and may guess incorrectly.  To avoid
        /// that problem, use initWithCoder:device instead.
        ///
        /// Parameter `aDecoder`: The NSCoder subclass with your serialized MPSKernel
        ///
        /// Parameter `device`: The MTLDevice on which to make the MPSKernel
        ///
        /// Returns: A new MPSKernel object, or nil if failure.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:device:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder_device(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
            device: &ProtocolObject<dyn MTLDevice>,
        ) -> Option<Retained<Self>>;

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImages`: An array containing the source images
        ///
        /// Parameter `destinationImage`: A valid MPSImage to be overwritten by result image. destinationImage may not alias primarySourceImage or secondarySourceImage.
        #[unsafe(method(encodeToCommandBuffer:sourceImages:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImages_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &NSArray<MPSImage>,
            destination_image: &MPSImage,
        );

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer.  The operation shall proceed out-of-place.
        ///
        /// This is the older style of encode which reads the offset, doesn't change it,
        /// and ignores the padding method. Multiple images are processed concurrently.
        /// All images must have MPSImage.numberOfImages = 1.
        ///
        /// Parameter `commandBuffer`: A valid MTLCommandBuffer to receive the encoded filter
        ///
        /// Parameter `sourceImages`: An array of image batches containing the source images.
        ///
        /// Parameter `destinationImages`: An array of MPSImage objects to contain the result images.
        /// destinationImages may not alias primarySourceImages or secondarySourceImages
        /// in any manner.
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:destinationImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages_destinationImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &NSArray<MPSImageBatch>,
            destination_images: &MPSImageBatch,
        );

        #[cfg(feature = "MPSImage")]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture to hold the result and return it.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property.  See discussion in MPSNeuralNetworkTypes.h.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImages`: An array of MPSImages to use as the source images for the filter.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:sourceImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &NSArray<MPSImage>,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create textures to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeBatchToCommandBuffer:sourceImage:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property.  See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImageBatches`: An array of image batches to use as the source images for the filter.
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image_batches: &NSArray<MPSImageBatch>,
        ) -> Retained<MPSImageBatch>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture and state to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImages`: An array of MPSImages to use as the source images for the filter.
        ///
        /// Parameter `outState`: The address of location to write the pointer to the result state of the operation
        ///
        /// Parameter `isTemporary`: YES if the outState should be a temporary object
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeToCommandBuffer:sourceImages:destinationState:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeToCommandBuffer_sourceImages_destinationState_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_images: &NSArray<MPSImage>,
            out_state: &mut Option<Retained<MPSState>>,
            is_temporary: bool,
        ) -> Retained<MPSImage>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        /// Encode a MPSCNNKernel into a command Buffer. Create a texture and state to hold the results and return them.
        ///
        /// In the first iteration on this method, encodeToCommandBuffer:sourceImage:destinationState:destinationImage:
        /// some work was left for the developer to do in the form of correctly setting the offset property
        /// and sizing the result buffer. With the introduction of the padding policy (see padding property)
        /// the filter can do this work itself. If you would like to have some input into what sort of MPSImage
        /// (e.g. temporary vs. regular) or what size it is or where it is allocated, you may set the
        /// destinationImageAllocator to allocate the image yourself.
        ///
        /// This method uses the MPSNNPadding padding property to figure out how to size
        /// the result image and to set the offset property. See discussion in MPSNeuralNetworkTypes.h.
        /// All images in a batch must have MPSImage.numberOfImages = 1.
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer
        ///
        /// Parameter `sourceImageBatches`: An array of batches to use as the source images for the filter.
        ///
        /// Parameter `outState`: A new state object is returned here.
        ///
        /// Parameter `isTemporary`: YES if the outState should be a temporary object
        ///
        /// Returns: A MPSImage or MPSTemporaryImage allocated per the destinationImageAllocator containing the output of the graph.
        /// The offset property will be adjusted to reflect the offset used during the encode.
        /// The returned image will be automatically released when the command buffer completes. If you want to
        /// keep it around for longer, retain the image. (ARC will do this for you if you use it later.)
        #[unsafe(method(encodeBatchToCommandBuffer:sourceImages:destinationStates:destinationStateIsTemporary:))]
        #[unsafe(method_family = none)]
        pub unsafe fn encodeBatchToCommandBuffer_sourceImages_destinationStates_destinationStateIsTemporary(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image_batches: &NSArray<MPSImageBatch>,
            out_state: &mut Option<Retained<MPSStateBatch>>,
            is_temporary: bool,
        ) -> Retained<MPSImageBatch>;

        /// Returns YES if the same state is used for every operation in a batch
        ///
        /// If NO, then each image in a MPSImageBatch will need a corresponding
        /// (and different) state to go with it. Set to YES to avoid allocating
        /// redundant state in the case when the same state is used all the time.
        /// Default: NO
        #[unsafe(method(isResultStateReusedAcrossBatch))]
        #[unsafe(method_family = none)]
        pub unsafe fn isResultStateReusedAcrossBatch(&self) -> bool;

        /// Returns YES if the filter must be run over the entire batch before its
        /// results may be used
        ///
        /// Nearly all filters do not need to see the entire batch all at once and can
        /// operate correctly with partial batches. This allows the graph to
        /// strip-mine the problem, processing the graph top to bottom on a subset
        /// of the batch at a time, dramatically reducing memory usage. As the full
        /// nominal working set for a graph is often so large that it may not fit
        /// in memory, sub-batching may be required forward progress.
        ///
        /// Batch normalization statistics on the other hand must complete the batch
        /// before the statistics may be used to normalize the images in the batch
        /// in the ensuing normalization filter. Consequently, batch normalization statistics
        /// requests the graph insert a batch barrier following it by returning
        /// YES from -appendBatchBarrier. This tells the graph to complete the batch
        /// before any dependent filters can start. Note that the filter itself may
        /// still be subject to sub-batching in its operation. All filters must be able to
        /// function without seeing the entire batch in a single -encode call. Carry
        /// over state that is accumulated across sub-batches is commonly carried in
        /// a shared MPSState containing a MTLBuffer. See -isResultStateReusedAcrossBatch.
        ///
        /// Caution: on most supported devices, the working set may be so large
        /// that the graph may be forced to throw away and recalculate most
        /// intermediate images in cases where strip-mining can not occur because
        /// -appendBatchBarrier returns YES. A single batch barrier can commonly
        /// cause a memory size increase and/or performance reduction by many fold
        /// over the entire graph.  Filters of this variety should be avoided.
        ///
        /// Default: NO
        #[unsafe(method(appendBatchBarrier))]
        #[unsafe(method_family = none)]
        pub unsafe fn appendBatchBarrier(&self) -> bool;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate any MPSState objects that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the source image.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION:
        /// The kernel must have all properties set to values that will ultimately be
        /// passed to the -encode call that writes to the state, before
        /// -resultStateForSourceImages:sourceStates:destinationImage: is called or behavior is undefined.
        /// Please note that -destinationImageDescriptorForSourceImages:sourceStates:
        /// will alter some of these properties automatically based on the padding policy.
        /// If you intend to call that to make the destination image, then you should
        /// call that before -resultStateForSourceImages:sourceStates:destinationImage:. This will ensure the
        /// properties used in the encode call and in the destination image creation
        /// match those used to configure the state.
        ///
        /// The following order is recommended:
        ///
        /// // Configure MPSCNNKernel properties first
        /// kernel.edgeMode = MPSImageEdgeModeZero;
        /// kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
        /// ...
        ///
        /// // ALERT: will change MPSCNNKernel properties
        /// MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
        /// sourceStates: states];
        /// MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
        /// imageDescriptor: d];
        ///
        /// // Now that all properties are configured properly, we can make the result state
        /// // and call encode.
        /// MPSState * __nullable destState = [kernel resultStateForSourceImage: source
        /// sourceStates: states
        /// destinationImage: dest];
        ///
        /// // This form of -encode will be declared by the MPSCNNKernel subclass
        /// [kernel encodeToCommandBuffer: cmdBuf
        /// sourceImage: source
        /// destinationState: destState
        /// destinationImage: dest ];
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `sourceImages`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Parameter `destinationImage`: The destination image for the encode call
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(resultStateForSourceImages:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateForSourceImages_sourceStates_destinationImage(
            &self,
            source_images: &NSArray<MPSImage>,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(resultStateBatchForSourceImages:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resultStateBatchForSourceImages_sourceStates_destinationImage(
            &self,
            source_images: &NSArray<MPSImageBatch>,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Allocate a temporary MPSState (subclass) to hold the results from a -encodeBatchToCommandBuffer... operation
        ///
        /// A graph may need to allocate storage up front before executing.  This may be
        /// necessary to avoid using too much memory and to manage large batches.  The function
        /// should allocate any MPSState objects that will be produced by an -encode call
        /// with the indicated sourceImages and sourceStates inputs. Though the states
        /// can be further adjusted in the ensuing -encode call, the states should
        /// be initialized with all important data and all MTLResource storage allocated.
        /// The data stored in the MTLResource need not be initialized, unless the ensuing
        /// -encode call expects it to be.
        ///
        /// The MTLDevice used by the result is derived from the command buffer.
        /// The padding policy will be applied to the filter before this is called
        /// to give it the chance to configure any properties like MPSCNNKernel.offset.
        ///
        /// CAUTION:
        /// The kernel must have all properties set to values that will ultimately be
        /// passed to the -encode call that writes to the state, before
        /// -resultStateForSourceImages:sourceStates:destinationImage: is called or behavior is undefined.
        /// Please note that -destinationImageDescriptorForSourceImages:sourceStates:destinationImage:
        /// will alter some of these properties automatically based on the padding policy.
        /// If you intend to call that to make the destination image, then you should
        /// call that before -resultStateForSourceImages:sourceStates:destinationImage:.  This will ensure the
        /// properties used in the encode call and in the destination image creation
        /// match those used to configure the state.
        ///
        /// The following order is recommended:
        ///
        /// // Configure MPSCNNKernel properties first
        /// kernel.edgeMode = MPSImageEdgeModeZero;
        /// kernel.destinationFeatureChannelOffset = 128; // concatenation without the copy
        /// ...
        ///
        /// // ALERT: will change MPSCNNKernel properties
        /// MPSImageDescriptor * d = [kernel destinationImageDescriptorForSourceImage: source
        /// sourceStates: states];
        /// MPSTemporaryImage * dest = [MPSTemporaryImage temporaryImageWithCommandBuffer: cmdBuf
        /// imageDescriptor: d];
        ///
        /// // Now that all properties are configured properly, we can make the result state
        /// // and call encode.
        /// MPSState * __nullable destState = [kernel temporaryResultStateForCommandBuffer: cmdBuf
        /// sourceImage: source
        /// sourceStates: states];
        ///
        /// // This form of -encode will be declared by the MPSCNNKernel subclass
        /// [kernel encodeToCommandBuffer: cmdBuf
        /// sourceImage: source
        /// destinationState: destState
        /// destinationImage: dest ];
        ///
        /// Default: returns nil
        ///
        ///
        /// Parameter `commandBuffer`: The command buffer to allocate the temporary storage against
        /// The state will only be valid on this command buffer.
        ///
        /// Parameter `sourceImage`: The MPSImage consumed by the associated -encode call.
        ///
        /// Parameter `sourceStates`: The list of MPSStates consumed by the associated -encode call,
        /// for a batch size of 1.
        ///
        /// Parameter `destinationImage`: The destination image for the encode call
        ///
        /// Returns: The list of states produced by the -encode call for batch size of 1.
        /// When the batch size is not 1, this function will be called repeatedly unless
        /// -isResultStateReusedAcrossBatch returns YES. If  -isResultStateReusedAcrossBatch
        /// returns YES, then it will be called once per batch and the MPSStateBatch array will
        /// contain MPSStateBatch.length references to the same object.
        #[unsafe(method(temporaryResultStateForCommandBuffer:sourceImages:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateForCommandBuffer_sourceImages_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &NSArray<MPSImage>,
            source_states: Option<&NSArray<MPSState>>,
            destination_image: &MPSImage,
        ) -> Option<Retained<MPSState>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSNDArray", feature = "MPSState"))]
        #[unsafe(method(temporaryResultStateBatchForCommandBuffer:sourceImages:sourceStates:destinationImage:))]
        #[unsafe(method_family = none)]
        pub unsafe fn temporaryResultStateBatchForCommandBuffer_sourceImages_sourceStates_destinationImage(
            &self,
            command_buffer: &ProtocolObject<dyn MTLCommandBuffer>,
            source_image: &NSArray<MPSImageBatch>,
            source_states: Option<&NSArray<MPSStateBatch>>,
            destination_image: &MPSImageBatch,
        ) -> Option<Retained<MPSStateBatch>>;

        #[cfg(all(feature = "MPSImage", feature = "MPSState"))]
        /// Get a suggested destination image descriptor for a source image
        ///
        /// Your application is certainly free to pass in any destinationImage
        /// it likes to encodeToCommandBuffer:sourceImage:destinationImage,
        /// within reason. This is the basic design for iOS 10. This method
        /// is therefore not required.
        ///
        /// However, calculating the MPSImage size and MPSCNNKernel properties
        /// for each filter can be tedious and complicated work, so this method
        /// is made available to automate the process. The application may
        /// modify the properties of the descriptor before a MPSImage is made from
        /// it, so long as the choice is sensible for the kernel in question.
        /// Please see individual kernel descriptions for restrictions.
        ///
        /// The expected timeline for use is as follows:
        ///
        /// 1) This method is called:
        /// a) The default MPS padding calculation is applied. It
        /// uses the MPSNNPaddingMethod of the .padding property to
        /// provide a consistent addressing scheme over the graph.
        /// It creates the MPSImageDescriptor and adjusts the .offset
        /// property of the MPSNNKernel. When using a MPSNNGraph, the
        /// padding is set using the MPSNNFilterNode as a proxy.
        ///
        /// b) This method may be overridden by MPSCNNKernel subclass
        /// to achieve any customization appropriate to the object type.
        ///
        /// c) Source states are then applied in order. These may modify the
        /// descriptor and may update other object properties. See:
        /// -destinationImageDescriptorForSourceImages:sourceStates:
        /// forKernel:suggestedDescriptor:  This is the typical way
        /// in which MPS may attempt to influence the operation of
        /// its kernels.
        ///
        /// d) If the .padding property has a custom padding policy method
        /// of the same name, it is called. Similarly, it may also adjust
        /// the descriptor and any MPSCNNKernel properties. This is the
        /// typical way in which your application may attempt to influence
        /// the operation of the MPS kernels.
        ///
        /// 2) A result is returned from this method and the caller
        /// may further adjust the descriptor and kernel properties
        /// directly.
        ///
        /// 3) The caller uses the descriptor to make a new MPSImage to
        /// use as the destination image for the -encode call in step 5.
        ///
        /// 4) The caller calls -resultStateForSourceImage:sourceStates:destinationImage:
        /// to make any result states needed for the kernel. If there isn't
        /// one, it will return nil. A variant is available to return a
        /// temporary state instead.
        ///
        /// 5) a -encode method is called to encode the kernel.
        ///
        /// The entire process 1-5 is more simply achieved by just calling an -encode...
        /// method that returns a MPSImage out the left hand sid of the method. Simpler
        /// still, use the MPSNNGraph to coordinate the entire process from end to end.
        /// Opportunities to influence the process are of course reduced, as (2) is no longer
        /// possible with either method. Your application may opt to use the five step method
        /// if it requires greater customization as described, or if it would like to estimate
        /// storage in advance based on the sum of MPSImageDescriptors before processing
        /// a graph. Storage estimation is done by using the MPSImageDescriptor to create
        /// a MPSImage (without passing it a texture), and then call -resourceSize. As long
        /// as the MPSImage is not used in an encode call and the .texture property is not
        /// invoked, the underlying MTLTexture is not created.
        ///
        /// No destination state or destination image is provided as an argument to this
        /// function because it is expected they will be made / configured after this
        /// is called. This method is expected to auto-configure important object properties
        /// that may be needed in the ensuing destination image and state creation steps.
        ///
        ///
        /// Parameter `sourceImages`: A array of source images that will be passed into the -encode call
        /// Since MPSCNNKernel is a unary kernel, it is an array of length 1.
        ///
        /// Parameter `sourceStates`: An optional array of source states that will be passed into the -encode call
        ///
        /// Returns: an image descriptor allocated on the autorelease pool
        #[unsafe(method(destinationImageDescriptorForSourceImages:sourceStates:))]
        #[unsafe(method_family = none)]
        pub unsafe fn destinationImageDescriptorForSourceImages_sourceStates(
            &self,
            source_images: &NSArray<MPSImage>,
            source_states: Option<&NSArray<MPSState>>,
        ) -> Retained<MPSImageDescriptor>;
    );
}

/// Methods declared on superclass `MPSKernel`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNMultiaryKernel {
    extern_methods!(
        /// Called by NSCoder to decode MPSKernels
        ///
        /// This isn't the right interface to decode a MPSKernel, but
        /// it is the one that NSCoder uses. To enable your NSCoder
        /// (e.g. NSKeyedUnarchiver) to set which device to use
        /// extend the object to adopt the MPSDeviceProvider
        /// protocol. Otherwise, the Metal system default device
        /// will be used.
        ///
        /// # Safety
        ///
        /// `a_decoder` possibly has further requirements.
        #[unsafe(method(initWithCoder:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithCoder(
            this: Allocated<Self>,
            a_decoder: &NSCoder,
        ) -> Option<Retained<Self>>;
    );
}

/// Methods declared on superclass `NSObject`.
#[cfg(all(feature = "MPSCore", feature = "MPSKernel"))]
impl MPSCNNMultiaryKernel {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}
