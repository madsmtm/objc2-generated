//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-graphics")]
use objc2_core_graphics::*;
use objc2_foundation::*;

use crate::*;

/// Configurations that represent the way the framework checks for sensitive content and how the app responds.
///
/// ## Overview
///
/// This enumeration defines the possible values for the [`SCSensitivityAnalyzer`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer) property [`analysisPolicy`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/analysispolicy). The values of the policy determine how your app manages sensitive content detection.
///
/// ```swift
/// // Check the current analysis policy.
/// let policy = analyzer.analysisPolicy
/// if policy == .disabled { return }
/// else if policy == .simpleInterventions {
///     // The Sensitive Content Warning setting is active.
/// } else if policy == .descriptiveInterventions {
///     // The Communication Safety setting is active.
/// }
/// ```
///
/// For guidance about observing the active analysis policy, see [Detecting nudity in media and providing intervention options](https://developer.apple.com/documentation/sensitivecontentanalysis/detecting-nudity-in-media-and-providing-intervention-options).
///
///
/// SensitivityAnalysis Policy on device, represents type of interventions when enabled
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, Default)]
pub struct SCSensitivityAnalysisPolicy(pub NSInteger);
impl SCSensitivityAnalysisPolicy {
    /// An indicator that the app lacks access to use the framework.
    ///
    /// ## Discussion
    ///
    /// If [`analysisPolicy`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/analysispolicy) is this value, the framework doesn’t detect nudity. The system disables sensitive content analysis under any of the following conditions:
    ///
    /// - The app lacks the necessary [`com.apple.developer.sensitivecontentanalysis.client`](https://developer.apple.com/documentation/bundleresources/entitlements/com.apple.developer.sensitivecontentanalysis.client) entitlement.
    ///
    /// - Neither the Sensitive Content Warning user preference nor the Communication Safety parental control in Screen Time are active.
    ///
    /// - The user disables the Sensitive Content Warnings toggle in your app’s Settings.
    ///
    ///
    /// No feature enabled that is requiring Sensitive Analysis on device, analysis will be disabled
    #[doc(alias = "SCSensitivityAnalysisPolicyDisabled")]
    pub const Disabled: Self = Self(0);
    /// An indicator that user preference requests discrete detection of sensitive content.
    ///
    /// ## Discussion
    ///
    /// If [`analysisPolicy`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/analysispolicy) is this value, it indicates that the user enables both of the following:
    ///
    /// - Sensitive Content Warnings user preference
    ///
    /// - Sensitive Content Warnings in your app’s settings
    ///
    /// When your app detects nudity under this policy, your app needs to:
    ///
    /// - Keep the intervention minimal by describing the issue briefly and updating your app’s UI unobstructively. For example, consider blurring and annotating the area that otherwise presents the sensitive content versus raising a new fullscreen alert.
    ///
    /// - Intervene on the receipt of sensitve content over the network but allow the app to transmit content over the network unchecked.
    ///
    ///
    /// Sensitive Analysis is enabled on device through "Sensitive Content Warning" in Settings.
    /// It is expected that brief/inline UI, like simple "show" button.
    #[doc(alias = "SCSensitivityAnalysisPolicySimpleInterventions")]
    pub const SimpleInterventions: Self = Self(1);
    /// An indicator that user preference requests overt detection of sensitive content.
    ///
    /// ## Discussion
    ///
    /// If [`analysisPolicy`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/analysispolicy) is this value, it indicates that the user enables both of the following:
    ///
    /// - Communication Safety parental control in Screen Time
    ///
    /// - Sensitive Content Warnings in your app’s settings
    ///
    /// When your app detects nudity under this policy, your app needs to:
    ///
    /// - Use child-appropriate language, such as broadly understood vocabulary
    ///
    /// - Present an alert that fills the full screen.
    ///
    /// - Intervene on the receipt of sensitve content over a network and before transmitting sensitive content over a network.
    ///
    ///
    /// Sensitive Analysis is enabled for kids or teens in ScreenTime through "Communications Safety" feature.
    /// It's expected to have more descriptive UI for the user, explaining potential risks.
    #[doc(alias = "SCSensitivityAnalysisPolicyDescriptiveInterventions")]
    pub const DescriptiveInterventions: Self = Self(2);
}

unsafe impl Encode for SCSensitivityAnalysisPolicy {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for SCSensitivityAnalysisPolicy {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// An object that analyzes media for sensitive content.
    ///
    /// ## Overview
    ///
    /// To check an image for nudity, call one of this class’s `analyzeImage` methods and pass in a user-provided image, or a URL to the image.
    ///
    /// ```swift
    /// // Analyze an image file at a particular URL.
    /// let response = try await analyzer.analyzeImage(at: url)
    /// ```
    ///
    /// To analyze a video file, pass a URL to a video on disk into [`videoAnalysis(forFileAt:)`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/videoanalysis(forfileat:)) and wait for the [`hasSensitiveContent()`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/videoanalysishandler/hassensitivecontent()) method to complete.
    ///
    /// ```swift
    /// let handler = analyzer.videoAnalysis(forFileAt: videoFileUrl)
    /// let response = try await handler.hasSensitiveContent()
    /// ```
    ///
    /// This class successfully detects nudity only when [`analysisPolicy`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalyzer/analysispolicy) is a value other than [`SCSensitivityAnalysisPolicyDisabled`](https://developer.apple.com/documentation/sensitivecontentanalysis/scsensitivityanalysispolicy/disabled).
    ///
    /// <div class="warning">
    ///
    /// ### Note
    ///  To analyze a video stream rather than static files, see [`SCVideoStreamAnalyzer`](https://developer.apple.com/documentation/sensitivecontentanalysis/scvideostreamanalyzer).
    ///
    ///
    ///
    /// </div>
    ///
    /// Main class for content sensitivity analysis
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct SCSensitivityAnalyzer;
);

unsafe impl Send for SCSensitivityAnalyzer {}

unsafe impl Sync for SCSensitivityAnalyzer {}

extern_conformance!(
    unsafe impl NSObjectProtocol for SCSensitivityAnalyzer {}
);

impl SCSensitivityAnalyzer {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        /// Current SCSensitivityAnalysisPolicy set on device. Can be used to determine whether analysis is available or not
        #[unsafe(method(analysisPolicy))]
        #[unsafe(method_family = none)]
        pub unsafe fn analysisPolicy(&self) -> SCSensitivityAnalysisPolicy;

        #[cfg(all(feature = "SCSensitivityAnalysis", feature = "block2"))]
        /// Analyze sensitivity of Image File on disk (only local fileURL)
        ///
        /// Parameter `fileURL`: Image file location on disk
        ///
        /// Parameter `completionHandler`: Block to be called on completion (callback is called on unspecified queue)
        #[unsafe(method(analyzeImageFile:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn analyzeImageFile_completionHandler(
            &self,
            file_url: &NSURL,
            completion_handler: &block2::DynBlock<dyn Fn(*mut SCSensitivityAnalysis, *mut NSError)>,
        );

        #[cfg(all(
            feature = "SCSensitivityAnalysis",
            feature = "block2",
            feature = "objc2-core-graphics"
        ))]
        /// Analyze sensitivity of CGImage in memory
        ///
        /// Parameter `image`: CGImage reference
        ///
        /// Parameter `completionHandler`: Block to be called on completion (callback is called on unspecified queue)
        #[unsafe(method(analyzeCGImage:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn analyzeCGImage_completionHandler(
            &self,
            image: &CGImage,
            completion_handler: &block2::DynBlock<dyn Fn(*mut SCSensitivityAnalysis, *mut NSError)>,
        );

        #[cfg(all(feature = "SCSensitivityAnalysis", feature = "block2"))]
        /// Analyze sensitivity of Video File on disk.
        ///
        /// Parameter `fileURL`: Video file location on disk
        ///
        /// Parameter `completionHandler`: Block to be called on completion (callback is called on unspecified queue)
        ///
        /// Returns: An NSProgress instance for tracking video file analysis progress
        #[unsafe(method(analyzeVideoFile:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn analyzeVideoFile_completionHandler(
            &self,
            file_url: &NSURL,
            completion_handler: &block2::DynBlock<dyn Fn(*mut SCSensitivityAnalysis, *mut NSError)>,
        ) -> Retained<NSProgress>;
    );
}

/// Methods declared on superclass `NSObject`.
impl SCSensitivityAnalyzer {
    extern_methods!(
        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}
