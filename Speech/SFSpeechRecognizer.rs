//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
use objc2_foundation::*;

use crate::*;

/// The app's authorization to perform speech recognition.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/speech/sfspeechrecognizerauthorizationstatus?language=objc)
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct SFSpeechRecognizerAuthorizationStatus(pub NSInteger);
impl SFSpeechRecognizerAuthorizationStatus {
    /// The app's authorization status has not yet been determined.
    ///
    /// When your app's status is not determined, calling the ``SFSpeechRecognizer/requestAuthorization(_:)`` method prompts the user to grant or deny authorization.
    #[doc(alias = "SFSpeechRecognizerAuthorizationStatusNotDetermined")]
    pub const NotDetermined: Self = Self(0);
    /// The user denied your app's request to perform speech recognition.
    #[doc(alias = "SFSpeechRecognizerAuthorizationStatusDenied")]
    pub const Denied: Self = Self(1);
    /// The device prevents your app from performing speech recognition.
    #[doc(alias = "SFSpeechRecognizerAuthorizationStatusRestricted")]
    pub const Restricted: Self = Self(2);
    /// The user granted your app's request to perform speech recognition.
    #[doc(alias = "SFSpeechRecognizerAuthorizationStatusAuthorized")]
    pub const Authorized: Self = Self(3);
}

unsafe impl Encode for SFSpeechRecognizerAuthorizationStatus {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for SFSpeechRecognizerAuthorizationStatus {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// An object you use to check for the availability of the speech recognition service, and to initiate the speech recognition process.
    ///
    /// An ``SFSpeechRecognizer`` object is the central object for managing the speech recognizer process. Use this object to:
    ///
    /// - Request authorization to use speech recognition services.
    /// - Specify the language to use during the recognition process.
    /// - Initiate new speech recognition tasks.
    ///
    /// ### Set up speech recognition
    ///
    /// Each speech recognizer supports only one language, which you specify at creation time. The successful creation of a speech recognizer does not guarantee that speech recognition services are available. For some languages, the recognizer might require an Internet connection. Use the ``isAvailable`` property to find out if speech recognition services are available for the current language.
    ///
    /// To initiate the speech recognition process, do the following:
    ///
    /// 1. Request authorization to use speech recognition. See
    /// <doc
    /// :asking-permission-to-use-speech-recognition>.
    /// 2. Create an ``SFSpeechRecognizer`` object.
    /// 3. Verify the availability of services using the ``isAvailable`` property of your speech recognizer object.
    /// 4. Prepare your audio content.
    /// 5. Create a recognition request objectâ€”an object that descends from ``SFSpeechRecognitionRequest``.
    /// 6. Call the ``recognitionTask(with:delegate:)`` or ``recognitionTask(with:resultHandler:)`` method to begin the recognition process.
    ///
    /// The type of recognition request object you create depends on whether you are processing an existing audio file or an incoming stream of audio. For existing audio files, create a ``SFSpeechURLRecognitionRequest`` object. For audio streams, create a ``SFSpeechAudioBufferRecognitionRequest`` object.
    ///
    /// ### Create a great user experience for speech recognition
    ///
    /// Here are some tips to consider when adding speech recognition support to your app.
    ///
    /// - **Be prepared to handle failures caused by speech recognition limits.** Because speech recognition is a network-based service, limits are enforced so that the service can remain freely available to all apps. Individual devices may be limited in the number of recognitions that can be performed per day, and each app may be throttled globally based on the number of requests it makes per day. If a recognition request fails quickly (within a second or two of starting), check to see if the recognition service became unavailable. If it is, you may want to ask users to try again later.
    /// - **Plan for a one-minute limit on audio duration.** Speech recognition places a relatively high burden on battery life and network usage. To minimize this burden, the framework stops speech recognition tasks that last longer than one minute. This limit is similar to the one for keyboard-related dictation.
    /// - **Remind the user when your app is recording.** For example, display a visual indicator and play sounds at the beginning and end of speech recognition to help users understand that they're being actively recorded. You can also display speech as it is being recognized so that users understand what your app is doing and see any mistakes made during the recognition process.
    /// - **Do not perform speech recognition on private or sensitive information.** Some speech is not appropriate for recognition. Don't send passwords, health or financial data, and other sensitive speech for recognition.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/speech/sfspeechrecognizer?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct SFSpeechRecognizer;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for SFSpeechRecognizer {}
);

impl SFSpeechRecognizer {
    extern_methods!(
        /// Returns the set of locales that are supported by the speech recognizer.
        ///
        /// This method returns the locales for which speech recognition is supported. Support for a locale does not guarantee that speech recognition is currently possible for that locale. For some locales, the speech recognizer requires an active Internet connection to communicate with Apple's servers. If the speech recognizer is currently unable to process requests,   ``isAvailable`` returns `false`.
        ///
        /// Speech recognition supports the same locales that are supported by the keyboard's dictation feature. For a list of these locales, see [QuickType Keyboard: Dictation](https://www.apple.com/ios/feature-availability/#quicktype-keyboard-dictation).
        ///
        /// - Returns: A set of locales that support speech recognition.
        #[unsafe(method(supportedLocales))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportedLocales() -> Retained<NSSet<NSLocale>>;

        /// Returns your app's current authorization to perform speech recognition.
        ///
        /// The user can reject your app's request to perform speech recognition, but your request can also be denied if speech recognition is not supported on the device. The app can also change your app's authorization status at any time from the Settings app.
        ///
        /// - Returns: The app's current authorization status value. For a list of values, see ``SFSpeechRecognizerAuthorizationStatus``.
        #[unsafe(method(authorizationStatus))]
        #[unsafe(method_family = none)]
        pub unsafe fn authorizationStatus() -> SFSpeechRecognizerAuthorizationStatus;

        #[cfg(feature = "block2")]
        /// Asks the user to allow your app to perform speech recognition.
        ///
        /// Call this method before performing any other tasks associated with speech recognition. This method executes asynchronously, returning shortly after you call it. At some point later, the system calls the provided `handler` block with the results.
        ///
        /// When your app's authorization status is ``SFSpeechRecognizerAuthorizationStatus/notDetermined``, this method causes the system to prompt the user to grant or deny permission for your app to use speech recognition. The prompt includes the custom message you specify in the `NSSpeechRecognitionUsageDescription` key of your app's `Info.plist` file. The user's response is saved so that future calls to this method do not prompt the user again.
        ///
        /// > Important:
        /// > Your app's `Info.plist` file must contain the `NSSpeechRecognitionUsageDescription` key with a valid usage description. If this key is not present, your app will crash when you call this method.
        ///
        /// For more information about requesting authorization, see
        /// <doc
        /// :asking-permission-to-use-speech-recognition>.
        ///
        /// - Parameters:
        /// - handler: The block to execute when your app's authorization status is known. The status parameter of the block contains your app's authorization status. The system does not guarantee the execution of this block on your app's main dispatch queue.
        #[unsafe(method(requestAuthorization:))]
        #[unsafe(method_family = none)]
        pub unsafe fn requestAuthorization(
            handler: &block2::DynBlock<dyn Fn(SFSpeechRecognizerAuthorizationStatus)>,
        );

        /// Creates a speech recognizer associated with the user's default language settings.
        ///
        /// If the user's default language is not supported for speech recognition, this method attempts to fall back to the language used by the keyboard for dictation. If that fails, this method returns `nil`.
        ///
        /// Even if this method returns a valid speech recognizer object, the speech recognition services may be temporarily unavailable. To determine whether speech recognition services are available, check the ``isAvailable`` property.
        ///
        /// - Returns: An initialized speech recognizer object, or `nil` if there was a problem creating the object.
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Option<Retained<Self>>;

        /// Creates a speech recognizer associated with the specified locale.
        ///
        /// If you specify a language that is not supported by the speech recognizer, this method attempts to fall back to the language used by the keyboard for dictation. If that fails, this method returns `nil`.
        ///
        /// Even if this method returns a valid speech recognizer object, the speech recognition services may be temporarily unavailable. To determine whether speech recognition services are available, check the ``isAvailable`` property.
        ///
        /// - Parameters:
        /// - locale: The locale object representing the language you want to use for speech recognition. For a list of languages supported by the speech recognizer, see ``supportedLocales()``.
        ///
        /// - Returns: An initialized speech recognizer object, or `nil` if the specified language was not supported.
        #[unsafe(method(initWithLocale:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithLocale(
            this: Allocated<Self>,
            locale: &NSLocale,
        ) -> Option<Retained<Self>>;

        /// A Boolean value that indicates whether the speech recognizer is currently available.
        ///
        /// When the value of this property is `true`, you may create new speech recognition tasks. When value of this property is `false`, speech recognition services are not available.
        #[unsafe(method(isAvailable))]
        #[unsafe(method_family = none)]
        pub unsafe fn isAvailable(&self) -> bool;

        /// The locale of the speech recognizer.
        ///
        /// The locale of the speech recognizer is an `NSLocale` object. The default value of this property is the system locale (that is, `+[NSLocale systemLocale]`).
        #[unsafe(method(locale))]
        #[unsafe(method_family = none)]
        pub unsafe fn locale(&self) -> Retained<NSLocale>;

        /// A Boolean value that indicates whether the speech recognizer can operate without network access.
        ///
        /// An ``SFSpeechRecognitionRequest`` can only honor its ``SFSpeechRecognitionRequest/requiresOnDeviceRecognition`` property if ``supportsOnDeviceRecognition`` is `true`. If ``supportsOnDeviceRecognition`` is `false`, the ``SFSpeechRecognizer`` requires a network in order to recognize speech.
        #[unsafe(method(supportsOnDeviceRecognition))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportsOnDeviceRecognition(&self) -> bool;

        /// Setter for [`supportsOnDeviceRecognition`][Self::supportsOnDeviceRecognition].
        #[unsafe(method(setSupportsOnDeviceRecognition:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSupportsOnDeviceRecognition(&self, supports_on_device_recognition: bool);

        /// The delegate object that handles changes to the availability of speech recognition services.
        ///
        /// Provide a delegate object when you want to monitor changes to the availability of speech recognition services. Your delegate object must conform to the ``SFSpeechRecognizerDelegate`` protocol.
        #[unsafe(method(delegate))]
        #[unsafe(method_family = none)]
        pub unsafe fn delegate(
            &self,
        ) -> Option<Retained<ProtocolObject<dyn SFSpeechRecognizerDelegate>>>;

        /// This is a [weak property][objc2::topics::weak_property].
        /// Setter for [`delegate`][Self::delegate].
        #[unsafe(method(setDelegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDelegate(
            &self,
            delegate: Option<&ProtocolObject<dyn SFSpeechRecognizerDelegate>>,
        );

        #[cfg(feature = "SFSpeechRecognitionTaskHint")]
        /// A hint that indicates the type of speech recognition being requested.
        ///
        /// By default, the value of this property overrides the ``SFSpeechRecognitionTaskHint/unspecified`` value for requests. For possible values, see ``SFSpeechRecognitionTaskHint``.
        #[unsafe(method(defaultTaskHint))]
        #[unsafe(method_family = none)]
        pub unsafe fn defaultTaskHint(&self) -> SFSpeechRecognitionTaskHint;

        #[cfg(feature = "SFSpeechRecognitionTaskHint")]
        /// Setter for [`defaultTaskHint`][Self::defaultTaskHint].
        #[unsafe(method(setDefaultTaskHint:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setDefaultTaskHint(&self, default_task_hint: SFSpeechRecognitionTaskHint);

        #[cfg(all(
            feature = "SFSpeechRecognitionRequest",
            feature = "SFSpeechRecognitionResult",
            feature = "SFSpeechRecognitionTask",
            feature = "block2"
        ))]
        /// Executes the speech recognition request and delivers the results to the specified handler block.
        ///
        /// Use this method to initiate the speech recognition process on the audio contained in the request object. This method executes asynchronously and returns a ``SFSpeechRecognitionTask`` object that you can use to cancel or finalize the recognition process later. As results become available, the method calls the block in the `resultHandler` parameter.
        ///
        /// - Parameters:
        /// - request: A request (in an ``SFSpeechRecognitionRequest`` object) to recognize speech from an audio source.
        /// - resultHandler: The block to call when partial or final results are available, or when an error occurs. If the ``SFSpeechRecognitionRequest/shouldReportPartialResults`` property is `true`, this block may be called multiple times to deliver the partial and final results. The block has no return value and takes the following parameters:
        ///
        /// - term result: A ``SFSpeechRecognitionResult`` containing the partial or final transcriptions of the audio content.
        /// - term error: An error object if a problem occurred. This parameter is `nil` if speech recognition was successful.
        ///
        /// - Returns: The task object you can use to manage an in-progress recognition request.
        #[unsafe(method(recognitionTaskWithRequest:resultHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn recognitionTaskWithRequest_resultHandler(
            &self,
            request: &SFSpeechRecognitionRequest,
            result_handler: &block2::DynBlock<dyn Fn(*mut SFSpeechRecognitionResult, *mut NSError)>,
        ) -> Retained<SFSpeechRecognitionTask>;

        #[cfg(all(
            feature = "SFSpeechRecognitionRequest",
            feature = "SFSpeechRecognitionTask"
        ))]
        /// Recognizes speech from the audio source associated with the specified request, using the specified delegate to manage the results.
        ///
        /// Use this method to initiate the speech recognition process on the audio contained in the request object. This method executes asynchronously and returns a ``SFSpeechRecognitionTask`` object that you can use to cancel or finalize the recognition process later. As results become available, the method calls the methods of the provided `delegate` object.
        ///
        /// Note that the ``SFSpeechRecognitionTask`` object returned by this method does not retain your delegate object. You must maintain a strong reference to your delegate while speech recognition is in progress.
        ///
        /// - Parameters:
        /// - request: A request (encapsulated in an ``SFSpeechRecognitionRequest`` object) to recognize speech from an audio source.
        /// - delegate: An object that can handle results from the speech recognition task. This object must conform to the ``SFSpeechRecognitionTaskDelegate`` protocol.
        ///
        /// - Returns: The task object you can use to manage an in-progress recognition request.
        #[unsafe(method(recognitionTaskWithRequest:delegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn recognitionTaskWithRequest_delegate(
            &self,
            request: &SFSpeechRecognitionRequest,
            delegate: &ProtocolObject<dyn SFSpeechRecognitionTaskDelegate>,
        ) -> Retained<SFSpeechRecognitionTask>;

        /// The queue on which to execute recognition task handlers and delegate methods.
        ///
        /// The default value of this property is the app's main queue. Assign a different queue if you want delegate methods and handlers to be executed on a background queue.
        ///
        /// The handler you pass to the ``requestAuthorization(_:)`` method does not use this queue.
        #[unsafe(method(queue))]
        #[unsafe(method_family = none)]
        pub unsafe fn queue(&self) -> Retained<NSOperationQueue>;

        /// Setter for [`queue`][Self::queue].
        #[unsafe(method(setQueue:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setQueue(&self, queue: &NSOperationQueue);
    );
}

/// Methods declared on superclass `NSObject`.
impl SFSpeechRecognizer {
    extern_methods!(
        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_protocol!(
    /// A protocol that you adopt in your objects to track the availability of a speech recognizer.
    ///
    /// A speech recognizer's availability can change due to the device's Internet connection or other factors. Use this protocol's optional method to track those changes and provide an appropriate response. For example, when speech recognition becomes unavailable, you might disable related features in your app.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/speech/sfspeechrecognizerdelegate?language=objc)
    pub unsafe trait SFSpeechRecognizerDelegate: NSObjectProtocol {
        /// Tells the delegate that the availability of its associated speech recognizer changed.
        ///
        /// - Parameters:
        /// - speechRecognizer: The ``SFSpeechRecognizer`` object whose availability changed.
        /// - available: A Boolean value that indicates the new availability of the speech recognizer.
        #[optional]
        #[unsafe(method(speechRecognizer:availabilityDidChange:))]
        #[unsafe(method_family = none)]
        unsafe fn speechRecognizer_availabilityDidChange(
            &self,
            speech_recognizer: &SFSpeechRecognizer,
            available: bool,
        );
    }
);
