//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// A tensor object
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/mlcompute/mlctensor?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[deprecated]
    pub struct MLCTensor;
);

unsafe impl NSCopying for MLCTensor {}

unsafe impl CopyingHelper for MLCTensor {
    type Result = Self;
}

unsafe impl NSObjectProtocol for MLCTensor {}

extern_methods!(
    unsafe impl MLCTensor {
        /// The tensor ID
        ///
        /// A unique number to identify each tensor.  Assigned when the tensor is created.
        #[deprecated]
        #[unsafe(method(tensorID))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorID(&self) -> NSUInteger;

        #[cfg(feature = "MLCTensorDescriptor")]
        /// The tensor descriptor
        #[deprecated]
        #[unsafe(method(descriptor))]
        #[unsafe(method_family = none)]
        pub unsafe fn descriptor(&self) -> Retained<MLCTensorDescriptor>;

        /// The tensor data
        #[deprecated]
        #[unsafe(method(data))]
        #[unsafe(method_family = none)]
        pub unsafe fn data(&self) -> Option<Retained<NSData>>;

        /// A string to help identify this object.
        #[deprecated]
        #[unsafe(method(label))]
        #[unsafe(method_family = none)]
        pub unsafe fn label(&self) -> Retained<NSString>;

        /// Setter for [`label`][Self::label].
        #[deprecated]
        #[unsafe(method(setLabel:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setLabel(&self, label: &NSString);

        #[cfg(feature = "MLCDevice")]
        /// The device associated with this tensor.
        #[deprecated]
        #[unsafe(method(device))]
        #[unsafe(method_family = none)]
        pub unsafe fn device(&self) -> Option<Retained<MLCDevice>>;

        #[cfg(feature = "MLCTensorData")]
        /// These are the host side optimizer (momentum and velocity) buffers which developers can query and initialize
        ///
        /// When customizing optimizer data, the contents of these buffers must be initialized before executing optimizer
        /// update for a graph.
        #[deprecated]
        #[unsafe(method(optimizerData))]
        #[unsafe(method_family = none)]
        pub unsafe fn optimizerData(&self) -> Retained<NSArray<MLCTensorData>>;

        #[cfg(feature = "MLCTensorOptimizerDeviceData")]
        /// These are the device side optimizer (momentum and velocity) buffers which developers can query
        #[deprecated]
        #[unsafe(method(optimizerDeviceData))]
        #[unsafe(method_family = none)]
        pub unsafe fn optimizerDeviceData(&self)
            -> Retained<NSArray<MLCTensorOptimizerDeviceData>>;

        #[deprecated]
        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[deprecated]
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[cfg(feature = "MLCTensorDescriptor")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object without any data
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithDescriptor:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithDescriptor(
            tensor_descriptor: &MLCTensorDescriptor,
        ) -> Retained<Self>;

        #[cfg(all(feature = "MLCTensorDescriptor", feature = "MLCTypes"))]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object initialized with a random initializer such as Glorot Uniform.
        ///
        /// Parameter `tensorDescriptor`: The tensor descriptor
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithDescriptor:randomInitializerType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithDescriptor_randomInitializerType(
            tensor_descriptor: &MLCTensorDescriptor,
            random_initializer_type: MLCRandomInitializerType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTensorDescriptor")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object with a MLCTensorData object that specifies the tensor data buffer
        ///
        /// Parameter `tensorDescriptor`: The tensor descriptor
        ///
        /// Parameter `fillData`: The scalar data to fill to tensor with
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithDescriptor:fillWithData:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithDescriptor_fillWithData(
            tensor_descriptor: &MLCTensorDescriptor,
            fill_data: &NSNumber,
        ) -> Retained<Self>;

        #[cfg(all(feature = "MLCTensorData", feature = "MLCTensorDescriptor"))]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object with a MLCTensorData object that specifies the tensor data buffer
        ///
        /// Parameter `tensorDescriptor`: The tensor descriptor
        ///
        /// Parameter `data`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithDescriptor:data:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithDescriptor_data(
            tensor_descriptor: &MLCTensorDescriptor,
            data: &MLCTensorData,
        ) -> Retained<Self>;

        /// Create a MLCTensor object
        ///
        /// Create a tensor object without any data.  The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape(shape: &NSArray<NSNumber>) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object initialized with a random initializer such as Glorot Uniform.
        /// The tensor data type is MLCDataTypeFloat32
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:randomInitializerType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape_randomInitializerType(
            shape: &NSArray<NSNumber>,
            random_initializer_type: MLCRandomInitializerType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object initialized with a random initializer such as Glorot Uniform.
        /// The tensor data type is MLCDataTypeFloat32
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:randomInitializerType:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape_randomInitializerType_dataType(
            shape: &NSArray<NSNumber>,
            random_initializer_type: MLCRandomInitializerType,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object without any data
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape_dataType(
            shape: &NSArray<NSNumber>,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        #[cfg(all(feature = "MLCTensorData", feature = "MLCTypes"))]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object with data
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Parameter `data`: The tensor data
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:data:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape_data_dataType(
            shape: &NSArray<NSNumber>,
            data: &MLCTensorData,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor object
        ///
        /// Create a tensor object with data
        ///
        /// Parameter `shape`: The tensor shape
        ///
        /// Parameter `fillData`: The scalar value to initialize the tensor data with
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithShape:fillWithData:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithShape_fillWithData_dataType(
            shape: &NSArray<NSNumber>,
            fill_data: &NSNumber,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        /// Create a MLCTensor  object
        ///
        /// Create a NCHW tensor object with tensor data type = MLCDataTypeFloat32
        ///
        /// Parameter `width`: The tensor width
        ///
        /// Parameter `height`: The tensor height
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithWidth:height:featureChannelCount:batchSize:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithWidth_height_featureChannelCount_batchSize(
            width: NSUInteger,
            height: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor  object
        ///
        /// Create a NCHW tensor object initialized with a scalar value
        ///
        /// Parameter `width`: The tensor width
        ///
        /// Parameter `height`: The tensor height
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `fillData`: The scalar value to initialize the tensor data with
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensorData object
        #[deprecated]
        #[unsafe(method(tensorWithWidth:height:featureChannelCount:batchSize:fillWithData:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithWidth_height_featureChannelCount_batchSize_fillWithData_dataType(
            width: NSUInteger,
            height: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            fill_data: c_float,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor  object
        ///
        /// Create a NCHW tensor object initialized with a random initializer type.
        /// The tensor data type is MLCDataTypeFloat32
        ///
        /// Parameter `width`: The tensor width
        ///
        /// Parameter `height`: The tensor height
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithWidth:height:featureChannelCount:batchSize:randomInitializerType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithWidth_height_featureChannelCount_batchSize_randomInitializerType(
            width: NSUInteger,
            height: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            random_initializer_type: MLCRandomInitializerType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTensorData")]
        /// Create a MLCTensor  object
        ///
        /// Create a NCHW tensor object with a tensor data object
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `width`: The tensor width
        ///
        /// Parameter `height`: The tensor height
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `data`: The tensor data
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithWidth:height:featureChannelCount:batchSize:data:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithWidth_height_featureChannelCount_batchSize_data(
            width: NSUInteger,
            height: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            data: &MLCTensorData,
        ) -> Retained<Self>;

        #[cfg(all(feature = "MLCTensorData", feature = "MLCTypes"))]
        /// Create a MLCTensor  object
        ///
        /// Create a NCHW tensor object with a tensor data object
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `width`: The tensor width
        ///
        /// Parameter `height`: The tensor height
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `data`: The tensor data
        ///
        /// Parameter `dataType`: The tensor data type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithWidth:height:featureChannelCount:batchSize:data:dataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithWidth_height_featureChannelCount_batchSize_data_dataType(
            width: NSUInteger,
            height: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            data: &MLCTensorData,
            data_type: MLCDataType,
        ) -> Retained<Self>;

        /// Create a MLCTensor  object
        ///
        /// Create a tensor typically used by a recurrent layer
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `sequenceLength`: The length of sequences stored in the tensor
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithSequenceLength:featureChannelCount:batchSize:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithSequenceLength_featureChannelCount_batchSize(
            sequence_length: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor  object
        ///
        /// Create a tensor typically used by a recurrent layer
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `sequenceLength`: The length of sequences stored in the tensor
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithSequenceLength:featureChannelCount:batchSize:randomInitializerType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithSequenceLength_featureChannelCount_batchSize_randomInitializerType(
            sequence_length: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            random_initializer_type: MLCRandomInitializerType,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTensorData")]
        /// Create a MLCTensor  object
        ///
        /// Create a tensor typically used by a recurrent layer
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `sequenceLength`: The length of sequences stored in the tensor
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `data`: The tensor data
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithSequenceLength:featureChannelCount:batchSize:data:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithSequenceLength_featureChannelCount_batchSize_data(
            sequence_length: NSUInteger,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            data: Option<&MLCTensorData>,
        ) -> Retained<Self>;

        #[cfg(feature = "MLCTypes")]
        /// Create a MLCTensor  object
        ///
        /// Create a tensor of variable length sequences typically used by a recurrent layer
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `sequenceLengths`: An array of sequence lengths
        ///
        /// Parameter `sortedSequences`: A flag to indicate if the sequence lengths are sorted.  If yes, they must be sorted in descending order
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `randomInitializerType`: The random initializer type
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithSequenceLengths:sortedSequences:featureChannelCount:batchSize:randomInitializerType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithSequenceLengths_sortedSequences_featureChannelCount_batchSize_randomInitializerType(
            sequence_lengths: &NSArray<NSNumber>,
            sorted_sequences: bool,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            random_initializer_type: MLCRandomInitializerType,
        ) -> Option<Retained<Self>>;

        #[cfg(feature = "MLCTensorData")]
        /// Create a MLCTensor  object
        ///
        /// Create a tensor of variable length sequences typically used by a recurrent layer
        /// The tensor data type is MLCDataTypeFloat32.
        ///
        /// Parameter `sequenceLengths`: An array of sequence lengths
        ///
        /// Parameter `sortedSequences`: A flag to indicate if the sequence lengths are sorted.  If yes, they must be sorted in descending order
        ///
        /// Parameter `featureChannelCount`: Number of feature channels
        ///
        /// Parameter `batchSize`: The tensor batch size
        ///
        /// Parameter `data`: The tensor data
        ///
        /// Returns: A new MLCTensor object
        #[deprecated]
        #[unsafe(method(tensorWithSequenceLengths:sortedSequences:featureChannelCount:batchSize:data:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorWithSequenceLengths_sortedSequences_featureChannelCount_batchSize_data(
            sequence_lengths: &NSArray<NSNumber>,
            sorted_sequences: bool,
            feature_channel_count: NSUInteger,
            batch_size: NSUInteger,
            data: Option<&MLCTensorData>,
        ) -> Option<Retained<Self>>;

        /// Returns a Boolean value indicating whether the underlying data has valid floating-point numerics, i.e. it
        /// does not contain NaN or INF floating-point values.
        #[deprecated]
        #[unsafe(method(hasValidNumerics))]
        #[unsafe(method_family = none)]
        pub unsafe fn hasValidNumerics(&self) -> bool;

        /// Synchronize the data in host memory.
        ///
        /// Synchronize the data in host memory i.e. tensor.data with latest contents in device memory
        /// This should only be called once the graph that this tensor is used with has finished execution;
        /// Otherwise the results in device memory may not be up to date.
        /// NOTE:  This method should not be called from a completion callback when device is the GPU.
        ///
        /// Returns: Returns YES if success, NO if there is a failure to synchronize
        #[deprecated]
        #[unsafe(method(synchronizeData))]
        #[unsafe(method_family = none)]
        pub unsafe fn synchronizeData(&self) -> bool;

        /// Synchronize the optimizer data in host memory.
        ///
        /// Synchronize the optimizer data in host memory with latest contents in device memory
        /// This should only be called once the graph that this tensor is used with has finished execution;
        /// Otherwise the results in device memory may not be up to date.
        /// NOTE:  This method should not be called from a completion callback when device is the GPU.
        ///
        /// Returns: Returns YES if success, NO if there is a failure to synchronize
        #[deprecated]
        #[unsafe(method(synchronizeOptimizerData))]
        #[unsafe(method_family = none)]
        pub unsafe fn synchronizeOptimizerData(&self) -> bool;

        /// Copy tensor data from device memory to user specified memory
        ///
        /// Before copying tensor data from device memory, one may need to synchronize the device memory for example
        /// when device is the GPU.  The synchronizeWithDevice argumet can be set appropraitely to indicate this.
        /// For CPU this is ignored.  If the tensor has been specified in outputs of a graph using addOutputs,
        /// synchronizeWithDevice should be set to NO.
        /// NOTE:  This method should only be called once the graph that this tensor is used with has finished execution;
        /// Otherwise the results in device memory may not be up to date.  synchronizeWithDevice must be set to NO
        /// when this method is called from a completion callback for GPU.
        ///
        /// Parameter `bytes`: The user specified data in which to copy
        ///
        /// Parameter `length`: The size in bytes to copy
        ///
        /// Parameter `synchronizeWithDevice`: Whether to synchronize device memory if device is GPU
        ///
        /// Returns: Returns YES if success, NO if there is a failure to synchronize
        #[deprecated]
        #[unsafe(method(copyDataFromDeviceMemoryToBytes:length:synchronizeWithDevice:))]
        #[unsafe(method_family = none)]
        pub unsafe fn copyDataFromDeviceMemoryToBytes_length_synchronizeWithDevice(
            &self,
            bytes: NonNull<c_void>,
            length: NSUInteger,
            synchronize_with_device: bool,
        ) -> bool;

        #[cfg(all(feature = "MLCDevice", feature = "MLCTensorData"))]
        /// Associates the given data to the tensor. If the device is GPU, also copies the data to the device memory.
        /// Returns true if the data is successfully associated with the tensor and copied to the device.
        ///
        /// The caller must guarantee the lifetime of the underlying memory of
        /// `data`for the entirety of the tensor's
        /// lifetime.  For input tensors, we recommend that the bindAndwriteData method provided by MLCTrainingGraph
        /// and MLCInferenceGraph be used.  This method should only be used to allocate and copy data to device memory
        /// for tensors that are typically layer parameters such as weights, bias for convolution layers, beta, gamma for
        /// normalization layers.
        ///
        /// Parameter `data`: The data to associated with the tensor
        ///
        /// Parameter `device`: The compute device
        ///
        /// Returns: A Boolean value indicating whether the data is successfully associated with the tensor and copied to the device.
        #[deprecated]
        #[unsafe(method(bindAndWriteData:toDevice:))]
        #[unsafe(method_family = none)]
        pub unsafe fn bindAndWriteData_toDevice(
            &self,
            data: &MLCTensorData,
            device: &MLCDevice,
        ) -> bool;

        #[cfg(all(feature = "MLCTensorData", feature = "MLCTensorOptimizerDeviceData"))]
        /// Associates the given optimizer data and device data buffers to the tensor.
        /// Returns true if the data is successfully associated with the tensor and copied to the device.
        ///
        /// The caller must guarantee the lifetime of the underlying memory of
        /// `data`for the entirety of the tensor's
        /// lifetime.  The
        /// `deviceData`buffers are allocated by MLCompute.  This method must be called
        /// before executeOptimizerUpdateWithOptions or executeWithInputsData is called for the training graph.
        ///
        /// Parameter `data`: The optimizer data to be associated with the tensor
        ///
        /// Parameter `deviceData`: The optimizer device data to be associated with the tensor
        ///
        /// Returns: A Boolean value indicating whether the data is successfully associated with the tensor .
        #[deprecated]
        #[unsafe(method(bindOptimizerData:deviceData:))]
        #[unsafe(method_family = none)]
        pub unsafe fn bindOptimizerData_deviceData(
            &self,
            data: &NSArray<MLCTensorData>,
            device_data: Option<&NSArray<MLCTensorOptimizerDeviceData>>,
        ) -> bool;

        #[cfg(feature = "MLCTypes")]
        /// Converts a 32-bit floating-point tensor with given scale and a zero point
        /// Returns a quantized tensor
        ///
        /// Parameter `type`: The quantized data type.  Must be MLCDataTypeInt8, MLCDataTypeUInt8 or MLCDataTypeInt32
        ///
        /// Parameter `scale`: The scale to apply in quantization
        ///
        /// Parameter `bias`: The offset value that maps to float zero
        ///
        /// Returns: A quantized tensor
        #[unsafe(method(tensorByQuantizingToType:scale:bias:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorByQuantizingToType_scale_bias(
            &self,
            r#type: MLCDataType,
            scale: c_float,
            bias: NSInteger,
        ) -> Option<Retained<MLCTensor>>;

        #[cfg(feature = "MLCTypes")]
        /// Converts a 32-bit floating-point tensor with given scale and a zero point
        /// Returns a quantized tensor
        ///
        /// Parameter `type`: The quantized data type.  Must be MLCDataTypeInt8, MLCDataTypeUInt8 or MLCDataTypeInt32
        ///
        /// Parameter `scale`: The scale to apply in quantization
        ///
        /// Parameter `bias`: The offset value that maps to float zero
        ///
        /// Parameter `axis`: The dimension on which to apply per-channel quantization
        ///
        /// Returns: A quantized tensor
        #[unsafe(method(tensorByQuantizingToType:scale:bias:axis:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorByQuantizingToType_scale_bias_axis(
            &self,
            r#type: MLCDataType,
            scale: &MLCTensor,
            bias: &MLCTensor,
            axis: NSInteger,
        ) -> Option<Retained<MLCTensor>>;

        #[cfg(feature = "MLCTypes")]
        /// Converts a quantized tensor to a 32-bit floating-point tensor
        /// Returns a de-quantized tensor
        ///
        /// Parameter `type`: The de-quantized data type.  Must be MLCFloat32
        ///
        /// Parameter `scale`: The scale thst was used for the quantized data
        ///
        /// Parameter `bias`: The offset value that maps to float zero used for the quantized data
        ///
        /// Parameter `axis`: The dimension on which to apply per-channel quantization
        ///
        /// Returns: A quantized tensor
        #[unsafe(method(tensorByDequantizingToType:scale:bias:axis:))]
        #[unsafe(method_family = none)]
        pub unsafe fn tensorByDequantizingToType_scale_bias_axis(
            &self,
            r#type: MLCDataType,
            scale: &MLCTensor,
            bias: &MLCTensor,
            axis: NSInteger,
        ) -> Option<Retained<MLCTensor>>;
    }
);
