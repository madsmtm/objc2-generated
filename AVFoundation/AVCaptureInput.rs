//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-foundation")]
use objc2_core_foundation::*;
#[cfg(feature = "objc2-core-graphics")]
use objc2_core_graphics::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// AVCaptureInput is an abstract class that provides an interface for connecting capture input sources to an AVCaptureSession.
    ///
    ///
    /// Concrete instances of AVCaptureInput representing input sources such as cameras can be added to instances of AVCaptureSession using the -[AVCaptureSession addInput:] method. An AVCaptureInput vends one or more streams of media data. For example, input devices can provide both audio and video data. Each media stream provided by an input is represented by an AVCaptureInputPort object. Within a capture session, connections are made between AVCaptureInput instances and AVCaptureOutput instances via AVCaptureConnection objects that define the mapping between a set of AVCaptureInputPort objects and a single AVCaptureOutput.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcaptureinput?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVCaptureInput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureInput {}
);

impl AVCaptureInput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// The ports owned by the receiver.
        ///
        ///
        /// The value of this property is an array of AVCaptureInputPort objects, each exposing an interface to a single stream of media data provided by an input.
        #[unsafe(method(ports))]
        #[unsafe(method_family = none)]
        pub unsafe fn ports(&self) -> Retained<NSArray<AVCaptureInputPort>>;
    );
}

extern "C" {
    /// This notification is posted when the value of an AVCaptureInputPort instance's formatDescription property changes.
    ///
    ///
    /// The notification object is the AVCaptureInputPort instance whose format description changed.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcaptureinputportformatdescriptiondidchangenotification?language=objc)
    pub static AVCaptureInputPortFormatDescriptionDidChangeNotification:
        &'static NSNotificationName;
}

extern_class!(
    /// An AVCaptureInputPort describes a single stream of media data provided by an AVCaptureInput and provides an interface for connecting that stream to AVCaptureOutput instances via AVCaptureConnection.
    ///
    ///
    /// Instances of AVCaptureInputPort cannot be created directly. An AVCaptureInput exposes its input ports via its ports property. Input ports provide information about the format of their media data via the mediaType and formatDescription properties, and allow clients to control the flow of data via the enabled property. Input ports are used by an AVCaptureConnection to define the mapping between inputs and outputs in an AVCaptureSession.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcaptureinputport?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVCaptureInputPort;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureInputPort {}
);

impl AVCaptureInputPort {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// The input that owns the receiver.
        ///
        ///
        /// The value of this property is an AVCaptureInput instance that owns the receiver.
        #[unsafe(method(input))]
        #[unsafe(method_family = none)]
        pub unsafe fn input(&self) -> Retained<AVCaptureInput>;

        #[cfg(feature = "AVMediaFormat")]
        /// The media type of the data provided by the receiver.
        ///
        ///
        /// The value of this property is a constant describing the type of media, such as AVMediaTypeVideo or AVMediaTypeAudio, provided by the receiver. Media type constants are defined in AVMediaFormat.h.
        #[unsafe(method(mediaType))]
        #[unsafe(method_family = none)]
        pub unsafe fn mediaType(&self) -> Retained<AVMediaType>;

        #[cfg(feature = "objc2-core-media")]
        /// The format of the data provided by the receiver.
        ///
        ///
        /// The value of this property is a CMFormatDescription that describes the format of the media data currently provided by the receiver. Clients can be notified of changes to the format by observing the AVCaptureInputPortFormatDescriptionDidChangeNotification.
        #[unsafe(method(formatDescription))]
        #[unsafe(method_family = none)]
        pub unsafe fn formatDescription(&self) -> Option<Retained<CMFormatDescription>>;

        /// Whether the receiver should provide data.
        ///
        ///
        /// The value of this property is a BOOL that determines whether the receiver should provide data to outputs when a session is running. Clients can set this property to fine tune which media streams from a given input will be used during capture. The default value is YES.
        #[unsafe(method(isEnabled))]
        #[unsafe(method_family = none)]
        pub unsafe fn isEnabled(&self) -> bool;

        /// Setter for [`isEnabled`][Self::isEnabled].
        #[unsafe(method(setEnabled:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setEnabled(&self, enabled: bool);

        #[cfg(feature = "objc2-core-media")]
        /// Provides access to the "native" clock used by the input port.
        ///
        ///
        /// The clock is read-only.
        #[unsafe(method(clock))]
        #[unsafe(method_family = none)]
        pub unsafe fn clock(&self) -> Option<Retained<CMClock>>;

        #[cfg(feature = "AVCaptureDevice")]
        /// The AVCaptureDeviceType of the source device providing input through this port.
        ///
        ///
        /// All AVCaptureInputPorts contained in an AVCaptureDeviceInput's ports array have the same sourceDeviceType, which is equal to deviceInput.device.deviceType. All of these ports are legal for use in an AVCaptureSession. When working with virtual devices such as the DualCamera in an AVCaptureMultiCamSession, it is possible to stream media from the virtual device's constituent device streams by discovering and connecting hidden ports. In the case of the DualCamera, its constituent devices are the WideAngle camera and the Telephoto camera. By calling -[AVCaptureDeviceInput portsWithMediaType:sourceDeviceType:sourceDevicePosition:], you may discover ports originating from one or more of the virtual device's constituent devices and then make connections using those ports. Constituent device ports are never present in their owning virtual device input's ports array. As an example, to find the video port originating from the DualCamera's Telephoto camera constituent device, you call [dualCameraDeviceInput portsWithMediaType:AVMediaTypeVideo sourceDeviceType:AVCaptureDeviceTypeBuiltInTelephotoCamera sourceDevicePosition:dualCamera.position] and use the first port in the resulting array.
        #[unsafe(method(sourceDeviceType))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceDeviceType(&self) -> Option<Retained<AVCaptureDeviceType>>;

        #[cfg(feature = "AVCaptureDevice")]
        /// The AVCaptureDevicePosition of the source device providing input through this port.
        ///
        ///
        /// All AVCaptureInputPorts contained in an AVCaptureDeviceInput's ports array have the same sourceDevicePosition, which is deviceInput.device.position. When working with microphone input in an AVCaptureMultiCamSession, it is possible to record multiple microphone directions simultaneously, for instance, to record front-facing microphone input to pair with video from the front facing camera, and back-facing microphone input to pair with the video from the back-facing camera. By calling -[AVCaptureDeviceInput portsWithMediaType:sourceDeviceType:sourceDevicePosition:], you may discover additional hidden ports originating from the source audio device. These ports represent individual microphones positioned to pick up audio from one particular direction. Examples follow.
        ///
        /// To discover the audio port that captures omnidirectional audio, use [microphoneDeviceInput portsWithMediaType:AVMediaTypeAudio sourceDeviceType:AVCaptureDeviceTypeMicrophone sourceDevicePosition:AVCaptureDevicePositionUnspecified].firstObject.
        /// To discover the audio port that captures front-facing audio, use [microphoneDeviceInput portsWithMediaType:AVMediaTypeAudio sourceDeviceType:AVCaptureDeviceTypeMicrophone sourceDevicePosition:AVCaptureDevicePositionFront].firstObject.
        /// To discover the audio port that captures back-facing audio, use [microphoneDeviceInput portsWithMediaType:AVMediaTypeAudio sourceDeviceType:AVCaptureDeviceTypeMicrophone sourceDevicePosition:AVCaptureDevicePositionBack].firstObject.
        #[unsafe(method(sourceDevicePosition))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceDevicePosition(&self) -> AVCaptureDevicePosition;
    );
}

/// Constants indicating the modes of multichannel audio.
///
///
/// Indicates that no multichannel audio should be used.
///
/// Indicates that the audio should be recorded using stereo.
///
/// Indicates that the audio should be recorded using first-order ambisonics. When recording a QuickTime movie file, a stereo audio track will be recorded alongside the FOA track for backward playback compatibility.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturemultichannelaudiomode?language=objc)
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord)]
pub struct AVCaptureMultichannelAudioMode(pub NSInteger);
impl AVCaptureMultichannelAudioMode {
    #[doc(alias = "AVCaptureMultichannelAudioModeNone")]
    pub const None: Self = Self(0);
    #[doc(alias = "AVCaptureMultichannelAudioModeStereo")]
    pub const Stereo: Self = Self(1);
    #[doc(alias = "AVCaptureMultichannelAudioModeFirstOrderAmbisonics")]
    pub const FirstOrderAmbisonics: Self = Self(2);
}

unsafe impl Encode for AVCaptureMultichannelAudioMode {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for AVCaptureMultichannelAudioMode {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// AVCaptureDeviceInput is a concrete subclass of AVCaptureInput that provides an interface for capturing media from an AVCaptureDevice.
    ///
    ///
    /// Instances of AVCaptureDeviceInput are input sources for AVCaptureSession that provide media data from devices connected to the system, represented by instances of AVCaptureDevice.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput?language=objc)
    #[unsafe(super(AVCaptureInput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVCaptureDeviceInput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureDeviceInput {}
);

impl AVCaptureDeviceInput {
    extern_methods!(
        #[cfg(feature = "AVCaptureDevice")]
        /// Returns an AVCaptureDeviceInput instance that provides media data from the given device.
        ///
        ///
        /// Parameter `device`: An AVCaptureDevice instance to be used for capture.
        ///
        /// Parameter `outError`: On return, if the given device cannot be used for capture, points to an NSError describing the problem.
        ///
        /// Returns: An AVCaptureDeviceInput instance that provides data from the given device, or nil, if the device could not be used for capture.
        ///
        ///
        /// This method returns an instance of AVCaptureDeviceInput that can be used to capture data from an AVCaptureDevice in an AVCaptureSession. This method attempts to open the device for capture, taking exclusive control of it if necessary. If the device cannot be opened because it is no longer available or because it is in use, for example, this method returns nil, and the optional outError parameter points to an NSError describing the problem.
        #[unsafe(method(deviceInputWithDevice:error:_))]
        #[unsafe(method_family = none)]
        pub unsafe fn deviceInputWithDevice_error(
            device: &AVCaptureDevice,
        ) -> Result<Retained<Self>, Retained<NSError>>;

        #[cfg(feature = "AVCaptureDevice")]
        /// Creates an AVCaptureDeviceInput instance that provides media data from the given device.
        ///
        ///
        /// Parameter `device`: An AVCaptureDevice instance to be used for capture.
        ///
        /// Parameter `outError`: On return, if the given device cannot be used for capture, points to an NSError describing the problem.
        ///
        /// Returns: An AVCaptureDeviceInput instance that provides data from the given device, or nil, if the device could not be used for capture.
        ///
        ///
        /// This method creates an instance of AVCaptureDeviceInput that can be used to capture data from an AVCaptureDevice in an AVCaptureSession. This method attempts to open the device for capture, taking exclusive control of it if necessary. If the device cannot be opened because it is no longer available or because it is in use, for example, this method returns nil, and the optional outError parameter points to an NSError describing the problem.
        #[unsafe(method(initWithDevice:error:_))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDevice_error(
            this: Allocated<Self>,
            device: &AVCaptureDevice,
        ) -> Result<Retained<Self>, Retained<NSError>>;

        #[cfg(feature = "AVCaptureDevice")]
        /// The device from which the receiver provides data.
        ///
        ///
        /// The value of this property is the AVCaptureDevice instance that was used to create the receiver.
        #[unsafe(method(device))]
        #[unsafe(method_family = none)]
        pub unsafe fn device(&self) -> Retained<AVCaptureDevice>;

        /// Specifies whether the source device should use the same default auto exposure behaviors for -[AVCaptureSession setSessionPreset:] and -[AVCaptureDevice setActiveFormat:].
        ///
        ///
        /// AVCaptureDevice's activeFormat property may be set two different ways. 1) You set it directly using one of the formats in the device's -formats array, or 2) the AVCaptureSession sets it on your behalf when you set the AVCaptureSession's sessionPreset property. Depending on the device and format, the default auto exposure behavior may be configured differently when you use one method or the other, resulting in non-uniform auto exposure behavior. Auto exposure defaults include min frame rate, max frame rate, and max exposure duration. If you wish to ensure that consistent default behaviors are applied to the device regardless of the API you use to configure the activeFormat, you may set the device input's unifiedAutoExposureDefaultsEnabled property to YES. Default value for this property is NO.
        ///
        /// Note that if you manually set the device's min frame rate, max frame rate, or max exposure duration, your custom values will override the device defaults regardless of whether you've set this property to YES.
        #[unsafe(method(unifiedAutoExposureDefaultsEnabled))]
        #[unsafe(method_family = none)]
        pub unsafe fn unifiedAutoExposureDefaultsEnabled(&self) -> bool;

        /// Setter for [`unifiedAutoExposureDefaultsEnabled`][Self::unifiedAutoExposureDefaultsEnabled].
        #[unsafe(method(setUnifiedAutoExposureDefaultsEnabled:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setUnifiedAutoExposureDefaultsEnabled(
            &self,
            unified_auto_exposure_defaults_enabled: bool,
        );

        #[cfg(all(feature = "AVCaptureDevice", feature = "AVMediaFormat"))]
        /// An accessor method used to retrieve a virtual device's constituent device ports for use in an AVCaptureMultiCamSession.
        ///
        ///
        /// Parameter `mediaType`: The AVMediaType of the port for which you're searching, or nil if all media types should be considered.
        ///
        /// Parameter `sourceDeviceType`: The AVCaptureDeviceType of the port for which you're searching, or nil if source device type is irrelevant.
        ///
        /// Parameter `sourceDevicePosition`: The AVCaptureDevicePosition of the port for which you're searching. AVCaptureDevicePositionUnspecified is germane to audio devices, indicating omnidirectional audio. For other types of capture devices (e.g. cameras), AVCaptureDevicePositionUnspecified means all positions should be considered in the search.
        ///
        ///
        /// Returns: An array of AVCaptureInputPorts satisfying the search criteria, or an empty array could be found.
        ///
        ///
        /// When using AVCaptureMultiCamSession, multiple devices may be run simultaneously. You may also run simultaneous streams from a virtual device such as the Dual Camera. By inspecting a virtual device's constituentDevices property, you can find its underlying physical devices and, using this method, search for ports originating from one of those constituent devices. Note that the AVCaptureInput.ports array does not include constituent device ports for virtual devices. You must use this accessor method to discover the ports for which you're specifically looking. These constituent device ports may be used to make connections to outputs for use with an AVCaptureMultiCamSession. Using the Dual Camera as an example, the AVCaptureInput.ports property exposes only those ports supported by the virtual device (it switches automatically between wide and telephoto cameras according to the zoom factor). You may use this method to find the video ports for the constituentDevices.
        ///
        /// AVCaptureInputPort *wideVideoPort = [dualCameraInput portsWithMediaType:AVMediaTypeVideo sourceDeviceType:AVCaptureDeviceTypeBuiltInWideAngleCamera sourceDevicePosition:AVCaptureDevicePositionBack].firstObject;
        /// AVCaptureInputPort *teleVideoPort = [dualCameraInput portsWithMediaType:AVMediaTypeVideo sourceDeviceType:AVCaptureDeviceTypeBuiltInTelephotoCamera sourceDevicePosition:AVCaptureDevicePositionBack].firstObject;
        ///
        /// These ports may be used to create connections, say, to two AVCaptureVideoDataOutput instances, allowing for synchronized full frame rate delivery of both wide and telephoto streams.
        ///
        /// As of iOS 13, constituent device ports may not be connected to AVCapturePhotoOutput instances. Clients who wish to capture multiple photos from a virtual device should use AVCapturePhotoOutput's virtualDeviceConstituentPhotoDeliveryEnabled feature.
        ///
        /// When used in conjunction with an audio device, this method allows you to discover microphones in different AVCaptureDevicePositions. When you intend to work with an AVCaptureMultiCamSession, you may use these ports to make connections and simultaneously capture both front facing and back facing audio simultaneously to two different outputs. When used with an AVCaptureMultiCamSession, the audio device port whose sourceDevicePosition is AVCaptureDevicePositionUnspecified produces omnidirectional sound.
        #[unsafe(method(portsWithMediaType:sourceDeviceType:sourceDevicePosition:))]
        #[unsafe(method_family = none)]
        pub unsafe fn portsWithMediaType_sourceDeviceType_sourceDevicePosition(
            &self,
            media_type: Option<&AVMediaType>,
            source_device_type: Option<&AVCaptureDeviceType>,
            source_device_position: AVCaptureDevicePosition,
        ) -> Retained<NSArray<AVCaptureInputPort>>;

        #[cfg(feature = "objc2-core-media")]
        /// A property that acts as a modifier to the AVCaptureDevice's activeVideoMinFrameDuration property. Default value is kCMTimeInvalid.
        ///
        ///
        /// An AVCaptureDevice's activeVideoMinFrameDuration property is the reciprocal of its active maximum frame rate. To limit the max frame rate of the capture device, clients may set the device's activeVideoMinFrameDuration to a value supported by the receiver's activeFormat (see AVCaptureDeviceFormat's videoSupportedFrameRateRanges property). Changes you make to the device's activeVideoMinFrameDuration property take effect immediately without disrupting preview. Therefore, the AVCaptureSession must always allocate sufficient resources to allow the device to run at its activeFormat's max allowable frame rate. If you wish to use a particular device format but only ever run it at lower frame rates (for instance, only run a 1080p240 fps format at a max frame rate of 60), you can set the AVCaptureDeviceInput's videoMinFrameDurationOverride property to the reciprocal of the max frame rate you intend to use before starting the session (or within a beginConfiguration / commitConfiguration block while running the session).
        ///
        /// When a device input is added to a session, this property reverts back to the default of kCMTimeInvalid (no override).
        #[unsafe(method(videoMinFrameDurationOverride))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoMinFrameDurationOverride(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`videoMinFrameDurationOverride`][Self::videoMinFrameDurationOverride].
        #[unsafe(method(setVideoMinFrameDurationOverride:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setVideoMinFrameDurationOverride(
            &self,
            video_min_frame_duration_override: CMTime,
        );

        /// Indicates whether the device input supports locked frame durations.
        ///
        /// See ``AVCaptureDeviceInput/activeLockedVideoFrameDuration`` for more information on video frame duration locking.
        #[unsafe(method(isLockedVideoFrameDurationSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isLockedVideoFrameDurationSupported(&self) -> bool;

        #[cfg(feature = "objc2-core-media")]
        /// The receiver's locked frame duration (the reciprocal of its frame rate). Setting this property guarantees the intra-frame duration delivered by the device input is precisely the frame duration you request.
        ///
        /// Set this property to run the receiver's associated ``AVCaptureDevice`` at precisely your provided frame rate (expressed as a duration). Query ``AVCaptureDevice/minSupportedLockedVideoFrameDuration`` to find the minimum value supported by this ``AVCaptureDeviceInput``. In order to disable locked video frame duration, set this property to `kCMTimeInvalid`. This property resets itself to `kCMTimeInvalid` when the receiver's attached ``AVCaptureDevice/activeFormat`` changes. When you set this property, its value is also reflected in the receiver's ``AVCaptureDevice/activeVideoMinFrameDuration`` and ``AVCaptureDevice/activeVideoMaxFrameDuration``.
        ///
        /// - Note: Locked frame duration availability may change depending on the device configuration. For example, locked frame duration is unsupported when ``AVCaptureDevice/autoVideoFrameRateEnabled`` or ``AVCaptureMovieFileOutput/spatialVideoCaptureEnabled`` is set to `true`.
        ///
        /// - Note: Only one ``AVCaptureDeviceInput`` added to an ``AVCaptureMultiCamSession`` can follow an external sync device or run at a locked frame duration.
        ///
        /// - Note: Setting this property may cause a lengthy reconfiguration of the receiver, similar to setting ``AVCaptureDevice/activeFormat`` or ``AVCaptureSession/sessionPreset``.
        ///
        /// - Important: If you set this property to a valid value while the receiver's ``AVCaptureDevice/minSupportedLockedVideoFrameDuration`` is `kCMTimeInvalid`, it throws an `NSInvalidArgumentException`.
        ///
        /// - Important: If you set this property while the receiver's  ``lockedVideoFrameDurationSupported`` property returns `false`, it throws an `NSInvalidArgumentException`.
        #[unsafe(method(activeLockedVideoFrameDuration))]
        #[unsafe(method_family = none)]
        pub unsafe fn activeLockedVideoFrameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`activeLockedVideoFrameDuration`][Self::activeLockedVideoFrameDuration].
        #[unsafe(method(setActiveLockedVideoFrameDuration:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setActiveLockedVideoFrameDuration(
            &self,
            active_locked_video_frame_duration: CMTime,
        );

        /// Indicates whether the device input supports being configured to follow an external sync device.
        ///
        /// See ``AVCaptureDeviceInput/followExternalSyncDevice:videoFrameDuration:delegate:`` for more information on external sync.
        #[unsafe(method(isExternalSyncSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isExternalSyncSupported(&self) -> bool;

        #[cfg(all(feature = "AVExternalSyncDevice", feature = "objc2-core-media"))]
        /// Configures the the device input to follow an external sync device at the given frame duration.
        ///
        /// - Parameter externalSyncDevice: The ``AVExternalSyncDevice`` hardware to follow.
        /// - Parameter videoFrameDuration: The frame duration to which the ``AVExternalSyncDevice`` is calibrated.
        /// - Parameter delegate: The delegate to notify when the connection status changes, or an error occurs.
        ///
        /// Call this method to direct your ``AVCaptureDeviceInput`` to follow the external sync pulse from a sync device at the given frame duration.
        ///
        /// Your provided `videoFrameDuration` value must match the sync pulse duration of the external sync device. If it does not, the request times out, the external sync device's status returns to ``AVExternalSyncDeviceStatusReady``, and your session stops running, posting a ``AVCaptureSessionRuntimeErrorNotification`` with ``AVErrorFollowExternalSyncDeviceTimedOut``.
        ///
        /// The ability to follow an external sync device may change depending on the device configuration. For example, ``followExternalSyncDevice:videoFrameDuration:delegate:`` cannot be used when ``AVCaptureDevice/autoVideoFrameRateEnabled`` is `true`.
        ///
        /// To stop following an external pulse, call ``unfollowExternalSyncDevice``. External sync device following is also disabled when your device's ``AVCaptureDeviceFormat`` changes.
        ///
        /// Your provided delegate's ``AVExternalSyncDeviceDelegate/externalSyncDeviceStatusDidChange:`` method is called with a status of ``AVExternalSyncDeviceStatusReady`` if the external pulse signal is not close enough to the provided `videoFrameDuration` for successful calibration.
        ///
        /// Once your ``AVExternalSyncDevice/status`` changes to ``AVExternalSyncDeviceStatusActiveSync``, your input's  ``AVCaptureInput/activeExternalSyncVideoFrameDuration`` property reports the up-to-date frame duration. ``AVCaptureInput/activeExternalSyncVideoFrameDuration`` is also reflected in the ``AVCaptureDevice/activeVideoMinFrameDuration`` and ``AVCaptureDevice/activeVideoMaxFrameDuration`` of your input's associated device.
        ///
        /// - Note: Calling this method may cause a lengthy reconfiguration of the receiver, similar to setting a new active format or ``AVCaptureSession/sessionPreset``.
        ///
        /// - Important: Calling this method throws an `NSInvalidArgumentException` if ``AVCaptureDeviceInput/externalSyncSupported`` returns `false`.
        ///
        /// - Important: The provided external sync device's ``status`` must be ``AVExternalSyncDeviceStatusReady`` when you call this method, otherwise an `NSInvalidArgumentException` is thrown.
        #[unsafe(method(followExternalSyncDevice:videoFrameDuration:delegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn followExternalSyncDevice_videoFrameDuration_delegate(
            &self,
            external_sync_device: &AVExternalSyncDevice,
            frame_duration: CMTime,
            delegate: Option<&ProtocolObject<dyn AVExternalSyncDeviceDelegate>>,
        );

        #[cfg(feature = "objc2-core-media")]
        /// The receiver's external sync frame duration (the reciprocal of its frame rate) when being driven by an external sync device.
        ///
        /// Set up your input to follow an external sync device by calling ``followExternalSyncDevice:videoFrameDuration:delegate:``.
        /// - Note: The value of this readonly property is `kCMTimeInvalid` unless the ``AVExternalSyncDevice`` is actively driving the ``AVCaptureDeviceInput``. This is reflected by the ``AVExternalSyncDevice/status`` being either ``AVExternalSyncDeviceStatusActiveSync`` or ``AVExternalSyncDeviceStatusFreeRunSync``.
        #[unsafe(method(activeExternalSyncVideoFrameDuration))]
        #[unsafe(method_family = none)]
        pub unsafe fn activeExternalSyncVideoFrameDuration(&self) -> CMTime;

        #[cfg(feature = "AVExternalSyncDevice")]
        /// The external sync device currently being followed by this input.
        ///
        /// This readonly property returns the ``AVExternalSyncDevice`` instance you provided in ``followExternalSyncDevice:videoFrameDuration:delegate:``. This property returns `nil` when an external sync device is disconnected or fails to calibrate.
        #[unsafe(method(externalSyncDevice))]
        #[unsafe(method_family = none)]
        pub unsafe fn externalSyncDevice(&self) -> Option<Retained<AVExternalSyncDevice>>;

        /// Discontinues external sync.
        ///
        /// This method stops your input from syncing to the external sync device you specified in ``followExternalSyncDevice:videoFrameDuration:delegate:``.
        #[unsafe(method(unfollowExternalSyncDevice))]
        #[unsafe(method_family = none)]
        pub unsafe fn unfollowExternalSyncDevice(&self);

        /// Returns whether the receiver supports the given multichannel audio mode.
        ///
        ///
        /// Parameter `multichannelAudioMode`: An AVCaptureMultichannelAudioMode to be checked.
        ///
        /// Returns: YES if the receiver supports the given multichannel audio mode, NO otherwise.
        ///
        ///
        /// The receiver's multichannelAudioMode property can only be set to a certain mode if this method returns YES for that mode.
        ///
        /// Multichannel audio modes are not supported when used in conjunction with AVCaptureMultiCamSession.
        #[unsafe(method(isMultichannelAudioModeSupported:))]
        #[unsafe(method_family = none)]
        pub unsafe fn isMultichannelAudioModeSupported(
            &self,
            multichannel_audio_mode: AVCaptureMultichannelAudioMode,
        ) -> bool;

        /// Indicates the multichannel audio mode to apply when recording audio.
        ///
        ///
        /// This property only takes effect when audio is being routed through the built-in microphone, and is ignored if an external microphone is in use.
        ///
        /// The default value is AVCaptureMultichannelAudioModeNone, in which case the default single channel audio recording is used.
        #[unsafe(method(multichannelAudioMode))]
        #[unsafe(method_family = none)]
        pub unsafe fn multichannelAudioMode(&self) -> AVCaptureMultichannelAudioMode;

        /// Setter for [`multichannelAudioMode`][Self::multichannelAudioMode].
        #[unsafe(method(setMultichannelAudioMode:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setMultichannelAudioMode(
            &self,
            multichannel_audio_mode: AVCaptureMultichannelAudioMode,
        );

        /// Returns whether or not the device supports wind noise removal during audio capture.
        ///
        ///
        /// YES if the device supports wind noise removal, NO otherwise.
        #[unsafe(method(isWindNoiseRemovalSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isWindNoiseRemovalSupported(&self) -> bool;

        /// Specifies whether or not wind noise is removed during audio capture.
        ///
        ///
        /// Wind noise removal is available when the AVCaptureDeviceInput multichannelAudioMode property is set to any value other than AVCaptureMultichannelAudioModeNone.
        #[unsafe(method(isWindNoiseRemovalEnabled))]
        #[unsafe(method_family = none)]
        pub unsafe fn isWindNoiseRemovalEnabled(&self) -> bool;

        /// Setter for [`isWindNoiseRemovalEnabled`][Self::isWindNoiseRemovalEnabled].
        #[unsafe(method(setWindNoiseRemovalEnabled:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setWindNoiseRemovalEnabled(&self, wind_noise_removal_enabled: bool);

        /// A BOOL value specifying whether Cinematic Video capture is supported.
        ///
        /// With Cinematic Video capture, you get a simulated depth-of-field effect that keeps your subjects (people, pets, and more) in sharp focus while applying a pleasing blur to the background (or foreground). Depending on the focus mode (see ``AVCaptureCinematicVideoFocusMode`` for detail), the camera either uses machine learning to automatically detect and focus on subjects in the scene, or it fixes focus on a subject until it exits the scene. Cinematic Videos can be played back and edited using the Cinematic framework.
        ///
        /// You can adjust the video's simulated aperture before starting a recording using the ``simulatedAperture`` property. With Cinematic Video specific focus methods on ``AVCaptureDevice``, you can dynamically control focus transitions.
        ///
        /// Movie files captured with Cinematic Video enabled can be played back and edited with the [Cinematic framework] (https://developer.apple.com/documentation/cinematic/playing-and-editing-cinematic-mode-video?language=objc).
        ///
        /// This property returns `true` if the session's current configuration allows Cinematic Video capture. When switching cameras or formats, this property may change. When this property changes from `true` to `false`, ``cinematicVideoCaptureEnabled`` also reverts to `false`. If you've previously opted in for Cinematic Video capture and then change configuration, you may need to set ``cinematicVideoCaptureEnabled`` to `true` again. This property is key-value observable.
        ///
        /// - Note: ``AVCaptureDepthDataOutput`` is not supported when ``cinematicVideoCaptureEnabled`` is set to `true`. Running an ``AVCaptureSession`` with both of these features throws an `NSInvalidArgumentException`.
        #[unsafe(method(isCinematicVideoCaptureSupported))]
        #[unsafe(method_family = none)]
        pub unsafe fn isCinematicVideoCaptureSupported(&self) -> bool;

        /// A BOOL value specifying whether the Cinematic Video effect is being applied to any movie file output, video data output, metadata output, or video preview layer added to the capture session.
        ///
        /// Default is `false`. Set to `true` to enable support for Cinematic Video capture.
        ///
        /// When you set this property to `true`, your input's associated ``AVCaptureDevice/focusMode`` changes to ``AVCaptureFocusModeContinuousAutoFocus``. While Cinematic Video capture is enabled, you are not permitted to change your device's focus mode, and any attempt to do so results in an `NSInvalidArgumentException`. You may only set this property to `true` if ``cinematicVideoCaptureSupported`` is `true`.
        ///
        /// - Note: Enabling Cinematic Video capture requires a lengthy reconfiguration of the capture render pipeline, so if you intend to capture Cinematic Video, you should set this property to `true` before calling ``AVCaptureSession/startRunning`` or within ``AVCaptureSession/beginConfiguration`` and ``AVCaptureSession/commitConfiguration`` while running.
        #[unsafe(method(isCinematicVideoCaptureEnabled))]
        #[unsafe(method_family = none)]
        pub unsafe fn isCinematicVideoCaptureEnabled(&self) -> bool;

        /// Setter for [`isCinematicVideoCaptureEnabled`][Self::isCinematicVideoCaptureEnabled].
        #[unsafe(method(setCinematicVideoCaptureEnabled:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCinematicVideoCaptureEnabled(&self, cinematic_video_capture_enabled: bool);

        /// Shallow depth of field simulated aperture.
        ///
        /// When capturing a Cinematic Video, use this property to control the amount of blur in the simulated depth of field effect.
        ///
        /// This property only takes effect when ``cinematicVideoCaptureEnabled`` is set to `true`.
        ///
        /// - Important: Setting this property to a value less than the ``AVCaptureDevice/activeFormat/minSimulatedAperture`` or greater than the ``AVCaptureDevice/activeFormat/maxSimulatedAperture`` throws an `NSRangeException`. you may only set this property if ``AVCaptureDevice/activeFormat/minSimulatedAperture`` returns a non-zero value, otherwise an `NSInvalidArgumentException` is thrown. You must set this property before starting a Cinematic Video capture. If you attempt to set it while a recording is in progress, an `NSInvalidArgumentException` is thrown.
        ///
        /// This property is initialized to the associated ``AVCaptureDevice/activeFormat/defaultSimulatedAperture``.
        ///
        /// This property is key-value observable.
        #[unsafe(method(simulatedAperture))]
        #[unsafe(method_family = none)]
        pub unsafe fn simulatedAperture(&self) -> c_float;

        /// Setter for [`simulatedAperture`][Self::simulatedAperture].
        #[unsafe(method(setSimulatedAperture:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSimulatedAperture(&self, simulated_aperture: c_float);
    );
}

/// Methods declared on superclass `AVCaptureInput`.
impl AVCaptureDeviceInput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// AVCaptureScreenInput is a concrete subclass of AVCaptureInput that provides an interface for capturing media from a screen or portion thereof.
    ///
    ///
    /// Instances of AVCaptureScreenInput are input sources for AVCaptureSession that provide media data from one of the screens connected to the system, represented by CGDirectDisplayIDs.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturescreeninput?language=objc)
    #[unsafe(super(AVCaptureInput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVCaptureScreenInput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureScreenInput {}
);

impl AVCaptureScreenInput {
    extern_methods!(
        /// Creates an AVCaptureScreenInput instance that provides media data from the main display.
        ///
        ///
        /// This method creates an instance of AVCaptureScreenInput using the main display whose id is returned from CGMainDisplayID().
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "objc2-core-graphics")]
        /// Creates an AVCaptureScreenInput instance that provides media data from the given display.
        ///
        ///
        /// Parameter `displayID`: The id of the display from which to capture video. CGDirectDisplayID is defined in
        /// <CoreGraphics
        /// /CGDirectDisplay.h>
        ///
        /// Returns: An AVCaptureScreenInput instance that provides data from the given screen, or nil, if the screen could not be used for capture.
        ///
        ///
        /// This method creates an instance of AVCaptureScreenInput that can be used to capture data from a display in an AVCaptureSession. This method validates the displayID. If the display cannot be used because it is not available on the system, for example, this method returns nil.
        #[unsafe(method(initWithDisplayID:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithDisplayID(
            this: Allocated<Self>,
            display_id: CGDirectDisplayID,
        ) -> Option<Retained<Self>>;

        #[cfg(feature = "objc2-core-media")]
        /// A property indicating the screen input's minimum frame duration.
        ///
        ///
        /// An AVCaptureScreenInput's minFrameDuration is the reciprocal of its maximum frame rate. This property may be used to request a maximum frame rate at which the input produces video frames. The requested rate may not be achievable due to overall bandwidth, so actual frame rates may be lower.
        #[unsafe(method(minFrameDuration))]
        #[unsafe(method_family = none)]
        pub unsafe fn minFrameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`minFrameDuration`][Self::minFrameDuration].
        #[unsafe(method(setMinFrameDuration:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setMinFrameDuration(&self, min_frame_duration: CMTime);

        #[cfg(feature = "objc2-core-foundation")]
        /// A property indicating the bounding rectangle of the screen area to be captured in points.
        ///
        ///
        /// By default, AVCaptureScreenInput captures the entire area of the displayID with which it is associated. To limit the capture rectangle to a subsection of the screen, set the cropRect property, which defines a smaller section of the screen in the screen's coordinate system. The origin (0,0) is the bottom-left corner of the screen.
        #[unsafe(method(cropRect))]
        #[unsafe(method_family = none)]
        pub unsafe fn cropRect(&self) -> CGRect;

        #[cfg(feature = "objc2-core-foundation")]
        /// Setter for [`cropRect`][Self::cropRect].
        #[unsafe(method(setCropRect:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCropRect(&self, crop_rect: CGRect);

        #[cfg(feature = "objc2-core-foundation")]
        /// A property indicating the factor by which video buffers captured from the screen are to be scaled.
        ///
        ///
        /// By default, AVCaptureScreenInput captures the video buffers from the display at a scale factor of 1.0 (no scaling). Set this property to scale the buffers by a given factor. For instance, a 320x240 capture area with a scaleFactor of 2.0f produces video buffers at 640x480.
        #[unsafe(method(scaleFactor))]
        #[unsafe(method_family = none)]
        pub unsafe fn scaleFactor(&self) -> CGFloat;

        #[cfg(feature = "objc2-core-foundation")]
        /// Setter for [`scaleFactor`][Self::scaleFactor].
        #[unsafe(method(setScaleFactor:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setScaleFactor(&self, scale_factor: CGFloat);

        /// A property indicating whether mouse clicks should be highlighted in the captured output.
        ///
        ///
        /// By default, AVCaptureScreenInput does not highlight mouse clicks in its captured output. If this property is set to YES, mouse clicks are highlighted (a circle is drawn around the mouse for the duration of the click) in the captured output.
        #[unsafe(method(capturesMouseClicks))]
        #[unsafe(method_family = none)]
        pub unsafe fn capturesMouseClicks(&self) -> bool;

        /// Setter for [`capturesMouseClicks`][Self::capturesMouseClicks].
        #[unsafe(method(setCapturesMouseClicks:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCapturesMouseClicks(&self, captures_mouse_clicks: bool);

        /// A property indicating whether the cursor should be rendered to the captured output.
        ///
        ///
        /// By default, AVCaptureScreenInput draws the cursor in its captured output. If this property is set to NO, the captured output contains only the windows on the screen. Cursor is omitted. Note that cursor position and mouse button state at the time of capture is preserved in CMSampleBuffers emitted from AVCaptureScreenInput. See the inline documentation for kCMIOSampleBufferAttachmentKey_MouseAndKeyboardModifiers in
        /// <CoreMediaIO
        /// /CMIOSampleBuffer.h>
        #[unsafe(method(capturesCursor))]
        #[unsafe(method_family = none)]
        pub unsafe fn capturesCursor(&self) -> bool;

        /// Setter for [`capturesCursor`][Self::capturesCursor].
        #[unsafe(method(setCapturesCursor:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCapturesCursor(&self, captures_cursor: bool);

        /// A property indicating whether duplicate frames should be removed by the input.
        ///
        ///
        /// If this property is set to YES, AVCaptureScreenInput performs frame differencing and when it detects duplicate frames, it drops them. If set to NO, the captured output receives all frames from the input. Prior to 10.9 this value defaulted to YES. In 10.9 and later, it defaults to NO, as modern platforms support frame differencing in hardware-based encoders.
        ///
        /// As of 10.10, this property has been deprecated and is ignored. Clients wishing to re-create this functionality can use an AVCaptureVideoDataOutput and compare frame contents in their own code. If they wish to write a movie file, they can then pass the unique frames to an AVAssetWriterInput.
        #[deprecated = "No longer supported."]
        #[unsafe(method(removesDuplicateFrames))]
        #[unsafe(method_family = none)]
        pub unsafe fn removesDuplicateFrames(&self) -> bool;

        /// Setter for [`removesDuplicateFrames`][Self::removesDuplicateFrames].
        #[deprecated = "No longer supported."]
        #[unsafe(method(setRemovesDuplicateFrames:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setRemovesDuplicateFrames(&self, removes_duplicate_frames: bool);
    );
}

extern_class!(
    /// AVCaptureMetadataInput is a concrete subclass of AVCaptureInput that provides a way for clients to supply AVMetadataItems to an AVCaptureSession.
    ///
    ///
    /// Instances of AVCaptureMetadataInput are input sources for AVCaptureSession that provide AVMetadataItems to an AVCaptureSession. AVCaptureMetadataInputs present one and only one AVCaptureInputPort, which currently may only be connected to an AVCaptureMovieFileOutput. The metadata supplied over the input port is provided by the client, and must conform to a client-supplied CMFormatDescription. The AVMetadataItems are supplied in an AVTimedMetadataGroup.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput?language=objc)
    #[unsafe(super(AVCaptureInput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVCaptureMetadataInput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureMetadataInput {}
);

impl AVCaptureMetadataInput {
    extern_methods!(
        #[cfg(feature = "objc2-core-media")]
        /// Returns an AVCaptureMetadataInput instance that allows a client to provide AVTimedMetadataGroups to an AVCaptureSession.
        ///
        ///
        /// Parameter `desc`: A CMFormatDescription that defines the metadata to be supplied by the client. Throws an NSInvalidArgumentException if NULL is passed.
        ///
        /// Parameter `clock`: A CMClock that provided the timebase for the supplied samples. Throws an NSInvalidArgumentException if NULL is passed.
        ///
        /// Returns: An AVCaptureMetadataInput instance.
        ///
        ///
        /// This method returns an instance of AVCaptureMetadataInput that can be used to capture AVTimedMetadataGroups supplied by the client to an AVCaptureSession.
        #[unsafe(method(metadataInputWithFormatDescription:clock:))]
        #[unsafe(method_family = none)]
        pub unsafe fn metadataInputWithFormatDescription_clock(
            desc: &CMMetadataFormatDescription,
            clock: &CMClock,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-core-media")]
        /// Creates an AVCaptureMetadataInput instance that allows a client to provide AVTimedMetadataGroups to an AVCaptureSession.
        ///
        ///
        /// Parameter `desc`: A CMFormatDescription that defines the metadata to be supplied by the client. Throws NSInvalidArgumentException if NULL is passed.
        ///
        /// Parameter `clock`: A CMClock that provided the timebase for the supplied samples. Throws NSInvalidArgumentException if NULL is passed.
        ///
        /// Returns: An AVCaptureMetadataInput instance, or nil, if the device could not be used for capture.
        ///
        ///
        /// This method creates an instance of AVCaptureMetadataInput that can be used to capture AVTimedMetadataGroups supplied by the client to an AVCaptureSession.
        #[unsafe(method(initWithFormatDescription:clock:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithFormatDescription_clock(
            this: Allocated<Self>,
            desc: &CMMetadataFormatDescription,
            clock: &CMClock,
        ) -> Retained<Self>;

        #[cfg(feature = "AVTimedMetadataGroup")]
        /// Provides metadata to the AVCaptureSession.
        ///
        ///
        /// Parameter `metadata`: An AVTimedMetadataGroup of metadata. Will throw an exception if nil. In order to denote a period of no metadata, an empty AVTimedMetadataGroup should be passed.
        ///
        ///
        /// The provided AVTimedMetadataGroup will be provided to the AVCaptureSession. The group's presentation timestamp is expressed in the context of the clock supplied to the initializer. It is not required that the AVTimedMetadataGroup have a duration; an empty AVTimedMetadataGroup can be supplied to denote a period of no metadata.
        #[unsafe(method(appendTimedMetadataGroup:error:_))]
        #[unsafe(method_family = none)]
        pub unsafe fn appendTimedMetadataGroup_error(
            &self,
            metadata: &AVTimedMetadataGroup,
        ) -> Result<(), Retained<NSError>>;
    );
}

/// Methods declared on superclass `AVCaptureInput`.
impl AVCaptureMetadataInput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}
