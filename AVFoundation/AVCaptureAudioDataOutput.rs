//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
#[cfg(feature = "dispatch2")]
use dispatch2::*;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-audio-types")]
use objc2_core_audio_types::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// AVCaptureAudioDataOutput is a concrete subclass of AVCaptureOutput that can be used to process uncompressed or compressed samples from the audio being captured.
    ///
    ///
    /// Instances of AVCaptureAudioDataOutput produce audio sample buffers suitable for processing using other media APIs. Applications can access the sample buffers with the captureOutput:didOutputSampleBuffer:fromConnection: delegate method.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcaptureaudiodataoutput?language=objc)
    #[unsafe(super(AVCaptureOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "AVCaptureOutputBase")]
    pub struct AVCaptureAudioDataOutput;
);

#[cfg(feature = "AVCaptureOutputBase")]
extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureAudioDataOutput {}
);

#[cfg(feature = "AVCaptureOutputBase")]
impl AVCaptureAudioDataOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "dispatch2")]
        /// Sets the receiver's delegate that will accept captured buffers and dispatch queue on which the delegate will be called.
        ///
        ///
        /// Parameter `sampleBufferDelegate`: An object conforming to the AVCaptureAudioDataOutputSampleBufferDelegate protocol that will receive sample buffers after they are captured.
        ///
        /// Parameter `sampleBufferCallbackQueue`: A dispatch queue on which all sample buffer delegate methods will be called.
        ///
        ///
        /// When a new audio sample buffer is captured it will be vended to the sample buffer delegate using the captureOutput:didOutputSampleBuffer:fromConnection: delegate method. All delegate methods will be called on the specified dispatch queue. If the queue is blocked when new samples are captured, those samples will be automatically dropped when they become sufficiently late. This allows clients to process existing samples on the same queue without having to manage the potential memory usage increases that would otherwise occur when that processing is unable to keep up with the rate of incoming samples.
        ///
        /// Clients that need to minimize the chances of samples being dropped should specify a queue on which a sufficiently small amount of processing is being done outside of receiving sample buffers. However, if such clients migrate extra processing to another queue, they are responsible for ensuring that memory usage does not grow without bound from samples that have not been processed.
        ///
        /// A serial dispatch queue must be used to guarantee that audio samples will be delivered in order. The sampleBufferCallbackQueue parameter may not be NULL, except when setting sampleBufferDelegate to nil otherwise -setSampleBufferDelegate:queue: throws an NSInvalidArgumentException.
        #[unsafe(method(setSampleBufferDelegate:queue:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSampleBufferDelegate_queue(
            &self,
            sample_buffer_delegate: Option<
                &ProtocolObject<dyn AVCaptureAudioDataOutputSampleBufferDelegate>,
            >,
            sample_buffer_callback_queue: Option<&DispatchQueue>,
        );

        /// The receiver's delegate.
        ///
        ///
        /// The value of this property is an object conforming to the AVCaptureAudioDataOutputSampleBufferDelegate protocol that will receive sample buffers after they are captured. The delegate is set using the setSampleBufferDelegate:queue: method.
        #[unsafe(method(sampleBufferDelegate))]
        #[unsafe(method_family = none)]
        pub unsafe fn sampleBufferDelegate(
            &self,
        ) -> Option<Retained<ProtocolObject<dyn AVCaptureAudioDataOutputSampleBufferDelegate>>>;

        #[cfg(feature = "dispatch2")]
        /// The dispatch queue on which all sample buffer delegate methods will be called.
        ///
        ///
        /// The value of this property is a dispatch_queue_t. The queue is set using the setSampleBufferDelegate:queue: method.
        #[unsafe(method(sampleBufferCallbackQueue))]
        #[unsafe(method_family = none)]
        pub unsafe fn sampleBufferCallbackQueue(&self) -> Option<Retained<DispatchQueue>>;

        /// Specifies the settings used to decode or re-encode audio before it is output by the receiver.
        ///
        ///
        /// The value of this property is an NSDictionary containing values for audio settings keys defined in AVAudioSettings.h. When audioSettings is set to nil, the AVCaptureAudioDataOutput vends samples in their device native format.
        #[unsafe(method(audioSettings))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioSettings(&self) -> Retained<NSDictionary<NSString, AnyObject>>;

        /// Setter for [`audioSettings`][Self::audioSettings].
        #[unsafe(method(setAudioSettings:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAudioSettings(
            &self,
            audio_settings: Option<&NSDictionary<NSString, AnyObject>>,
        );

        #[cfg(feature = "objc2-core-audio-types")]
        /// Specifies the audio channel layout tag that describes the audio channel layout to be output by the AVCaptureAudioDataOutput.
        ///
        ///
        /// The value of this property is from the AudioChannelLayoutTag enumeration defined in CoreAudioBaseTypes.h. Currently, the only two supported values are kAudioChannelLayoutTag_Stereo or ( kAudioChannelLayoutTag_HOA_ACN_SN3D | 4 ) which will provide either a Stereo channel pair or four channels of First Order Ambisonic audio data output. The default value is kAudioChannelLayoutTag_Unknown which results in an AudioChannelLayout determined by the AVCaptureDeviceInput's configuration.
        ///
        /// The rules for allowed values in a given AVCaptureSession are as follows:
        ///
        /// When the associated AVCaptureDeviceInput's multichannelAudioMode property is set to AVCaptureMultichannelAudioModeFirstOrderAmbisonics, the AVCaptureSession can support up to two AVCaptureAudioDataOutput instances. If a single AVCaptureAudioDataOutput is present it can produce either four channels of First Order Ambisonic audio or two channels of Stereo audio. If two AVCaptureAudioDataOutputs are present, one of them must output four channels of First Order Ambisonic audio and the other must output two channels of Stereo audio.
        ///
        /// When the associated AVCaptureDeviceInput's multichannelAudioMode property is set to anything other than AVCaptureMultichannelAudioModeFirstOrderAmbisonics, there must be only one AVCaptureAudioDataOutput present in the AVCaptureSession with its spatialAudioChannelLayoutTag property set to kAudioChannelLayoutTag_Unknown or left at the default value.
        ///
        /// These rules are validated when a client calls -[AVCaptureSession startRunning:] or -[AVCaptureSession commitConfiguration:]. If the validation fails an exception will be thrown indicating the invalid setting and the session will not start running.
        #[unsafe(method(spatialAudioChannelLayoutTag))]
        #[unsafe(method_family = none)]
        pub unsafe fn spatialAudioChannelLayoutTag(&self) -> AudioChannelLayoutTag;

        #[cfg(feature = "objc2-core-audio-types")]
        /// Setter for [`spatialAudioChannelLayoutTag`][Self::spatialAudioChannelLayoutTag].
        #[unsafe(method(setSpatialAudioChannelLayoutTag:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSpatialAudioChannelLayoutTag(
            &self,
            spatial_audio_channel_layout_tag: AudioChannelLayoutTag,
        );

        #[cfg(feature = "AVMediaFormat")]
        /// Specifies the recommended settings for use with an AVAssetWriterInput.
        ///
        ///
        /// Parameter `outputFileType`: Specifies the UTI of the file type to be written (see AVMediaFormat.h for a list of file format UTIs).
        ///
        /// Returns: A fully populated dictionary of keys and values that are compatible with AVAssetWriter.
        ///
        ///
        /// The value of this property is an NSDictionary containing values for compression settings keys defined in AVAudioSettings.h. This dictionary is suitable for use as the "outputSettings" parameter when creating an AVAssetWriterInput, such as,
        ///
        /// [AVAssetWriterInput assetWriterInputWithMediaType:AVMediaTypeAudio outputSettings:outputSettings sourceFormatHint:hint];
        ///
        /// The dictionary returned contains all necessary keys and values needed by AVAssetWriter (see AVAssetWriterInput.h, -initWithMediaType:outputSettings: for a more in depth discussion). For QuickTime movie and ISO files, the recommended audio settings will always produce output comparable to that of AVCaptureMovieFileOutput.
        ///
        /// Note that the dictionary of settings is dependent on the current configuration of the receiver's AVCaptureSession and its inputs. The settings dictionary may change if the session's configuration changes. As such, you should configure your session first, then query the recommended audio settings.
        #[unsafe(method(recommendedAudioSettingsForAssetWriterWithOutputFileType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn recommendedAudioSettingsForAssetWriterWithOutputFileType(
            &self,
            output_file_type: &AVFileType,
        ) -> Option<Retained<NSDictionary<NSString, AnyObject>>>;
    );
}

extern_protocol!(
    /// Defines an interface for delegates of AVCaptureAudioDataOutput to receive captured audio sample buffers.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcaptureaudiodataoutputsamplebufferdelegate?language=objc)
    pub unsafe trait AVCaptureAudioDataOutputSampleBufferDelegate: NSObjectProtocol {
        #[cfg(all(
            feature = "AVCaptureOutputBase",
            feature = "AVCaptureSession",
            feature = "objc2-core-media"
        ))]
        /// Called whenever an AVCaptureAudioDataOutput instance outputs a new audio sample buffer.
        ///
        ///
        /// Parameter `output`: The AVCaptureAudioDataOutput instance that output the samples.
        ///
        /// Parameter `sampleBuffer`: A CMSampleBuffer object containing the audio samples and additional information about them, such as their format and presentation time.
        ///
        /// Parameter `connection`: The AVCaptureConnection from which the audio was received.
        ///
        ///
        /// Delegates receive this message whenever the output captures and outputs new audio samples, decoding or re-encoding as specified by the audioSettings property. Delegates can use the provided sample buffer in conjunction with other APIs for further processing. This method will be called on the dispatch queue specified by the output's sampleBufferCallbackQueue property. This method is called periodically, so it must be efficient to prevent capture performance problems, including dropped audio samples.
        ///
        /// Clients that need to reference the CMSampleBuffer object outside of the scope of this method must CFRetain it and then CFRelease it when they are finished with it.
        #[optional]
        #[unsafe(method(captureOutput:didOutputSampleBuffer:fromConnection:))]
        #[unsafe(method_family = none)]
        unsafe fn captureOutput_didOutputSampleBuffer_fromConnection(
            &self,
            output: &AVCaptureOutput,
            sample_buffer: &CMSampleBuffer,
            connection: &AVCaptureConnection,
        );
    }
);
