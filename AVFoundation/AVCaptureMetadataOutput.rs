//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
#[cfg(feature = "dispatch2")]
use dispatch2::*;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-foundation")]
use objc2_core_foundation::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// AVCaptureMetadataOutput is a concrete subclass of AVCaptureOutput that can be used to process metadata objects from an attached connection.
    ///
    ///
    /// Instances of AVCaptureMetadataOutput emit arrays of AVMetadataObject instances (see AVMetadataObject.h), such as detected faces. Applications can access the metadata objects with the captureOutput:didOutputMetadataObjects:fromConnection: delegate method.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutput?language=objc)
    #[unsafe(super(AVCaptureOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    #[cfg(feature = "AVCaptureOutputBase")]
    pub struct AVCaptureMetadataOutput;
);

#[cfg(feature = "AVCaptureOutputBase")]
extern_conformance!(
    unsafe impl NSObjectProtocol for AVCaptureMetadataOutput {}
);

#[cfg(feature = "AVCaptureOutputBase")]
impl AVCaptureMetadataOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "dispatch2")]
        /// Sets the receiver's delegate that will accept metadata objects and dispatch queue on which the delegate will be called.
        ///
        ///
        /// Parameter `objectsDelegate`: An object conforming to the AVCaptureMetadataOutputObjectsDelegate protocol that will receive metadata objects after they are captured.
        ///
        /// Parameter `objectsCallbackQueue`: A dispatch queue on which all delegate methods will be called.
        ///
        ///
        /// When new metadata objects are captured in the receiver's connection, they will be vended to the delegate using the captureOutput:didOutputMetadataObjects:fromConnection: delegate method. All delegate methods will be called on the specified dispatch queue.
        ///
        /// Clients that need to minimize the chances of metadata being dropped should specify a queue on which a sufficiently small amount of processing is performed along with receiving metadata objects.
        ///
        /// A serial dispatch queue must be used to guarantee that metadata objects will be delivered in order. The objectsCallbackQueue parameter may not be NULL, except when setting the objectsDelegate to nil otherwise -setMetadataObjectsDelegate:queue: throws an NSInvalidArgumentException.
        ///
        /// # Safety
        ///
        /// `objects_callback_queue` possibly has additional threading requirements.
        #[unsafe(method(setMetadataObjectsDelegate:queue:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setMetadataObjectsDelegate_queue(
            &self,
            objects_delegate: Option<&ProtocolObject<dyn AVCaptureMetadataOutputObjectsDelegate>>,
            objects_callback_queue: Option<&DispatchQueue>,
        );

        /// The receiver's delegate.
        ///
        ///
        /// The value of this property is an object conforming to the AVCaptureMetadataOutputObjectsDelegate protocol that will receive metadata objects after they are captured. The delegate is set using the setMetadataObjectsDelegate:queue: method.
        #[unsafe(method(metadataObjectsDelegate))]
        #[unsafe(method_family = none)]
        pub unsafe fn metadataObjectsDelegate(
            &self,
        ) -> Option<Retained<ProtocolObject<dyn AVCaptureMetadataOutputObjectsDelegate>>>;

        #[cfg(feature = "dispatch2")]
        /// The dispatch queue on which all metadata object delegate methods will be called.
        ///
        ///
        /// The value of this property is a dispatch_queue_t. The queue is set using the setMetadataObjectsDelegate:queue: method.
        #[unsafe(method(metadataObjectsCallbackQueue))]
        #[unsafe(method_family = none)]
        pub unsafe fn metadataObjectsCallbackQueue(&self) -> Option<Retained<DispatchQueue>>;

        #[cfg(feature = "AVMetadataObject")]
        /// Indicates the receiver's supported metadata object types.
        ///
        ///
        /// The value of this property is an NSArray of NSStrings corresponding to AVMetadataObjectType strings defined in AVMetadataObject.h -- one for each metadata object type supported by the receiver. Available metadata object types are dependent on the capabilities of the AVCaptureInputPort to which this receiver's AVCaptureConnection is connected. Clients may specify the types of objects they would like to process by calling setMetadataObjectTypes:. This property is key-value observable.
        #[unsafe(method(availableMetadataObjectTypes))]
        #[unsafe(method_family = none)]
        pub unsafe fn availableMetadataObjectTypes(
            &self,
        ) -> Retained<NSArray<AVMetadataObjectType>>;

        #[cfg(feature = "AVMetadataObject")]
        /// Specifies the types of metadata objects that the receiver should present to the client.
        ///
        ///
        /// AVCaptureMetadataOutput may detect and emit multiple metadata object types. For apps linked before iOS 7.0, the receiver defaults to capturing face metadata objects if supported (see -availableMetadataObjectTypes). For apps linked on or after iOS 7.0, the receiver captures no metadata objects by default. -setMetadataObjectTypes: throws an NSInvalidArgumentException if any elements in the array are not present in the -availableMetadataObjectTypes array.
        ///
        /// If you've set your AVCaptureMetadataOutput's connected input's `cinematicVideoCaptureEnabled` property to YES, you must set your `metadataObjectTypes` property to `requiredMetadataObjectTypesForCinematicVideoCapture` or an NSInvalidArgumentException is thrown.
        #[unsafe(method(metadataObjectTypes))]
        #[unsafe(method_family = none)]
        pub unsafe fn metadataObjectTypes(&self) -> Retained<NSArray<AVMetadataObjectType>>;

        #[cfg(feature = "AVMetadataObject")]
        /// Setter for [`metadataObjectTypes`][Self::metadataObjectTypes].
        ///
        /// This is [copied][objc2_foundation::NSCopying::copy] when set.
        #[unsafe(method(setMetadataObjectTypes:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setMetadataObjectTypes(
            &self,
            metadata_object_types: Option<&NSArray<AVMetadataObjectType>>,
        );

        #[cfg(feature = "objc2-core-foundation")]
        /// Specifies a rectangle of interest for limiting the search area for visual metadata.
        ///
        ///
        /// The value of this property is a CGRect that determines the receiver's rectangle of interest for each frame of video. The rectangle's origin is top left and is relative to the coordinate space of the device providing the metadata. Specifying a rectOfInterest may improve detection performance for certain types of metadata. The default value of this property is the value CGRectMake(0, 0, 1, 1). Metadata objects whose bounds do not intersect with the rectOfInterest will not be returned.
        ///
        /// As of iOS 13, this property can be set without requiring a lengthy rebuild of the session in which video preview is disrupted.
        #[unsafe(method(rectOfInterest))]
        #[unsafe(method_family = none)]
        pub unsafe fn rectOfInterest(&self) -> CGRect;

        #[cfg(feature = "objc2-core-foundation")]
        /// Setter for [`rectOfInterest`][Self::rectOfInterest].
        #[unsafe(method(setRectOfInterest:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setRectOfInterest(&self, rect_of_interest: CGRect);

        #[cfg(feature = "AVMetadataObject")]
        /// The required metadata object types when Cinematic Video capture is enabled.
        ///
        /// Since the Cinematic Video algorithm requires a particular set of metadata objects to function optimally, you must set your ``metadataObjectTypes`` property to this property's returned value if you've set ``AVCaptureDeviceInput/cinematicVideoCaptureEnabled`` to `true` on the connected device input, otherwise an `NSInvalidArgumentException` is thrown.
        #[unsafe(method(requiredMetadataObjectTypesForCinematicVideoCapture))]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredMetadataObjectTypesForCinematicVideoCapture(
            &self,
        ) -> Retained<NSArray<AVMetadataObjectType>>;
    );
}

extern_protocol!(
    /// Defines an interface for delegates of AVCaptureMetadataOutput to receive emitted objects.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutputobjectsdelegate?language=objc)
    pub unsafe trait AVCaptureMetadataOutputObjectsDelegate: NSObjectProtocol {
        #[cfg(all(
            feature = "AVCaptureOutputBase",
            feature = "AVCaptureSession",
            feature = "AVMetadataObject"
        ))]
        /// Called whenever an AVCaptureMetadataOutput instance emits new objects through a connection.
        ///
        ///
        /// Parameter `output`: The AVCaptureMetadataOutput instance that emitted the objects.
        ///
        /// Parameter `metadataObjects`: An array of AVMetadataObject subclasses (see AVMetadataObject.h).
        ///
        /// Parameter `connection`: The AVCaptureConnection through which the objects were emitted.
        ///
        ///
        /// Delegates receive this message whenever the output captures and emits new objects, as specified by its metadataObjectTypes property. Delegates can use the provided objects in conjunction with other APIs for further processing. This method will be called on the dispatch queue specified by the output's metadataObjectsCallbackQueue property. This method may be called frequently, so it must be efficient to prevent capture performance problems, including dropped metadata objects.
        ///
        /// Clients that need to reference metadata objects outside of the scope of this method must retain them and then release them when they are finished with them.
        #[optional]
        #[unsafe(method(captureOutput:didOutputMetadataObjects:fromConnection:))]
        #[unsafe(method_family = none)]
        unsafe fn captureOutput_didOutputMetadataObjects_fromConnection(
            &self,
            output: &AVCaptureMetadataOutput,
            metadata_objects: &NSArray<AVMetadataObject>,
            connection: &AVCaptureConnection,
        );
    }
);
