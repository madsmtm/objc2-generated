//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-foundation")]
use objc2_core_foundation::*;
#[cfg(feature = "objc2-core-graphics")]
use objc2_core_graphics::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
use objc2_foundation::*;
#[cfg(feature = "objc2-quartz-core")]
#[cfg(not(target_os = "watchos"))]
use objc2_quartz_core::*;

use crate::*;

/// Configures policy for per frame HDR display metadata
///
/// Determines what HDR display metadata should be attached to the rendered frame.
///
/// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicy?language=objc)
// NS_TYPED_ENUM
pub type AVVideoCompositionPerFrameHDRDisplayMetadataPolicy = NSString;

extern "C" {
    /// Default. Pass the HDR metadata through, if present on the composed frame.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicypropagate?language=objc)
    pub static AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate:
        &'static AVVideoCompositionPerFrameHDRDisplayMetadataPolicy;
}

extern "C" {
    /// AVVideoComposition may generate HDR metadata and attach it to the rendered frame. HDR metadata generation is influenced by the color space of the rendered frame, device, and HDR metadata format platform support. Any previously attached HDR metadata of the same metadata format will be overwritten.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionperframehdrdisplaymetadatapolicygenerate?language=objc)
    pub static AVVideoCompositionPerFrameHDRDisplayMetadataPolicyGenerate:
        &'static AVVideoCompositionPerFrameHDRDisplayMetadataPolicy;
}

extern_class!(
    /// An AVVideoComposition object represents an immutable video composition.
    ///
    /// A video composition describes, for any time in the aggregate time range of its instructions, the number and IDs of video tracks that are to be used in order to produce a composed video frame corresponding to that time. When AVFoundation's built-in video compositor is used, the instructions an AVVideoComposition contain can specify a spatial transformation, an opacity value, and a cropping rectangle for each video source, and these can vary over time via simple linear ramping functions.
    ///
    /// A client can implement their own custom video compositor by implementing the AVVideoCompositing protocol; a custom video compositor is provided with pixel buffers for each of its video sources during playback and other operations and can perform arbitrary graphical operations on them in order to produce visual output.
    ///
    /// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocomposition?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoComposition;
);

extern_conformance!(
    unsafe impl NSCopying for AVVideoComposition {}
);

unsafe impl CopyingHelper for AVVideoComposition {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVVideoComposition {}
);

unsafe impl MutableCopyingHelper for AVVideoComposition {
    type Result = AVMutableVideoComposition;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoComposition {}
);

impl AVVideoComposition {
    extern_methods!(
        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// The returned AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVVideoComposition instance with an empty collection of instructions.
        ///
        /// - Parameter asset: An instance of AVAsset. Ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// - Returns: An instance of AVVideoComposition.
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:completionHandler: instead"]
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset(
            asset: &AVAsset,
        ) -> Retained<AVVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// The new AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVVideoComposition instance with an empty collection of instructions.
        ///
        /// - Parameter asset: An instance of AVAsset.
        /// - Parameter completionHandler: A block that is invoked when the new video composition has finished being created. If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_completionHandler(
            asset: &AVAsset,
            completion_handler: &block2::DynBlock<dyn Fn(*mut AVVideoComposition, *mut NSError)>,
        );

        /// Pass-through initializer, for internal use in AVFoundation only
        #[unsafe(method(videoCompositionWithVideoComposition:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithVideoComposition(
            video_composition: &AVVideoComposition,
        ) -> Retained<AVVideoComposition>;

        #[cfg(feature = "AVVideoCompositing")]
        /// Indicates a custom compositor class to use. The class must implement the AVVideoCompositing protocol. If nil, the default, internal video compositor is used
        #[unsafe(method(customVideoCompositorClass))]
        #[unsafe(method_family = none)]
        pub unsafe fn customVideoCompositorClass(&self) -> Option<&'static AnyClass>;

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the interval which the video composition, when enabled, should render composed video frames
        #[unsafe(method(frameDuration))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// If sourceTrackIDForFrameTiming is not kCMPersistentTrackID_Invalid, frame timing for the video composition is derived from the source asset's track with the corresponding ID. This may be used to preserve a source asset's variable frame timing. If an empty edit is encountered in the source assetâ€™s track, the compositor composes frames as needed up to the frequency specified in frameDuration property. */
        #[unsafe(method(sourceTrackIDForFrameTiming))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceTrackIDForFrameTiming(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-foundation")]
        /// Indicates the size at which the video composition, when enabled, should render
        #[unsafe(method(renderSize))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderSize(&self) -> CGSize;

        /// Indicates the scale at which the video composition should render. May only be other than 1.0 for a video composition set on an AVPlayerItem
        #[unsafe(method(renderScale))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderScale(&self) -> c_float;

        #[cfg(feature = "AVVideoCompositing")]
        /// Indicates instructions for video composition via an NSArray of instances of classes implementing the AVVideoCompositionInstruction protocol. For the first instruction in the array, timeRange.start must be less than or equal to the earliest time for which playback or other processing will be attempted (note that this will typically be kCMTimeZero). For subsequent instructions, timeRange.start must be equal to the prior instruction's end time. The end time of the last instruction must be greater than or equal to the latest time for which playback or other processing will be attempted (note that this will often be the duration of the asset with which the instance of AVVideoComposition is associated).
        #[unsafe(method(instructions))]
        #[unsafe(method_family = none)]
        pub unsafe fn instructions(
            &self,
        ) -> Retained<NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>>;

        /// Indicates a special video composition tool for use of Core Animation; may be nil
        #[unsafe(method(animationTool))]
        #[unsafe(method_family = none)]
        pub unsafe fn animationTool(&self)
            -> Option<Retained<AVVideoCompositionCoreAnimationTool>>;

        /// List of all track IDs for tracks from which sample data should be presented to the compositor at any point in the overall composition. The sample data will be delivered to the custom compositor via AVAsynchronousVideoCompositionRequest.
        #[unsafe(method(sourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        /// The output buffers of the video composition can be specified with the outputBufferDescription. The value is an array of CMTagCollectionRef objects that describes the output buffers.
        ///
        /// If the video composition will output tagged buffers, the details of those buffers should be specified with CMTags. Specifically, the StereoView (eyes) must be specified. The behavior is undefined if the output tagged buffers do not match the outputBufferDescription.
        /// The default is nil, which means monoscopic output. Note that an empty array is not valid. An exception will be thrown if the objects in the array are not of type CMTagCollectionRef.
        /// Note that tagged buffers are only supported for custom compositors.
        #[unsafe(method(outputBufferDescription))]
        #[unsafe(method_family = none)]
        pub unsafe fn outputBufferDescription(&self) -> Option<Retained<NSArray>>;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoComposition {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

/// AVVideoCompositionColorimetery.
/// Indicates the color space of the frames output from the video composition.
///
/// Collectively the properties colorPrimaries, colorYCbCrMatrix, and colorTransferFunction define the color space that the rendered frames will be tagged with. For custom video compositing these properties are also used to specify the required color space of the source frames.
///
/// For examples of common color spaces see AVVideoSettings.h.
///
/// How to preserve the color space of the source frames:
///
/// Decide which color space to be preserved by examining the source asset's video tracks. Copy the source track's primaries, matrix and transfer function into the video composition's colorPrimaries, colorYCbCrMatrix and colorTransferFunction respectively.
///
/// - When using custom video compositing
/// Setting these properties will cause source frames to be converted into the specified color space and tagged as such. New frames allocated using -[AVVideoCompositionRenderContext newPixelBuffer] will also be tagged correctly.
///
/// - When using Core Image via videoCompositionWithAsset:options:applyingCIFiltersWithHandler:
/// Setting these properties will cause source frames to be converted into the specified color space and tagged as such. The source frames provided as CIImages will have the appropriate CGColorSpace applied. The color space is preserved when the output CIImage is finally rendered internally.
///
/// - When using basic compositing (i.e. AVVideoCompositionLayerInstruction)
/// Setting these properties will ensure that the internal compositor renders (or passes through) frames in specified color space and are tagged as such.
impl AVVideoComposition {
    extern_methods!(
        /// Rendering will use these primaries and frames will be tagged as such. If the value of this property is nil then the source's primaries will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoColorPrimariesKey. Generally set as a triple along with colorYCbCrMatrix and colorTransferFunction.
        #[unsafe(method(colorPrimaries))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorPrimaries(&self) -> Option<Retained<NSString>>;

        /// Rendering will use this matrix and frames will be tagged as such. If the value of this property is nil then the source's matrix will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoYCbCrMatrixKey. Generally set as a triple along with colorPrimaries and colorTransferFunction.
        #[unsafe(method(colorYCbCrMatrix))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorYCbCrMatrix(&self) -> Option<Retained<NSString>>;

        /// Rendering will use this transfer function and frames will be tagged as such. If the value of this property is nil then the source's transfer function will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoTransferFunctionKey. Generally set as a triple along with colorYCbCrMatrix and colorYCbCrMatrix.
        #[unsafe(method(colorTransferFunction))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorTransferFunction(&self) -> Option<Retained<NSString>>;

        /// Configures policy for per frame HDR display metadata on the rendered frame
        ///
        /// Allows the system to identify situations where HDR metadata can be generated and attached to the rendered video frame.
        /// Default is AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate. Any HDR metadata attached to the composed frame will be propagated to the rendered video frames.
        #[unsafe(method(perFrameHDRDisplayMetadataPolicy))]
        #[unsafe(method_family = none)]
        pub unsafe fn perFrameHDRDisplayMetadataPolicy(
            &self,
        ) -> Retained<AVVideoCompositionPerFrameHDRDisplayMetadataPolicy>;
    );
}

/// AVVideoCompositionFiltering.
impl AVVideoComposition {
    extern_methods!(
        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Returns a new instance of AVVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// The returned AVVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload.
        ///
        /// NOTE: The returned AVVideoComposition's properties are private and support only CIFilter-based operations. Mutations are not supported, either in the values of properties of the AVVideoComposition itself or in its private instructions. If rotations or other transformations are desired, they must be accomplished via the application of CIFilters during the execution of your specified handler.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        /// ```objc
        /// playerItem.videoComposition = [AVVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// }];
        /// ```
        ///
        /// - Parameter asset: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// - Returns: An instance of AVVideoComposition.
        #[deprecated = "Use videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler: instead"]
        #[unsafe(method(videoCompositionWithAsset:applyingCIFiltersWithHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler(
            asset: &AVAsset,
            applier: &block2::DynBlock<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
        ) -> Retained<AVVideoComposition>;

        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Vends a new instance of AVVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// The new AVVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload.
        ///
        /// NOTE: The returned AVVideoComposition's properties are private and support only CIFilter-based operations. Mutations are not supported, either in the values of properties of the AVVideoComposition itself or in its private instructions. If rotations or other transformations are desired, they must be accomplished via the application of CIFilters during the execution of your specified handler.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        /// ```objc
        /// [AVVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// } completionHandler:
        /// ^(AVVideoComposition * _Nullable videoComposition, NSError * _Nullable error)
        /// {
        /// if (videoComposition != nil) {
        /// playerItem.videoComposition = videoComposition
        /// else {
        /// // handle error
        /// }];
        /// ```
        /// - Parameter asset: An instance of AVAsset.
        /// - Parameter completionHandler: A block that is invoked when the new video composition has finished being created. If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        #[unsafe(method(videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler_completionHandler(
            asset: &AVAsset,
            applier: &block2::DynBlock<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
            completion_handler: &block2::DynBlock<dyn Fn(*mut AVVideoComposition, *mut NSError)>,
        );
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition?language=objc)
    #[unsafe(super(AVVideoComposition, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoComposition;
);

extern_conformance!(
    unsafe impl NSCopying for AVMutableVideoComposition {}
);

unsafe impl CopyingHelper for AVMutableVideoComposition {
    type Result = AVVideoComposition;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVMutableVideoComposition {}
);

unsafe impl MutableCopyingHelper for AVMutableVideoComposition {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVMutableVideoComposition {}
);

impl AVMutableVideoComposition {
    extern_methods!(
        /// Returns a new instance of AVMutableVideoComposition.
        ///
        /// The returned AVMutableVideoComposition will have a frameDuration of kCMTimeZero, a renderSize of {0.0, 0.0}, a nil array of instructions, and a nil animationTool.
        #[unsafe(method(videoComposition))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoComposition() -> Retained<AVMutableVideoComposition>;

        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// The returned AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVMutableVideoComposition instance with an empty collection of instructions.
        ///
        /// - Parameter asset: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// - Returns: An instance of AVMutableVideoComposition.
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:completionHandler: instead"]
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset(
            asset: &AVAsset,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks.
        ///
        /// The new AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        /// It will also have the following values for its properties:
        ///
        /// - If the asset has exactly one video track, the original timing of the source video track will be used. If the asset has more than one video track, and the nominal frame rate of any of video tracks is known, the reciprocal of the greatest known nominalFrameRate will be used as the value of frameDuration. Otherwise, a default framerate of 30fps is used.
        /// - If the specified asset is an instance of AVComposition, the renderSize will be set to the naturalSize of the AVComposition; otherwise the renderSize will be set to a value that encompasses all of the asset's video tracks.
        /// - A renderScale of 1.0.
        /// - A nil animationTool.
        ///
        /// If the specified asset has no video tracks, this method will return an AVMutableVideoComposition instance with an empty collection of instructions.
        ///
        /// - Parameter asset: An instance of AVAsset.
        /// - Parameter completionHandler: A block that is invoked when the new video composition has finished being created. If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_completionHandler(
            asset: &AVAsset,
            completion_handler: &block2::DynBlock<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );

        #[cfg(feature = "AVAsset")]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks, and also overrides default properties with those from a prototypeInstruction.
        ///
        /// Also see videoCompositionWithPropertiesOfAsset:.
        /// The returned AVVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. Anything not pertaining to spatial layout and timing, such as background color for their composition or post-processing behaviors, is eligible to be specified via a prototype instruction.
        /// Example: To add a background color,
        /// ```objc
        /// myPrototypeInstruction = [[AVMutableVideoCompositionInstruction alloc] init];
        /// myPrototypeInstruction.backgroundColor = myCGColorRef; // Do not use constant CGColorRef colors here.
        /// myVideoComposition = [AVVideoComposition videoCompositionWithPropertiesOfAsset:myAsset prototypeInstruction:myPrototypeInstruction];
        /// ```
        /// - Parameter asset: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        /// - Parameter prototypeInstruction: Custom instructions that the client can choose to override.
        ///
        /// - Returns: An instance of AVMutableVideoComposition.
        #[deprecated = "Use videoCompositionWithPropertiesOfAsset:prototypeInstruction:completionHandler: instead"]
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:prototypeInstruction:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_prototypeInstruction(
            asset: &AVAsset,
            prototype_instruction: &AVVideoCompositionInstruction,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(feature = "AVAsset", feature = "block2"))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions suitable for presenting the video tracks of the specified asset according to its temporal and geometric properties and those of its tracks, and also overrides default properties with those from a prototypeInstruction.
        ///
        /// Also see videoCompositionWithPropertiesOfAsset:completionHandler:.
        /// The new AVMutableVideoComposition will have instructions that respect the spatial properties and timeRanges of the specified asset's video tracks. Anything not pertaining to spatial layout and timing, such as background color for their composition or post-processing behaviors, is eligible to be specified via a prototype instruction.
        /// Example: To add a background color,
        /// ```objc
        /// myPrototypeInstruction = [[AVMutableVideoCompositionInstruction alloc] init];
        /// myPrototypeInstruction.backgroundColor = myCGColorRef; // Do not use constant CGColorRef colors here.
        /// myVideoComposition = [AVVideoComposition videoCompositionWithPropertiesOfAsset:myAsset prototypeInstruction:myPrototypeInstruction completionHandler:^(AVMutableVideoComposition * _Nullable myVideoComposition, NSError * _Nullable error) {
        /// if (myVideoComposition != nil) {
        /// // use myVideoComposition
        /// }
        /// else {
        /// // handle error
        /// }
        /// }];
        /// ```
        /// - Parameter asset: An instance of AVAsset.
        /// - Parameter prototypeInstruction: Custom instructions that the client can choose to override.
        /// - Parameter completionHandler: A block that is invoked when the new video composition has finished being created. If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        #[unsafe(method(videoCompositionWithPropertiesOfAsset:prototypeInstruction:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithPropertiesOfAsset_prototypeInstruction_completionHandler(
            asset: &AVAsset,
            prototype_instruction: &AVVideoCompositionInstruction,
            completion_handler: &block2::DynBlock<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );

        #[cfg(feature = "AVVideoCompositing")]
        /// Indicates the custom compositor class to use. If nil, the default, internal video compositor is used
        #[unsafe(method(customVideoCompositorClass))]
        #[unsafe(method_family = none)]
        pub unsafe fn customVideoCompositorClass(&self) -> Option<&'static AnyClass>;

        #[cfg(feature = "AVVideoCompositing")]
        /// Setter for [`customVideoCompositorClass`][Self::customVideoCompositorClass].
        #[unsafe(method(setCustomVideoCompositorClass:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCustomVideoCompositorClass(
            &self,
            custom_video_compositor_class: Option<&AnyClass>,
        );

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the interval which the video composition, when enabled, should render composed video frames
        #[unsafe(method(frameDuration))]
        #[unsafe(method_family = none)]
        pub unsafe fn frameDuration(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`frameDuration`][Self::frameDuration].
        #[unsafe(method(setFrameDuration:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setFrameDuration(&self, frame_duration: CMTime);

        #[cfg(feature = "objc2-core-media")]
        /// If sourceTrackIDForFrameTiming is not kCMPersistentTrackID_Invalid, frame timing for the video composition is derived from the source asset's track with the corresponding ID. This may be used to preserve a source asset's variable frame timing. If an empty edit is encountered in the source assetâ€™s track, the compositor composes frames as needed up to the frequency specified in frameDuration property.
        #[unsafe(method(sourceTrackIDForFrameTiming))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceTrackIDForFrameTiming(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`sourceTrackIDForFrameTiming`][Self::sourceTrackIDForFrameTiming].
        #[unsafe(method(setSourceTrackIDForFrameTiming:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceTrackIDForFrameTiming(
            &self,
            source_track_id_for_frame_timing: CMPersistentTrackID,
        );

        #[cfg(feature = "objc2-core-foundation")]
        /// Indicates the size at which the video composition, when enabled, should render
        #[unsafe(method(renderSize))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderSize(&self) -> CGSize;

        #[cfg(feature = "objc2-core-foundation")]
        /// Setter for [`renderSize`][Self::renderSize].
        #[unsafe(method(setRenderSize:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setRenderSize(&self, render_size: CGSize);

        /// Indicates the scale at which the video composition should render. May only be other than 1.0 for a video composition set on an AVPlayerItem
        #[unsafe(method(renderScale))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderScale(&self) -> c_float;

        /// Setter for [`renderScale`][Self::renderScale].
        #[unsafe(method(setRenderScale:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setRenderScale(&self, render_scale: c_float);

        #[cfg(feature = "AVVideoCompositing")]
        /// Indicates instructions for video composition via an NSArray of instances of classes implementing the AVVideoCompositionInstruction protocol.
        ///
        /// For the first instruction in the array, timeRange.start must be less than or equal to the earliest time for which playback or other processing will be attempted (note that this will typically be kCMTimeZero). For subsequent instructions, timeRange.start must be equal to the prior instruction's end time. The end time of the last instruction must be greater than or equal to the latest time for which playback or other processing will be attempted (note that this will often be the duration of the asset with which the instance of AVVideoComposition is associated).
        #[unsafe(method(instructions))]
        #[unsafe(method_family = none)]
        pub unsafe fn instructions(
            &self,
        ) -> Retained<NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>>;

        #[cfg(feature = "AVVideoCompositing")]
        /// Setter for [`instructions`][Self::instructions].
        #[unsafe(method(setInstructions:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setInstructions(
            &self,
            instructions: &NSArray<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>,
        );

        /// Indicates a special video composition tool for use of Core Animation; may be nil
        #[unsafe(method(animationTool))]
        #[unsafe(method_family = none)]
        pub unsafe fn animationTool(&self)
            -> Option<Retained<AVVideoCompositionCoreAnimationTool>>;

        /// Setter for [`animationTool`][Self::animationTool].
        #[unsafe(method(setAnimationTool:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAnimationTool(
            &self,
            animation_tool: Option<&AVVideoCompositionCoreAnimationTool>,
        );

        /// List of all track IDs for tracks from which sample data should be presented to the compositor at any point in the overall composition.  Currently only tracks of type kCMMediaType_Metadata are allowed to be specified.
        #[unsafe(method(sourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        /// Setter for [`sourceSampleDataTrackIDs`][Self::sourceSampleDataTrackIDs].
        #[unsafe(method(setSourceSampleDataTrackIDs:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSourceSampleDataTrackIDs(
            &self,
            source_sample_data_track_i_ds: &NSArray<NSNumber>,
        );

        /// The output buffers of the video composition can be specified with the outputBufferDescription. The value is an array of CMTagCollectionRef objects that describes the output buffers.
        ///
        /// If the video composition will output tagged buffers, the details of those buffers should be specified with CMTags. Specifically, the StereoView (eyes) must be specified. The behavior is undefined if the output tagged buffers do not match the outputBufferDescription.
        /// The default is nil, which means monoscopic output. Note that an empty array is not valid. An exception will be thrown if the objects in the array are not of type CMTagCollectionRef.
        /// Note that tagged buffers are only supported for custom compositors.
        #[unsafe(method(outputBufferDescription))]
        #[unsafe(method_family = none)]
        pub unsafe fn outputBufferDescription(&self) -> Option<Retained<NSArray>>;

        /// Setter for [`outputBufferDescription`][Self::outputBufferDescription].
        #[unsafe(method(setOutputBufferDescription:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setOutputBufferDescription(
            &self,
            output_buffer_description: Option<&NSArray>,
        );
    );
}

/// Methods declared on superclass `NSObject`.
impl AVMutableVideoComposition {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

/// AVMutableVideoCompositionColorimetery.
/// Indicates the color space of the frames output from the video composition.
///
/// Collectively the properties colorPrimaries, colorYCbCrMatrix, and colorTransferFunction define the color space that the rendered frames will be tagged with. For custom video compositing these properties are also used to specify the required color space of the source frames.
///
/// For examples of common color spaces see AVVideoSettings.h.
///
/// How to preserve the color space of the source frames:
///
/// Decide which color space to be preserved by examining the source asset's video tracks. Copy the source track's primaries, matrix and transfer function into the video composition's colorPrimaries, colorYCbCrMatrix and colorTransferFunction respectively.
///
/// - When using custom video compositing
/// Setting these properties will cause source frames to be converted into the specified color space and tagged as such. New frames allocated using -[AVVideoCompositionRenderContext newPixelBuffer] will also be tagged correctly.
///
/// - When using Core Image via videoCompositionWithAsset:options:applyingCIFiltersWithHandler:
/// Setting these properties will cause source frames to be converted into the specified color space and tagged as such. The source frames provided as CIImages will have the appropriate CGColorSpace applied. The color space is preserved when the output CIImage is finally rendered internally.
///
/// - When using basic compositing (i.e. AVVideoCompositionLayerInstruction)
/// Setting these properties will ensure that the internal compositor renders (or passes through) frames in specified color space and are tagged as such.
impl AVMutableVideoComposition {
    extern_methods!(
        /// Rendering will use these primaries and frames will be tagged as such. If the value of this property is nil then the source's primaries will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoColorPrimariesKey. Generally set as a triple along with colorYCbCrMatrix and colorTransferFunction.
        #[unsafe(method(colorPrimaries))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorPrimaries(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorPrimaries`][Self::colorPrimaries].
        #[unsafe(method(setColorPrimaries:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setColorPrimaries(&self, color_primaries: Option<&NSString>);

        /// Rendering will use this matrix and frames will be tagged as such. If the value of this property is nil then the source's matrix will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoYCbCrMatrixKey. Generally set as a triple along with colorPrimaries and colorTransferFunction.
        #[unsafe(method(colorYCbCrMatrix))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorYCbCrMatrix(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorYCbCrMatrix`][Self::colorYCbCrMatrix].
        #[unsafe(method(setColorYCbCrMatrix:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setColorYCbCrMatrix(&self, color_y_cb_cr_matrix: Option<&NSString>);

        /// Rendering will use this transfer function and frames will be tagged as such. If the value of this property is nil then the source's transfer function will be propagated and used.
        ///
        /// Default is nil. Valid values are those suitable for AVVideoTransferFunctionKey. Generally set as a triple along with colorYCbCrMatrix and colorYCbCrMatrix.
        #[unsafe(method(colorTransferFunction))]
        #[unsafe(method_family = none)]
        pub unsafe fn colorTransferFunction(&self) -> Option<Retained<NSString>>;

        /// Setter for [`colorTransferFunction`][Self::colorTransferFunction].
        #[unsafe(method(setColorTransferFunction:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setColorTransferFunction(&self, color_transfer_function: Option<&NSString>);

        /// Configures policy for per frame HDR display metadata on the rendered frame
        ///
        /// Allows the system to identify situations where HDR metadata can be generated and attached to the rendered video frame.
        /// Default is AVVideoCompositionPerFrameHDRDisplayMetadataPolicyPropagate. Any HDR metadata attached to the composed frame will be propagated to the rendered video frames.
        #[unsafe(method(perFrameHDRDisplayMetadataPolicy))]
        #[unsafe(method_family = none)]
        pub unsafe fn perFrameHDRDisplayMetadataPolicy(
            &self,
        ) -> Retained<AVVideoCompositionPerFrameHDRDisplayMetadataPolicy>;

        /// Setter for [`perFrameHDRDisplayMetadataPolicy`][Self::perFrameHDRDisplayMetadataPolicy].
        #[unsafe(method(setPerFrameHDRDisplayMetadataPolicy:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setPerFrameHDRDisplayMetadataPolicy(
            &self,
            per_frame_hdr_display_metadata_policy: &AVVideoCompositionPerFrameHDRDisplayMetadataPolicy,
        );
    );
}

/// AVMutableVideoCompositionFiltering.
impl AVMutableVideoComposition {
    extern_methods!(
        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Returns a new instance of AVMutableVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// The returned AVMutableVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        /// ```objc
        /// playerItem.videoComposition = [AVMutableVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// }];
        /// ```
        /// - Parameter asset: An instance of AVAsset. For best performance, ensure that the duration and tracks properties of the asset are already loaded before invoking this method.
        ///
        /// - Returns: An instance of AVMutableVideoComposition.
        #[deprecated = "Use videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler: instead"]
        #[unsafe(method(videoCompositionWithAsset:applyingCIFiltersWithHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler(
            asset: &AVAsset,
            applier: &block2::DynBlock<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
        ) -> Retained<AVMutableVideoComposition>;

        #[cfg(all(
            feature = "AVAsset",
            feature = "AVVideoCompositing",
            feature = "block2"
        ))]
        /// Vends a new instance of AVMutableVideoComposition with values and instructions that will apply the specified handler block to video frames represented as instances of CIImage.
        ///
        /// The new AVMutableVideoComposition will cause the specified handler block to be called to filter each frame of the asset's first enabled video track. The handler block should use the properties of the provided AVAsynchronousCIImageFilteringRequest and respond using finishWithImage:context: with a "filtered" new CIImage (or the provided source image for no affect). In the event of an error, respond to the request using finishWithError:. The error can be observed via AVPlayerItemFailedToPlayToEndTimeNotification, see AVPlayerItemFailedToPlayToEndTimeErrorKey in notification payload. The client can set sourceTrackIDForFrameTiming to kCMPersistentTrackID_Invalid and frameDuration to an appropriate value in order to specify the maximum output frame rate independent of the source track timing.
        ///
        /// The video composition will also have the following values for its properties:
        ///
        /// - The original timing of the asset's first enabled video track will be used.
        /// - A renderSize that encompasses the asset's first enabled video track respecting the track's preferredTransform.
        /// - A renderScale of 1.0.
        ///
        /// The default CIContext has the following properties:
        ///
        /// - iOS: Device RGB color space
        /// - macOS: sRGB color space
        ///
        /// Example usage:
        /// ```objc
        /// [AVMutableVideoComposition videoCompositionWithAsset:srcAsset applyingCIFiltersWithHandler:
        /// ^(AVAsynchronousCIImageFilteringRequest *request)
        /// {
        /// NSError *err = nil;
        /// CIImage *filtered = myRenderer(request,
        /// &err
        /// );
        /// if (filtered)
        /// [request finishWithImage:filtered context:nil];
        /// else
        /// [request finishWithError:err];
        /// } completionHandler:
        /// ^(AVMutableVideoComposition * _Nullable videoComposition, NSError * _Nullable error)
        /// {
        /// if (videoComposition != nil) {
        /// playerItem.videoComposition = videoComposition
        /// else {
        /// // handle error
        /// }];
        /// ```
        /// - Parameter asset: An instance of AVAsset.
        /// - Parameter completionHandler: A block that is invoked when the new video composition has finished being created. If the `videoComposition` parameter is nil, the `error` parameter describes the failure that occurred.
        #[unsafe(method(videoCompositionWithAsset:applyingCIFiltersWithHandler:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionWithAsset_applyingCIFiltersWithHandler_completionHandler(
            asset: &AVAsset,
            applier: &block2::DynBlock<dyn Fn(NonNull<AVAsynchronousCIImageFilteringRequest>)>,
            completion_handler: &block2::DynBlock<
                dyn Fn(*mut AVMutableVideoComposition, *mut NSError),
            >,
        );
    );
}

extern_class!(
    /// An AVVideoCompositionInstruction object represents an operation to be performed by a compositor.
    ///
    /// An AVVideoComposition object maintains an array of instructions to perform its composition. This class is not intended to be subclassed; instead, conform to AVVideoCompositionInstructionProtocol ("AVVideoCompositionInstruction" in Objective-C). Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositioninstruction?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionInstruction;
);

unsafe impl Send for AVVideoCompositionInstruction {}

unsafe impl Sync for AVVideoCompositionInstruction {}

#[cfg(feature = "AVVideoCompositing")]
extern_conformance!(
    unsafe impl AVVideoCompositionInstructionProtocol for AVVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSCoding for AVVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSCopying for AVVideoCompositionInstruction {}
);

unsafe impl CopyingHelper for AVVideoCompositionInstruction {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVVideoCompositionInstruction {}
);

unsafe impl MutableCopyingHelper for AVVideoCompositionInstruction {
    type Result = AVMutableVideoCompositionInstruction;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSSecureCoding for AVVideoCompositionInstruction {}
);

impl AVVideoCompositionInstruction {
    extern_methods!(
        /// Pass-through initializer, for internal use in AVFoundation only
        #[unsafe(method(videoCompositionInstructionWithInstruction:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionInstructionWithInstruction(
            instruction: &AVVideoCompositionInstruction,
        ) -> Retained<AVVideoCompositionInstruction>;

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the timeRange during which the instruction is effective. Note requirements for the timeRanges of instructions described in connection with AVVideoComposition's instructions key above.
        #[unsafe(method(timeRange))]
        #[unsafe(method_family = none)]
        pub unsafe fn timeRange(&self) -> CMTimeRange;

        #[cfg(feature = "objc2-core-graphics")]
        /// Indicates the background color of the composition.
        ///
        /// Solid BGRA colors only are supported; patterns and other color refs that are not supported will be ignored.
        /// - If the background color is not specified the video compositor will use a default backgroundColor of opaque black.
        /// - If the rendered pixel buffer does not have alpha, the alpha value of the backgroundColor will be ignored.
        #[unsafe(method(backgroundColor))]
        #[unsafe(method_family = none)]
        pub unsafe fn backgroundColor(&self) -> Option<Retained<CGColor>>;

        /// Provides an array of instances of AVVideoCompositionLayerInstruction that specify how video frames from source tracks should be layered and composed.
        ///
        /// Tracks are layered in the composition according to the top-to-bottom order of the layerInstructions array; the track with trackID of the first instruction in the array will be layered on top, with the track with the trackID of the second instruction immediately underneath, etc. If this key is nil, the output will be a fill of the background color.
        #[unsafe(method(layerInstructions))]
        #[unsafe(method_family = none)]
        pub unsafe fn layerInstructions(
            &self,
        ) -> Retained<NSArray<AVVideoCompositionLayerInstruction>>;

        /// If NO, indicates that post-processing should be skipped for the duration of this instruction.  YES by default.
        ///
        /// See +[AVVideoCompositionCoreAnimationTool videoCompositionToolWithPostProcessingAsVideoLayer:inLayer:].
        #[unsafe(method(enablePostProcessing))]
        #[unsafe(method_family = none)]
        pub unsafe fn enablePostProcessing(&self) -> bool;

        /// List of video track IDs required to compose frames for this instruction. The value of this property is computed from the layer instructions.
        #[unsafe(method(requiredSourceTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceTrackIDs(&self) -> Retained<NSArray<NSValue>>;

        #[cfg(feature = "objc2-core-media")]
        /// If the video composition result is one of the source frames for the duration of the instruction, this property returns the corresponding track ID. The compositor won't be run for the duration of the instruction and the proper source frame will be used instead. The value of this property is computed from the layer instructions
        #[unsafe(method(passthroughTrackID))]
        #[unsafe(method_family = none)]
        pub unsafe fn passthroughTrackID(&self) -> CMPersistentTrackID;

        /// List of track IDs for which sample data should be presented to the compositor for this instruction.
        #[unsafe(method(requiredSourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoCompositionInstruction {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction?language=objc)
    #[unsafe(super(AVVideoCompositionInstruction, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoCompositionInstruction;
);

#[cfg(feature = "AVVideoCompositing")]
extern_conformance!(
    unsafe impl AVVideoCompositionInstructionProtocol for AVMutableVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSCoding for AVMutableVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSCopying for AVMutableVideoCompositionInstruction {}
);

unsafe impl CopyingHelper for AVMutableVideoCompositionInstruction {
    type Result = AVVideoCompositionInstruction;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVMutableVideoCompositionInstruction {}
);

unsafe impl MutableCopyingHelper for AVMutableVideoCompositionInstruction {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVMutableVideoCompositionInstruction {}
);

extern_conformance!(
    unsafe impl NSSecureCoding for AVMutableVideoCompositionInstruction {}
);

impl AVMutableVideoCompositionInstruction {
    extern_methods!(
        /// Returns a new instance of AVMutableVideoCompositionInstruction.
        ///
        /// The returned AVMutableVideoCompositionInstruction will have a timeRange of kCMTimeRangeInvalid, a NULL backgroundColor, and a nil array of layerInstructions.
        #[unsafe(method(videoCompositionInstruction))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionInstruction() -> Retained<Self>;

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the timeRange during which the instruction is effective. Note requirements for the timeRanges of instructions described in connection with AVVideoComposition's instructions key above.
        #[unsafe(method(timeRange))]
        #[unsafe(method_family = none)]
        pub unsafe fn timeRange(&self) -> CMTimeRange;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`timeRange`][Self::timeRange].
        #[unsafe(method(setTimeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setTimeRange(&self, time_range: CMTimeRange);

        #[cfg(feature = "objc2-core-graphics")]
        /// Indicates the background color of the composition.
        ///
        /// Solid BGRA colors only are supported; patterns and other color refs that are not supported will be ignored.
        /// - If the background color is not specified the video compositor will use a default backgroundColor of opaque black.
        /// - If the rendered pixel buffer does not have alpha, the alpha value of the backgroundColor will be ignored.
        #[unsafe(method(backgroundColor))]
        #[unsafe(method_family = none)]
        pub unsafe fn backgroundColor(&self) -> Option<Retained<CGColor>>;

        #[cfg(feature = "objc2-core-graphics")]
        /// Setter for [`backgroundColor`][Self::backgroundColor].
        #[unsafe(method(setBackgroundColor:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setBackgroundColor(&self, background_color: Option<&CGColor>);

        /// Provides an array of instances of AVVideoCompositionLayerInstruction that specify how video frames from source tracks should be layered and composed.
        ///
        /// Tracks are layered in the composition according to the top-to-bottom order of the layerInstructions array; the track with trackID of the first instruction in the array will be layered on top, with the track with the trackID of the second instruction immediately underneath, etc.
        /// If this key is nil, the output will be a fill of the background color.
        #[unsafe(method(layerInstructions))]
        #[unsafe(method_family = none)]
        pub unsafe fn layerInstructions(
            &self,
        ) -> Retained<NSArray<AVVideoCompositionLayerInstruction>>;

        /// Setter for [`layerInstructions`][Self::layerInstructions].
        #[unsafe(method(setLayerInstructions:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setLayerInstructions(
            &self,
            layer_instructions: &NSArray<AVVideoCompositionLayerInstruction>,
        );

        /// If NO, indicates that post-processing should be skipped for the duration of this instruction.  YES by default.
        ///
        /// See +[AVVideoCompositionCoreAnimationTool videoCompositionToolWithPostProcessingAsVideoLayer:inLayer:].
        #[unsafe(method(enablePostProcessing))]
        #[unsafe(method_family = none)]
        pub unsafe fn enablePostProcessing(&self) -> bool;

        /// Setter for [`enablePostProcessing`][Self::enablePostProcessing].
        #[unsafe(method(setEnablePostProcessing:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setEnablePostProcessing(&self, enable_post_processing: bool);

        /// List of sample data track IDs required to compose frames for this instruction.
        ///
        /// Currently only tracks of type kCMMediaType_Metadata are allowed to be specified.  If this property is unspecified or is an empty array, no sample data is considered to be required for this instruction.  Note that you must also specify all tracks for which sample data is required for ANY instruction in the AVVideoComposition, in AVVideoComposition's property sourceSampleDataTrackIDs.
        #[unsafe(method(requiredSourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn requiredSourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        /// Setter for [`requiredSourceSampleDataTrackIDs`][Self::requiredSourceSampleDataTrackIDs].
        #[unsafe(method(setRequiredSourceSampleDataTrackIDs:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setRequiredSourceSampleDataTrackIDs(
            &self,
            required_source_sample_data_track_i_ds: &NSArray<NSNumber>,
        );
    );
}

/// Methods declared on superclass `NSObject`.
impl AVMutableVideoCompositionInstruction {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// An AVVideoCompositionLayerInstruction object represents the transform, opacity, and cropping ramps to apply to a given track. Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionlayerinstruction?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionLayerInstruction;
);

unsafe impl Send for AVVideoCompositionLayerInstruction {}

unsafe impl Sync for AVVideoCompositionLayerInstruction {}

extern_conformance!(
    unsafe impl NSCoding for AVVideoCompositionLayerInstruction {}
);

extern_conformance!(
    unsafe impl NSCopying for AVVideoCompositionLayerInstruction {}
);

unsafe impl CopyingHelper for AVVideoCompositionLayerInstruction {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVVideoCompositionLayerInstruction {}
);

unsafe impl MutableCopyingHelper for AVVideoCompositionLayerInstruction {
    type Result = AVMutableVideoCompositionLayerInstruction;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoCompositionLayerInstruction {}
);

extern_conformance!(
    unsafe impl NSSecureCoding for AVVideoCompositionLayerInstruction {}
);

impl AVVideoCompositionLayerInstruction {
    extern_methods!(
        /// Pass-through initializer, for internal use in AVFoundation only
        #[unsafe(method(videoCompositionLayerInstructionWithLayerInstruction:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionLayerInstructionWithLayerInstruction(
            instruction: &AVVideoCompositionLayerInstruction,
        ) -> Retained<AVVideoCompositionLayerInstruction>;

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the trackID of the source track to which the compositor will apply the instruction.
        #[unsafe(method(trackID))]
        #[unsafe(method_family = none)]
        pub unsafe fn trackID(&self) -> CMPersistentTrackID;

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Obtains the transform ramp that includes the specified time.
        ///
        /// - Parameter time: If a ramp with a timeRange that contains the specified time has been set, information about the effective ramp for that time is supplied. Otherwise, information about the first ramp that starts after the specified time is supplied.
        /// - Parameter startTransform: A pointer to a float to receive the starting transform value for the transform ramp. May be NULL.
        /// - Parameter endTransform: A pointer to a float to receive the ending transform value for the transform ramp. May be NULL.
        /// - Parameter timeRange: A pointer to a CMTimeRange to receive the timeRange of the transform ramp. May be NULL.
        ///
        /// - Returns: An indication of success. NO will be returned if the specified time is beyond the duration of the last transform ramp that has been set.
        #[unsafe(method(getTransformRampForTime:startTransform:endTransform:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn getTransformRampForTime_startTransform_endTransform_timeRange(
            &self,
            time: CMTime,
            start_transform: *mut CGAffineTransform,
            end_transform: *mut CGAffineTransform,
            time_range: *mut CMTimeRange,
        ) -> bool;

        #[cfg(feature = "objc2-core-media")]
        /// Obtains the opacity ramp that includes the specified time.
        ///
        /// - Parameter time: If a ramp with a timeRange that contains the specified time has been set, information about the effective ramp for that time is supplied. Otherwise, information about the first ramp that starts after the specified time is supplied.
        /// - Parameter startOpacity: A pointer to a float to receive the starting opacity value for the opacity ramp. May be NULL.
        /// - Parameter endOpacity: A pointer to a float to receive the ending opacity value for the opacity ramp. May be NULL.
        /// - Parameter timeRange: A pointer to a CMTimeRange to receive the timeRange of the opacity ramp. May be NULL.
        ///
        /// - Returns: An indication of success. NO will be returned if the specified time is beyond the duration of the last opacity ramp that has been set.
        #[unsafe(method(getOpacityRampForTime:startOpacity:endOpacity:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn getOpacityRampForTime_startOpacity_endOpacity_timeRange(
            &self,
            time: CMTime,
            start_opacity: *mut c_float,
            end_opacity: *mut c_float,
            time_range: *mut CMTimeRange,
        ) -> bool;

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Obtains the crop rectangle ramp that includes the specified time.
        ///
        /// - Parameter time: If a ramp with a timeRange that contains the specified time has been set, information about the effective ramp for that time is supplied. Otherwise, information about the first ramp that starts after the specified time is supplied.
        /// - Parameter startCropRectangle: A pointer to a CGRect to receive the starting crop rectangle value for the crop rectangle ramp. May be NULL.
        /// - Parameter endCropRecrangle: A pointer to a CGRect to receive the ending crop rectangle value for the crop rectangle ramp. May be NULL.
        /// - Parameter timeRange: A pointer to a CMTimeRange to receive the timeRange of the crop rectangle ramp. May be NULL.
        ///
        /// - Returns: An indication of success. NO will be returned if the specified time is beyond the duration of the last crop rectangle ramp that has been set.
        #[unsafe(method(getCropRectangleRampForTime:startCropRectangle:endCropRectangle:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn getCropRectangleRampForTime_startCropRectangle_endCropRectangle_timeRange(
            &self,
            time: CMTime,
            start_crop_rectangle: *mut CGRect,
            end_crop_rectangle: *mut CGRect,
            time_range: *mut CMTimeRange,
        ) -> bool;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoCompositionLayerInstruction {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction?language=objc)
    #[unsafe(super(AVVideoCompositionLayerInstruction, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVMutableVideoCompositionLayerInstruction;
);

extern_conformance!(
    unsafe impl NSCoding for AVMutableVideoCompositionLayerInstruction {}
);

extern_conformance!(
    unsafe impl NSCopying for AVMutableVideoCompositionLayerInstruction {}
);

unsafe impl CopyingHelper for AVMutableVideoCompositionLayerInstruction {
    type Result = AVVideoCompositionInstruction;
}

extern_conformance!(
    unsafe impl NSMutableCopying for AVMutableVideoCompositionLayerInstruction {}
);

unsafe impl MutableCopyingHelper for AVMutableVideoCompositionLayerInstruction {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVMutableVideoCompositionLayerInstruction {}
);

extern_conformance!(
    unsafe impl NSSecureCoding for AVMutableVideoCompositionLayerInstruction {}
);

impl AVMutableVideoCompositionLayerInstruction {
    extern_methods!(
        #[cfg(feature = "AVAssetTrack")]
        /// Returns a new instance of AVMutableVideoCompositionLayerInstruction with no transform or opacity ramps and a trackID set to the specified track's trackID.
        ///
        /// - Parameter track: A reference to an AVAssetTrack.
        #[unsafe(method(videoCompositionLayerInstructionWithAssetTrack:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionLayerInstructionWithAssetTrack(
            track: &AVAssetTrack,
        ) -> Retained<Self>;

        /// Returns a new instance of AVMutableVideoCompositionLayerInstruction with no transform or opacity ramps and a trackID initialized to kCMPersistentTrackID_Invalid.
        #[unsafe(method(videoCompositionLayerInstruction))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionLayerInstruction() -> Retained<Self>;

        #[cfg(feature = "objc2-core-media")]
        /// Indicates the trackID of the source track to which the compositor will apply the instruction.
        #[unsafe(method(trackID))]
        #[unsafe(method_family = none)]
        pub unsafe fn trackID(&self) -> CMPersistentTrackID;

        #[cfg(feature = "objc2-core-media")]
        /// Setter for [`trackID`][Self::trackID].
        #[unsafe(method(setTrackID:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setTrackID(&self, track_id: CMPersistentTrackID);

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Sets a transform ramp to apply during the specified timerange.
        ///
        /// For purposes of spatial positioning of video frames, the origin is in the top-left corner, so
        /// (a) positive translation values in an affine transform move a video frame right and down; and
        /// (b) with an identity transform a video frame is positioned with its top-left corner in the top-left corner of the composited frame.
        /// Video frames shall be interpreted at their display sizes (as described by CVImageBufferGetDisplaySize,
        /// ie, taking pixel aspect ratio attachments into account) before any affine transform is applied.
        ///
        /// During a transform ramp, the affine transform is interpolated between the values set at the ramp's start time and end time.
        /// Before the first specified time for which a transform is set, the affine transform is held constant at the value of CGAffineTransformIdentity;
        /// after the last time for which a transform is set, the affine transform is held constant at that last value;
        ///
        /// This method throws an exception if the time range overlaps the time range of an existing transform ramp or if the time range of a does not have a numeric start time and duration.
        ///
        /// - Parameter startTransform: The transform to be applied at the starting time of the timeRange. See the discussion below of how transforms are applied to video frames.
        /// - Parameter endTransform: The transform to be applied at the end time of the timeRange.
        /// - Parameter timeRange: The timeRange over which the value of the transform will be interpolated between startTransform and endTransform.
        #[unsafe(method(setTransformRampFromStartTransform:toEndTransform:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setTransformRampFromStartTransform_toEndTransform_timeRange(
            &self,
            start_transform: CGAffineTransform,
            end_transform: CGAffineTransform,
            time_range: CMTimeRange,
        );

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Sets a value of the transform at a time within the timeRange of the instruction.
        ///
        /// For purposes of spatial positioning of video frames, the origin is in the top-left corner, so
        /// (a) positive translation values in an affine transform move a video frame right and down; and
        /// (b) with an identity transform a video frame is positioned with its top-left corner in the top-left corner of the composited frame.
        /// Video frames shall be interpreted at their display sizes (as described by CVImageBufferGetDisplaySize,
        /// ie, taking pixel aspect ratio attachments into account) before any affine transform is applied.
        ///
        /// Sets a fixed transform to apply from the specified time until the next time at which a transform is set; this is the same as setting a flat ramp for that time range.
        /// Before the first specified time for which a transform is set, the affine transform is held constant at the value of CGAffineTransformIdentity;
        /// after the last time for which a transform is set, the affine transform is held constant at that last value;
        ///
        /// This method throws an exception if time is not numeric.
        ///
        /// - Parameter transform: The transform to be applied at the specified time. See the discussion below of how transforms are applied to video frames.
        /// - Parameter time: A time value within the timeRange of the composition instruction.
        #[unsafe(method(setTransform:atTime:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setTransform_atTime(&self, transform: CGAffineTransform, time: CMTime);

        #[cfg(feature = "objc2-core-media")]
        /// Sets an opacity ramp to apply during the specified timerange.
        ///
        /// During an opacity ramp, opacity is computed using a linear interpolation.
        /// Before the first time for which an opacity is set, the opacity is held constant at 1.0; after the last specified time, the opacity is held constant at the last value
        /// This method throws an exception if the time range of a does not have a numeric start time and duration.
        ///
        /// - Parameter startOpacity: The opacity to be applied at the starting time of the timeRange. The value must be between 0.0 and 1.0.
        /// - Parameter endOpacity: The opacity to be applied at the end time of the timeRange. The value must be between 0.0 and 1.0.
        /// - Parameter timeRange: The timeRange over which the value of the opacity will be interpolated between startOpacity and endOpacity.
        #[unsafe(method(setOpacityRampFromStartOpacity:toEndOpacity:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setOpacityRampFromStartOpacity_toEndOpacity_timeRange(
            &self,
            start_opacity: c_float,
            end_opacity: c_float,
            time_range: CMTimeRange,
        );

        #[cfg(feature = "objc2-core-media")]
        /// Sets a value of the opacity at a time within the timeRange of the instruction.
        ///
        /// Sets a fixed opacity to apply from the specified time until the next time at which an opacity is set; this is the same as setting a flat ramp for that time range.
        /// Before the first time for which an opacity is set, the opacity is held constant at 1.0; after the last specified time, the opacity is held constant at the last value.
        /// This method throws an exception if time is not numeric.
        ///
        /// - Parameter opacity: The opacity to be applied at the specified time. The value must be between 0.0 and 1.0.
        /// - Parameter time: A time value within the timeRange of the composition instruction.
        #[unsafe(method(setOpacity:atTime:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setOpacity_atTime(&self, opacity: c_float, time: CMTime);

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Sets an crop rectangle ramp to apply during the specified timerange.
        ///
        /// The origin of the crop rectangle is the top-left corner of the buffer clean aperture rectangle. The crop rectangle is defined in
        /// square pixel space, i.e. without taking the pixel aspect ratio into account. Crop rectangles extending outside of the clean aperture,
        /// are cropped to the clean aperture.
        ///
        /// During a crop rectangle ramp, the rectangle is interpolated between the values set at the ramp's start time and end time.
        /// When the starting or ending rectangle is empty, interpolations take into account the origin and size of the empty rectangle.
        /// Before the first specified time for which a crop rectangle is set, the crop rectangle is held constant to CGRectInfinite
        /// after the last time for which a crop rectangle is set, the crop rectangle is held constant at that last value.
        ///
        /// This method throws an exception if the time range overlaps the time range of an existing crop rectangle ramp, or if the time range does not have a numeric start time and duration.
        ///
        /// - Parameter startCropRectangle: The crop rectangle to be applied at the starting time of the timeRange. See the discussion below of how crop rectangles are applied to video frames.
        /// - Parameter endCropRectangle: The crop rectangle to be applied at the end time of the timeRange.
        /// - Parameter timeRange: The timeRange over which the value of the opacity will be interpolated between startCropRectangle and endCropRectangle.
        #[unsafe(method(setCropRectangleRampFromStartCropRectangle:toEndCropRectangle:timeRange:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCropRectangleRampFromStartCropRectangle_toEndCropRectangle_timeRange(
            &self,
            start_crop_rectangle: CGRect,
            end_crop_rectangle: CGRect,
            time_range: CMTimeRange,
        );

        #[cfg(all(feature = "objc2-core-foundation", feature = "objc2-core-media"))]
        /// Sets a value of the crop rectangle at a time within the timeRange of the instruction.
        ///
        /// The origin of the crop rectangle is the top-left corner of the buffer clean aperture rectangle. The crop rectangle is defined in
        /// square pixel space, i.e. without taking the pixel aspect ratio into account. Crop rectangles extending outside of the clean aperture,
        /// are cropped to the clean aperture.
        ///
        /// Sets a fixed crop rectangle to apply from the specified time until the next time at which a crop rectangle is set; this is the same as setting a flat ramp for that time range.
        /// Before the first specified time for which a crop rectangle is set, the crop rectangle is held constant to CGRectInfinite
        /// after the last time for which a crop rectangle is set, the crop rectangle is held constant at that last value.
        ///
        /// This method throws an exception if time is not numeric.
        ///
        /// - Parameter cropRectangle: The crop rectangle to be applied at the specified time. See the discussion below of how crop rectangles are applied to video frames.
        /// - Parameter time: A time value within the timeRange of the composition instruction.
        #[unsafe(method(setCropRectangle:atTime:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setCropRectangle_atTime(&self, crop_rectangle: CGRect, time: CMTime);
    );
}

/// Methods declared on superclass `NSObject`.
impl AVMutableVideoCompositionLayerInstruction {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// A tool for using Core Animation in a video composition.
    ///
    /// Instances of AVVideoCompositionCoreAnimationTool are for use with offline rendering (AVAssetExportSession and AVAssetReader), not with AVPlayer.
    /// To synchronize real-time playback with other CoreAnimation layers, use AVSynchronizedLayer.
    ///
    /// Any animations will be interpreted on the video's timeline, not real-time, so
    /// (a) set animation beginTimes to small positive value such as AVCoreAnimationBeginTimeAtZero rather than 0,
    /// because CoreAnimation will replace a value of 0 with CACurrentMediaTime();
    /// (b) set removedOnCompletion to NO on animations so they are not automatically removed;
    /// (c) do not use layers associated with UIViews.
    ///
    /// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositioncoreanimationtool?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionCoreAnimationTool;
);

unsafe impl Send for AVVideoCompositionCoreAnimationTool {}

unsafe impl Sync for AVVideoCompositionCoreAnimationTool {}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoCompositionCoreAnimationTool {}
);

impl AVVideoCompositionCoreAnimationTool {
    extern_methods!(
        #[cfg(all(feature = "objc2-core-media", feature = "objc2-quartz-core"))]
        #[cfg(not(target_os = "watchos"))]
        /// Add a Core Animation layer to the video composition
        ///
        /// Include a Core Animation layer as an individual track input in video composition.
        /// This layer should not come from, or be added to, another layer tree.
        /// trackID should not match any real trackID in the source. Use -[AVAsset unusedTrackID]
        /// to obtain a trackID that's guaranteed not to coincide with the trackID of any track of the asset.
        /// AVVideoCompositionInstructions should reference trackID where the rendered animation should be included.
        /// For best performance, no transform should be set in the AVVideoCompositionLayerInstruction for this trackID.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[unsafe(method(videoCompositionCoreAnimationToolWithAdditionalLayer:asTrackID:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithAdditionalLayer_asTrackID(
            layer: &CALayer,
            track_id: CMPersistentTrackID,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-quartz-core")]
        #[cfg(not(target_os = "watchos"))]
        /// Compose the composited video frames with the Core Animation layer
        ///
        /// Place composited video frames in videoLayer and render animationLayer
        /// to produce the final frame. Normally videoLayer should be in animationLayer's sublayer tree.
        /// The animationLayer should not come from, or be added to, another layer tree.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[unsafe(method(videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayer:inLayer:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayer_inLayer(
            video_layer: &CALayer,
            animation_layer: &CALayer,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-quartz-core")]
        #[cfg(not(target_os = "watchos"))]
        /// Compose the composited video frames with the Core Animation layer
        ///
        /// Duplicate the composited video frames in each videoLayer and render animationLayer
        /// to produce the final frame. Normally videoLayers should be in animationLayer's sublayer tree.
        /// The animationLayer should not come from, or be added to, another layer tree.
        /// Be aware that on iOS, CALayers backing a UIView usually have their content flipped (as defined by the
        /// -contentsAreFlipped method). It may be required to insert a CALayer with its geometryFlipped property set
        /// to YES in the layer hierarchy to get the same result when attaching a CALayer to a AVVideoCompositionCoreAnimationTool
        /// as when using it to back a UIView.
        #[unsafe(method(videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayers:inLayer:))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayers_inLayer(
            video_layers: &NSArray<CALayer>,
            animation_layer: &CALayer,
        ) -> Retained<Self>;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoCompositionCoreAnimationTool {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

/// AVAssetVideoCompositionUtility.
#[cfg(feature = "AVAsset")]
impl AVAsset {
    extern_methods!(
        #[cfg(feature = "objc2-core-media")]
        #[deprecated = "Use findUnusedTrackIDWithCompletionHandler: instead"]
        #[unsafe(method(unusedTrackID))]
        #[unsafe(method_family = none)]
        pub unsafe fn unusedTrackID(&self) -> CMPersistentTrackID;

        #[cfg(all(feature = "block2", feature = "objc2-core-media"))]
        /// Loads a track ID that will not collide with any existing track
        ///
        /// - Parameter completionHandler: A block that is invoked when loading is complete, vending the track ID or an error.
        #[unsafe(method(findUnusedTrackIDWithCompletionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn findUnusedTrackIDWithCompletionHandler(
            &self,
            completion_handler: &block2::DynBlock<dyn Fn(CMPersistentTrackID, *mut NSError)>,
        );
    );
}

/// AVVideoCompositionValidation.
impl AVVideoComposition {
    extern_methods!(
        #[cfg(all(feature = "AVAsset", feature = "objc2-core-media"))]
        /// Indicates whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        ///
        /// - Parameter asset: Pass a reference to an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset and the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation. Clients should ensure that the keys
        /// "
        /// tracks" and @"duration" are already loaded on the AVAsset before validation is attempted.
        /// - Parameter timeRange: A CMTimeRange. Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        /// - Parameter validationDelegate: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -isValidForAsset:. May be nil.
        #[deprecated = "Use isValidForTracks:assetDuration:timeRange:validationDelegate: instead"]
        #[unsafe(method(isValidForAsset:timeRange:validationDelegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn isValidForAsset_timeRange_validationDelegate(
            &self,
            asset: Option<&AVAsset>,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
        ) -> bool;

        #[cfg(all(feature = "AVAsset", feature = "block2", feature = "objc2-core-media"))]
        /// Determines whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        ///
        /// - Parameter asset: Pass a reference to an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset and the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation.
        /// - Parameter timeRange: A CMTimeRange. Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        /// - Parameter validationDelegate: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -determineValidityForAsset:. May be nil.
        /// - Parameter completionHandler: A block that is invoked when a determination is made about whether the video composition is valid. If the `isValid` parameter is NO, either the video composition is not valid, in which case the `error` parameter will be nil, or the answer could not be determined, in which case the `error` parameter will be non-nil and describe the failure that occurred.
        #[deprecated]
        #[unsafe(method(determineValidityForAsset:timeRange:validationDelegate:completionHandler:))]
        #[unsafe(method_family = none)]
        pub unsafe fn determineValidityForAsset_timeRange_validationDelegate_completionHandler(
            &self,
            asset: Option<&AVAsset>,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
            completion_handler: &block2::DynBlock<dyn Fn(Bool, *mut NSError)>,
        );

        #[cfg(all(feature = "AVAssetTrack", feature = "objc2-core-media"))]
        /// Indicates whether the timeRanges of the receiver's instructions conform to the requirements described for them immediately above (in connection with the instructions property) and also whether all of the layer instructions have a value for trackID that corresponds either to a track of the specified asset or to the receiver's animationTool.
        ///
        /// In the course of validation, the receiver will invoke its validationDelegate with reference to any trouble spots in the video composition.
        /// An exception will be raised if the delegate modifies the receiver's array of instructions or the array of layerInstructions of any AVVideoCompositionInstruction contained therein during validation.
        ///
        /// - Parameter tracks: Pass a reference to an AVAsset's tracks if you wish to validate the trackIDs of the layer instructions against the asset's tracks. Pass nil to skip that validation. This method throws an exception if the tracks are not all from the same asset.
        /// - Parameter duration: Pass an AVAsset if you wish to validate the timeRanges of the instructions against the duration of the asset. Pass kCMTimeInvalid to skip that validation.
        /// - Parameter timeRange: A CMTimeRange. Only those instructions with timeRanges that overlap with the specified timeRange will be validated. To validate all instructions that may be used for playback or other processing, regardless of timeRange, pass CMTimeRangeMake(kCMTimeZero, kCMTimePositiveInfinity).
        /// - Parameter validationDelegate: Indicates an object implementing the AVVideoCompositionValidationHandling protocol to receive information about troublesome portions of a video composition during processing of -isValidForAsset:. May be nil.
        #[unsafe(method(isValidForTracks:assetDuration:timeRange:validationDelegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn isValidForTracks_assetDuration_timeRange_validationDelegate(
            &self,
            tracks: &NSArray<AVAssetTrack>,
            duration: CMTime,
            time_range: CMTimeRange,
            validation_delegate: Option<&ProtocolObject<dyn AVVideoCompositionValidationHandling>>,
        ) -> bool;
    );
}

extern_protocol!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionvalidationhandling?language=objc)
    pub unsafe trait AVVideoCompositionValidationHandling: NSObjectProtocol {
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a key that has an invalid value.
        ///
        /// - Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[unsafe(method(videoComposition:shouldContinueValidatingAfterFindingInvalidValueForKey:))]
        #[unsafe(method_family = none)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidValueForKey(
            &self,
            video_composition: &AVVideoComposition,
            key: &NSString,
        ) -> bool;

        #[cfg(feature = "objc2-core-media")]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a timeRange that has no corresponding video composition instruction.
        ///
        /// - Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[unsafe(method(videoComposition:shouldContinueValidatingAfterFindingEmptyTimeRange:))]
        #[unsafe(method_family = none)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingEmptyTimeRange(
            &self,
            video_composition: &AVVideoComposition,
            time_range: CMTimeRange,
        ) -> bool;

        #[cfg(feature = "AVVideoCompositing")]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a video composition instruction with a timeRange that's invalid, that overlaps with the timeRange of a prior instruction, or that contains times earlier than the timeRange of a prior instruction.
        ///
        /// Use CMTIMERANGE_IS_INVALID, defined in CMTimeRange.h, to test whether the timeRange itself is invalid. Refer to headerdoc for AVVideoComposition.instructions for a discussion of how timeRanges for instructions must be formulated.
        ///
        /// - Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[unsafe(method(videoComposition:shouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction:))]
        #[unsafe(method_family = none)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidTimeRangeInInstruction(
            &self,
            video_composition: &AVVideoComposition,
            video_composition_instruction: &ProtocolObject<
                dyn AVVideoCompositionInstructionProtocol,
            >,
        ) -> bool;

        #[cfg(all(feature = "AVAsset", feature = "AVVideoCompositing"))]
        /// Invoked by an instance of AVVideoComposition when validating an instance of AVVideoComposition, to report a video composition layer instruction with a trackID that does not correspond either to the trackID used for the composition's animationTool or to a track of the asset specified in -[AVVideoComposition isValidForAsset:timeRange:delegate:].
        ///
        /// - Returns: An indication of whether the AVVideoComposition should continue validation in order to report additional problems that may exist.
        #[optional]
        #[unsafe(method(videoComposition:shouldContinueValidatingAfterFindingInvalidTrackIDInInstruction:layerInstruction:asset:))]
        #[unsafe(method_family = none)]
        unsafe fn videoComposition_shouldContinueValidatingAfterFindingInvalidTrackIDInInstruction_layerInstruction_asset(
            &self,
            video_composition: &AVVideoComposition,
            video_composition_instruction: &ProtocolObject<
                dyn AVVideoCompositionInstructionProtocol,
            >,
            layer_instruction: &AVVideoCompositionLayerInstruction,
            asset: &AVAsset,
        ) -> bool;
    }
);
