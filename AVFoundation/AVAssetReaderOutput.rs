//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
use objc2_foundation::*;

use crate::*;

extern_class!(
    /// AVAssetReaderOutput is an abstract class that defines an interface for reading a single collection of samples of a common media type from an AVAssetReader.
    ///
    ///
    /// Clients can read the media data of an asset by adding one or more concrete instances of AVAssetReaderOutput to an AVAssetReader using the -[AVAssetReader addOutput:] method.
    ///
    /// IMPORTANT PERFORMANCE NOTE: Make sure to set the alwaysCopiesSampleData property to NO if you do not need to modify the sample data in-place, to avoid unnecessary and inefficient copying.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreaderoutput?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderOutput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderOutput {}
);

impl AVAssetReaderOutput {
    extern_methods!(
        #[cfg(feature = "AVMediaFormat")]
        /// The media type of the samples that can be read from the receiver.
        ///
        ///
        /// The value of this property is one of the media type strings defined in AVMediaFormat.h.
        #[unsafe(method(mediaType))]
        #[unsafe(method_family = none)]
        pub unsafe fn mediaType(&self) -> Retained<AVMediaType>;

        /// Indicates whether or not the data in buffers gets copied before being vended to the client.
        ///
        ///
        /// When the value of this property is YES, the AVAssetReaderOutput will always vend a buffer with copied data to the client.  Data in such buffers can be freely modified by the client. When the value of this property is NO, the buffers vended to the client may not be copied.  Such buffers may still be referenced by other entities. The result of modifying a buffer whose data hasn't been copied is undefined.  Requesting buffers whose data hasn't been copied when possible can lead to performance improvements.
        ///
        /// The default value is YES.
        ///
        /// This property throws an exception if a value is set after reading has started (the asset reader has progressed beyond AVAssetReaderStatusUnknown).
        #[unsafe(method(alwaysCopiesSampleData))]
        #[unsafe(method_family = none)]
        pub unsafe fn alwaysCopiesSampleData(&self) -> bool;

        /// Setter for [`alwaysCopiesSampleData`][Self::alwaysCopiesSampleData].
        #[unsafe(method(setAlwaysCopiesSampleData:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAlwaysCopiesSampleData(&self, always_copies_sample_data: bool);

        #[cfg(feature = "objc2-core-media")]
        /// Copies the next sample buffer for the output synchronously.
        ///
        ///
        /// Returns: A CMSampleBuffer object referencing the output sample buffer.
        ///
        ///
        /// The client is responsible for calling CFRelease on the returned CMSampleBuffer object when finished with it. This method will return NULL if there are no more sample buffers available for the receiver within the time range specified by its AVAssetReader's timeRange property, or if there is an error that prevents the AVAssetReader from reading more media data. When this method returns NULL, clients should check the value of the associated AVAssetReader's status property to determine why no more samples could be read.
        ///
        /// In certain configurations, such as when outputSettings is nil, copyNextSampleBuffer may return marker-only sample buffers as well as sample buffers containing media data. Marker-only sample buffers can be identified by CMSampleBufferGetNumSamples returning 0. Clients who do not need the information attached to marker-only sample buffers may skip them.
        ///
        /// This method throws an exception if this output is not added to an instance of AVAssetReader (using -addOutput:) and -startReading is not called on that asset reader.
        #[unsafe(method(copyNextSampleBuffer))]
        #[unsafe(method_family = copy)]
        pub unsafe fn copyNextSampleBuffer(&self) -> Option<Retained<CMSampleBuffer>>;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVAssetReaderOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

/// AVAssetReaderOutputRandomAccess.
impl AVAssetReaderOutput {
    extern_methods!(
        /// Indicates whether the asset reader output supports reconfiguration of the time ranges to read.
        ///
        ///
        /// When the value of this property is YES, the time ranges read by the asset reader output can be reconfigured during reading using the -resetForReadingTimeRanges: method.  This also prevents the attached AVAssetReader from progressing to AVAssetReaderStatusCompleted until -markConfigurationAsFinal has been invoked.
        ///
        /// The default value is NO, which means that the asset reader output may not be reconfigured once reading has begun.  When the value of this property is NO, AVAssetReader may be able to read media data more efficiently, particularly when multiple asset reader outputs are attached.
        ///
        /// This property throws an exception if a value is set after reading has started (the asset reader has progressed beyond AVAssetReaderStatusUnknown) or after an AVAssetReaderOutput.Provider is attached.
        #[unsafe(method(supportsRandomAccess))]
        #[unsafe(method_family = none)]
        pub unsafe fn supportsRandomAccess(&self) -> bool;

        /// Setter for [`supportsRandomAccess`][Self::supportsRandomAccess].
        #[unsafe(method(setSupportsRandomAccess:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setSupportsRandomAccess(&self, supports_random_access: bool);

        /// Starts reading over with a new set of time ranges.
        ///
        ///
        /// Parameter `timeRanges`: An NSArray of NSValue objects, each representing a single CMTimeRange structure
        ///
        ///
        /// This method may only be used if supportsRandomAccess has been set to YES and may not be called after -markConfigurationAsFinal has been invoked.
        ///
        /// This method is often used in conjunction with AVAssetWriter multi-pass (see AVAssetWriterInput category AVAssetWriterInputMultiPass).  In this usage, the caller will invoke -copyNextSampleBuffer until that method returns NULL and then ask the AVAssetWriterInput for a set of time ranges from which it thinks media data should be re-encoded.  These time ranges are then given to this method to set up the asset reader output for the next pass.
        ///
        /// The time ranges set here override the time range set on AVAssetReader.timeRange.  Just as with that property, for each time range in the array the intersection of that time range and CMTimeRangeMake(kCMTimeZero, asset.duration) will take effect.
        ///
        /// If this method is invoked after the status of the attached AVAssetReader has become AVAssetReaderStatusFailed or AVAssetReaderStatusCancelled, no change in status will occur and the result of the next call to -copyNextSampleBuffer will be NULL.
        ///
        /// This method throws an exception if the following conditions are not honored:
        /// - each item in time ranges must be an NSValue
        /// - the start of each time range must be numeric - see CMTIME_IS_NUMERIC
        /// - the duration of each time range must be nonnegative and numeric, or kCMTimePositiveInfinity
        /// - the start of each time range must be greater than or equal to the end of the previous time range
        /// - start times must be strictly increasing
        /// - time ranges must not overlap
        /// - cannot be called before -startReading has been invoked on the attached asset reader
        /// - cannot be called until all samples of media data have been read (i.e. copyNextSampleBuffer returns NULL and the asset reader has not entered a failure state)
        /// - cannot be called without setting "supportsRandomAccess" to YES
        /// - cannot be called after calling -markConfigurationAsFinal
        #[unsafe(method(resetForReadingTimeRanges:))]
        #[unsafe(method_family = none)]
        pub unsafe fn resetForReadingTimeRanges(&self, time_ranges: &NSArray<NSValue>);

        /// Informs the receiver that no more reconfiguration of time ranges is necessary and allows the attached AVAssetReader to advance to AVAssetReaderStatusCompleted.
        ///
        ///
        /// When the value of supportsRandomAccess is YES, the attached asset reader will not advance to AVAssetReaderStatusCompleted until this method is called.
        ///
        /// When the destination of media data vended by the receiver is an AVAssetWriterInput configured for multi-pass encoding, a convenient time to invoke this method is after the asset writer input indicates that no more passes will be performed.
        ///
        /// Once this method has been called, further invocations of -resetForReadingTimeRanges: are disallowed.
        #[unsafe(method(markConfigurationAsFinal))]
        #[unsafe(method_family = none)]
        pub unsafe fn markConfigurationAsFinal(&self);
    );
}

extern_class!(
    /// AVAssetReaderTrackOutput is a concrete subclass of AVAssetReaderOutput that defines an interface for reading media data from a single AVAssetTrack of an AVAssetReader's AVAsset.
    ///
    ///
    /// Clients can read the media data of an asset track by adding an instance of AVAssetReaderTrackOutput to an AVAssetReader using the -[AVAssetReader addOutput:] method. The track's media samples can either be read in the format in which they are stored in the asset, or they can be converted to a different format.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput?language=objc)
    #[unsafe(super(AVAssetReaderOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderTrackOutput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderTrackOutput {}
);

impl AVAssetReaderTrackOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Returns an instance of AVAssetReaderTrackOutput for reading from the specified track and supplying media data according to the specified output settings.
        ///
        ///
        /// Parameter `track`: The AVAssetTrack from which the resulting AVAssetReaderTrackOutput should read sample buffers.
        ///
        /// Parameter `outputSettings`: An NSDictionary of output settings to be used for sample output.  See AVAudioSettings.h for available output settings for audio tracks or AVVideoSettings.h for available output settings for video tracks and also for more information about how to construct an output settings dictionary.
        ///
        /// Returns: An instance of AVAssetReaderTrackOutput.
        ///
        ///
        /// The track must be one of the tracks contained by the target AVAssetReader's asset.
        ///
        /// A value of nil for outputSettings configures the output to vend samples in their original format as stored by the specified track.  Initialization will fail if the output settings cannot be used with the specified track.
        ///
        /// AVAssetReaderTrackOutput can only produce uncompressed output.  For audio output settings, this means that AVFormatIDKey must be kAudioFormatLinearPCM.  For video output settings, this means that the dictionary must follow the rules for uncompressed video output, as laid out in AVVideoSettings.h.  AVAssetReaderTrackOutput does not support the AVAudioSettings.h key AVSampleRateConverterAudioQualityKey or the following AVVideoSettings.h keys:
        ///
        /// AVVideoCleanApertureKey
        /// AVVideoPixelAspectRatioKey
        /// AVVideoScalingModeKey
        ///
        /// When constructing video output settings the choice of pixel format will affect the performance and quality of the decompression. For optimal performance when decompressing video the requested pixel format should be one that the decoder supports natively to avoid unnecessary conversions. Below are some recommendations:
        ///
        /// For H.264 use kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange, or kCVPixelFormatType_420YpCbCr8BiPlanarFullRange if the video is known to be full range.  For JPEG on iOS, use kCVPixelFormatType_420YpCbCr8BiPlanarFullRange.
        ///
        /// For other codecs on OSX, kCVPixelFormatType_422YpCbCr8 is the preferred pixel format for video and is generally the most performant when decoding. If you need to work in the RGB domain then kCVPixelFormatType_32BGRA is recommended.
        ///
        /// ProRes encoded media can contain up to 12bits/ch. If your source is ProRes encoded and you wish to preserve more than 8bits/ch during decompression then use one of the following pixel formats: kCVPixelFormatType_4444AYpCbCr16, kCVPixelFormatType_422YpCbCr16, kCVPixelFormatType_422YpCbCr10, or kCVPixelFormatType_64ARGB.  AVAssetReader does not support scaling with any of these high bit depth pixel formats. If you use them then do not specify kCVPixelBufferWidthKey or kCVPixelBufferHeightKey in your outputSettings dictionary. If you plan to append these sample buffers to an AVAssetWriterInput then note that only the ProRes encoders support these pixel formats.
        ///
        /// ProRes 4444 encoded media can contain a mathematically lossless alpha channel. To preserve the alpha channel during decompression use a pixel format with an alpha component such as kCVPixelFormatType_4444AYpCbCr16 or kCVPixelFormatType_64ARGB. To test whether your source contains an alpha channel check that the track's format description has kCMFormatDescriptionExtension_Depth and that its value is 32.
        #[unsafe(method(assetReaderTrackOutputWithTrack:outputSettings:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderTrackOutputWithTrack_outputSettings(
            track: &AVAssetTrack,
            output_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Returns an instance of AVAssetReaderTrackOutput for reading from the specified track and supplying media data according to the specified output settings.
        ///
        ///
        /// Parameter `track`: The AVAssetTrack from which the resulting AVAssetReaderTrackOutput should read sample buffers.
        ///
        /// Parameter `outputSettings`: An NSDictionary of output settings to be used for sample output.  See AVAudioSettings.h for available output settings for audio tracks or AVVideoSettings.h for available output settings for video tracks and also for more information about how to construct an output settings dictionary.
        ///
        /// Returns: An instance of AVAssetReaderTrackOutput.
        ///
        ///
        /// The track must be one of the tracks contained by the target AVAssetReader's asset.
        ///
        /// A value of nil for outputSettings configures the output to vend samples in their original format as stored by the specified track.  Initialization will fail if the output settings cannot be used with the specified track.
        ///
        /// AVAssetReaderTrackOutput can only produce uncompressed output.  For audio output settings, this means that AVFormatIDKey must be kAudioFormatLinearPCM.  For video output settings, this means that the dictionary must follow the rules for uncompressed video output, as laid out in AVVideoSettings.h.  AVAssetReaderTrackOutput does not support the AVAudioSettings.h key AVSampleRateConverterAudioQualityKey or the following AVVideoSettings.h keys:
        ///
        /// AVVideoCleanApertureKey
        /// AVVideoPixelAspectRatioKey
        /// AVVideoScalingModeKey
        ///
        /// When constructing video output settings the choice of pixel format will affect the performance and quality of the decompression. For optimal performance when decompressing video the requested pixel format should be one that the decoder supports natively to avoid unnecessary conversions. Below are some recommendations:
        ///
        /// For H.264 use kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange, or kCVPixelFormatType_420YpCbCr8BiPlanarFullRange if the video is known to be full range.  For JPEG on iOS, use kCVPixelFormatType_420YpCbCr8BiPlanarFullRange.
        ///
        /// For other codecs on OSX, kCVPixelFormatType_422YpCbCr8 is the preferred pixel format for video and is generally the most performant when decoding. If you need to work in the RGB domain then kCVPixelFormatType_32BGRA is recommended.
        ///
        /// ProRes encoded media can contain up to 12bits/ch. If your source is ProRes encoded and you wish to preserve more than 8bits/ch during decompression then use one of the following pixel formats: kCVPixelFormatType_4444AYpCbCr16, kCVPixelFormatType_422YpCbCr16, kCVPixelFormatType_422YpCbCr10, or kCVPixelFormatType_64ARGB.  AVAssetReader does not support scaling with any of these high bit depth pixel formats. If you use them then do not specify kCVPixelBufferWidthKey or kCVPixelBufferHeightKey in your outputSettings dictionary. If you plan to append these sample buffers to an AVAssetWriterInput then note that only the ProRes encoders support these pixel formats.
        ///
        /// ProRes 4444 encoded media can contain a mathematically lossless alpha channel. To preserve the alpha channel during decompression use a pixel format with an alpha component such as kCVPixelFormatType_4444AYpCbCr16 or kCVPixelFormatType_64ARGB.  To test whether your source contains an alpha channel check that the track's format description has kCMFormatDescriptionExtension_Depth and that its value is 32.
        ///
        /// This method throws an exception for any of the following reasons:
        /// - the output settings dictionary contains an unsupported key mentioned above
        /// - the output settings dictionary does not contain any recognized key
        /// - output settings are not compatible with track's media type
        /// - track output settings would cause the output to yield compressed samples
        #[unsafe(method(initWithTrack:outputSettings:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithTrack_outputSettings(
            this: Allocated<Self>,
            track: &AVAssetTrack,
            output_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// The track from which the receiver reads sample buffers.
        ///
        ///
        /// The value of this property is an AVAssetTrack owned by the target AVAssetReader's asset.
        #[unsafe(method(track))]
        #[unsafe(method_family = none)]
        pub unsafe fn track(&self) -> Retained<AVAssetTrack>;

        /// The output settings used by the receiver.
        ///
        ///
        /// The value of this property is an NSDictionary that contains values for keys as specified by either AVAudioSettings.h for audio tracks or AVVideoSettings.h for video tracks.  A value of nil indicates that the receiver will vend samples in their original format as stored in the target track.
        #[unsafe(method(outputSettings))]
        #[unsafe(method_family = none)]
        pub unsafe fn outputSettings(&self) -> Option<Retained<NSDictionary<NSString, AnyObject>>>;

        #[cfg(feature = "AVAudioProcessingSettings")]
        /// Indicates the processing algorithm used to manage audio pitch for scaled audio edits.
        ///
        ///
        /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchAlgorithmSpectral, are defined in AVAudioProcessingSettings.h.  An NSInvalidArgumentException will be raised if this property is set to a value other than the constants defined in that file.
        ///
        /// The default value is AVAudioTimePitchAlgorithmSpectral.
        ///
        /// This property throws an exception for any of the following reasons:
        /// - a value is set value after reading has started
        /// - a value is set other than AVAudioTimePitchAlgorithmSpectral, AVAudioTimePitchAlgorithmTimeDomain, or AVAudioTimePitchAlgorithmVarispeed.
        #[unsafe(method(audioTimePitchAlgorithm))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioTimePitchAlgorithm(&self) -> Retained<AVAudioTimePitchAlgorithm>;

        #[cfg(feature = "AVAudioProcessingSettings")]
        /// Setter for [`audioTimePitchAlgorithm`][Self::audioTimePitchAlgorithm].
        #[unsafe(method(setAudioTimePitchAlgorithm:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAudioTimePitchAlgorithm(
            &self,
            audio_time_pitch_algorithm: &AVAudioTimePitchAlgorithm,
        );
    );
}

extern_class!(
    /// AVAssetReaderAudioMixOutput is a concrete subclass of AVAssetReaderOutput that defines an interface for reading audio samples that result from mixing the audio from one or more AVAssetTracks of an AVAssetReader's AVAsset.
    ///
    ///
    /// Clients can read the audio data mixed from one or more asset tracks by adding an instance of AVAssetReaderAudioMixOutput to an AVAssetReader using the -[AVAssetReader addOutput:] method.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreaderaudiomixoutput?language=objc)
    #[unsafe(super(AVAssetReaderOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderAudioMixOutput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderAudioMixOutput {}
);

impl AVAssetReaderAudioMixOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Returns an instance of AVAssetReaderAudioMixOutput for reading mixed audio from the specified audio tracks, with optional audio settings.
        ///
        ///
        /// Parameter `tracks`: An NSArray of AVAssetTrack objects from which the created object should read sample buffers to be mixed.
        ///
        /// Parameter `audioSettings`: An NSDictionary of audio settings to be used for audio output.
        ///
        /// Returns: An instance of AVAssetReaderAudioMixOutput.
        ///
        ///
        /// Each track must be one of the tracks owned by the target AVAssetReader's asset and must be of media type AVMediaTypeAudio.
        ///
        /// For non-nil values of audioSettings, the audio settings dictionary must contain values for keys in AVAudioSettings.h (linear PCM only). Initialization will fail if the audio settings cannot be used with the specified tracks. AVSampleRateConverterAudioQualityKey is not supported.
        ///
        /// A value of nil for audioSettings configures the output to return samples in a convenient uncompressed format, with sample rate and other properties determined according to the properties of the specified audio tracks as well as other considerations that may vary according to device capabilities, operating system version, and other factors. Therefore if you wish to perform any processing on the output, you must examine the CMAudioFormatDescription of the CMSampleBuffers that are provided in order to ensure that your processing is appropriately configured for the output format.
        #[unsafe(method(assetReaderAudioMixOutputWithAudioTracks:audioSettings:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderAudioMixOutputWithAudioTracks_audioSettings(
            audio_tracks: &NSArray<AVAssetTrack>,
            audio_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Creates an instance of AVAssetReaderAudioMixOutput for reading mixed audio from the specified audio tracks, with optional audio settings.
        ///
        ///
        /// Parameter `tracks`: An NSArray of AVAssetTrack objects from which the created object should read sample buffers to be mixed.
        ///
        /// Parameter `audioSettings`: An NSDictionary of audio settings to be used for audio output.
        ///
        /// Returns: An instance of AVAssetReaderAudioMixOutput.
        ///
        ///
        /// Each track must be one of the tracks owned by the target AVAssetReader's asset and must be of media type AVMediaTypeAudio.
        ///
        /// For non-nil values of audioSettings, the audio settings dictionary must contain values for keys in AVAudioSettings.h (linear PCM only). Initialization will fail if the audio settings cannot be used with the specified tracks. AVSampleRateConverterAudioQualityKey is not supported.
        ///
        /// A value of nil for audioSettings configures the output to return samples in a convenient uncompressed format, with sample rate and other properties determined according to the properties of the specified audio tracks as well as other considerations that may vary according to device capabilities, operating system version, and other factors. Therefore if you wish to perform any processing on the output, you must examine the CMAudioFormatDescription of the CMSampleBuffers that are provided in order to ensure that your processing is appropriately configured for the output format.
        ///
        /// This method throws an exception for any of the following reasons:
        /// - an audio track does not have media type AVMediaTypeAudio
        /// - an audio track belongs to a different AVAsset
        /// - the audio settings contains an AVSampleRateConverterAudioQualityKey
        /// - the output would be compressed
        #[unsafe(method(initWithAudioTracks:audioSettings:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithAudioTracks_audioSettings(
            this: Allocated<Self>,
            audio_tracks: &NSArray<AVAssetTrack>,
            audio_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// The tracks from which the receiver reads mixed audio.
        ///
        ///
        /// The value of this property is an NSArray of AVAssetTracks owned by the target AVAssetReader's asset.
        #[unsafe(method(audioTracks))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioTracks(&self) -> Retained<NSArray<AVAssetTrack>>;

        /// The audio settings used by the receiver.
        ///
        ///
        /// The value of this property is an NSDictionary that contains values for keys from AVAudioSettings.h (linear PCM only).  A value of nil indicates that the receiver will return audio samples in a convenient uncompressed format, with sample rate and other properties determined according to the properties of the receiver's audio tracks.
        #[unsafe(method(audioSettings))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioSettings(&self) -> Option<Retained<NSDictionary<NSString, AnyObject>>>;

        #[cfg(feature = "AVAudioMix")]
        /// The audio mix used by the receiver.
        ///
        ///
        /// The value of this property is an AVAudioMix that can be used to specify how the volume of audio samples read from each source track will change over the timeline of the source asset.
        ///
        /// This property throws an exception for any of the following reasons:
        /// - an audio mix is set after reading has started (the asset reader has progressed beyond AVAssetReaderStatusUnknown)
        /// - setting an audio mix containing a track that was not used to create the receiver
        /// - an audio mix is set containing an invalid audio time pitch algorithm
        #[unsafe(method(audioMix))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioMix(&self) -> Option<Retained<AVAudioMix>>;

        #[cfg(feature = "AVAudioMix")]
        /// Setter for [`audioMix`][Self::audioMix].
        #[unsafe(method(setAudioMix:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAudioMix(&self, audio_mix: Option<&AVAudioMix>);

        #[cfg(feature = "AVAudioProcessingSettings")]
        /// Indicates the processing algorithm used to manage audio pitch for scaled audio edits.
        ///
        ///
        /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchAlgorithmSpectral, are defined in AVAudioProcessingSettings.h.  An NSInvalidArgumentException will be raised if this property is set to a value other than the constants defined in that file.
        ///
        /// The default value is AVAudioTimePitchAlgorithmSpectral.
        #[unsafe(method(audioTimePitchAlgorithm))]
        #[unsafe(method_family = none)]
        pub unsafe fn audioTimePitchAlgorithm(&self) -> Retained<AVAudioTimePitchAlgorithm>;

        #[cfg(feature = "AVAudioProcessingSettings")]
        /// Setter for [`audioTimePitchAlgorithm`][Self::audioTimePitchAlgorithm].
        #[unsafe(method(setAudioTimePitchAlgorithm:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setAudioTimePitchAlgorithm(
            &self,
            audio_time_pitch_algorithm: &AVAudioTimePitchAlgorithm,
        );
    );
}

extern_class!(
    /// AVAssetReaderVideoCompositionOutput is a concrete subclass of AVAssetReaderOutput that defines an interface for reading video frames that have been composited together from the frames in one or more AVAssetTracks of an AVAssetReader's AVAsset.
    ///
    ///
    /// Clients can read the video frames composited from one or more asset tracks by adding an instance of AVAssetReaderVideoCompositionOutput to an AVAssetReader using the -[AVAssetReader addOutput:] method.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreadervideocompositionoutput?language=objc)
    #[unsafe(super(AVAssetReaderOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderVideoCompositionOutput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderVideoCompositionOutput {}
);

impl AVAssetReaderVideoCompositionOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Creates an instance of AVAssetReaderVideoCompositionOutput for reading composited video from the specified video tracks and supplying media data according to the specified video settings.
        ///
        ///
        /// Parameter `tracks`: An NSArray of AVAssetTrack objects from which the resulting AVAssetReaderVideoCompositionOutput should read video frames for compositing.
        ///
        /// Parameter `videoSettings`: An NSDictionary of video settings to be used for video output.  See AVVideoSettings.h for more information about how to construct a video settings dictionary.
        ///
        /// Returns: An instance of AVAssetReaderVideoCompositionOutput.
        ///
        ///
        /// Each track must be one of the tracks owned by the target AVAssetReader's asset and must be of media type AVMediaTypeVideo.
        ///
        /// A value of nil for videoSettings configures the output to return samples in a convenient uncompressed format, with properties determined according to the properties of the specified video tracks.  Initialization will fail if the video settings cannot be used with the specified tracks.
        ///
        /// AVAssetReaderVideoCompositionOutput can only produce uncompressed output.  This means that the video settings dictionary must follow the rules for uncompressed video output, as laid out in AVVideoSettings.h.  In addition, the following keys are not supported:
        ///
        /// AVVideoCleanApertureKey
        /// AVVideoPixelAspectRatioKey
        /// AVVideoScalingModeKey
        #[unsafe(method(assetReaderVideoCompositionOutputWithVideoTracks:videoSettings:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderVideoCompositionOutputWithVideoTracks_videoSettings(
            video_tracks: &NSArray<AVAssetTrack>,
            video_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Creates an instance of AVAssetReaderVideoCompositionOutput for reading composited video from the specified video tracks and supplying media data according to the specified video settings.
        ///
        ///
        /// Parameter `tracks`: An NSArray of AVAssetTrack objects from which the resulting AVAssetReaderVideoCompositionOutput should read video frames for compositing.
        ///
        /// Parameter `videoSettings`: An NSDictionary of video settings to be used for video output.  See AVVideoSettings.h for more information about how to construct a video settings dictionary.
        ///
        /// Returns: An instance of AVAssetReaderVideoCompositionOutput.
        ///
        ///
        /// Each track must be one of the tracks owned by the target AVAssetReader's asset and must be of media type AVMediaTypeVideo.
        ///
        /// A value of nil for videoSettings configures the output to return samples in a convenient uncompressed format, with properties determined according to the properties of the specified video tracks.  Initialization will fail if the video settings cannot be used with the specified tracks.
        ///
        /// AVAssetReaderVideoCompositionOutput can only produce uncompressed output.  This means that the video settings dictionary must follow the rules for uncompressed video output, as laid out in AVVideoSettings.h.
        ///
        /// This method throws an exception for any of the following reasons:
        /// - any video track is not of media type AVMediaTypeVideo
        /// - any video track is not part of this asset reader output's AVAsset
        /// - track output settings would cause the output to yield compressed samples
        /// - video settings does not follow the rules for uncompressed video output (AVVideoSettings.h)
        /// - video settings contains any of the following keys:
        /// - AVVideoCleanApertureKey
        /// - AVVideoPixelAspectRatioKey
        /// - AVVideoScalingModeKey
        /// - AVVideoDecompressionPropertiesKey
        #[unsafe(method(initWithVideoTracks:videoSettings:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithVideoTracks_videoSettings(
            this: Allocated<Self>,
            video_tracks: &NSArray<AVAssetTrack>,
            video_settings: Option<&NSDictionary<NSString, AnyObject>>,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// The tracks from which the receiver reads composited video.
        ///
        ///
        /// The value of this property is an NSArray of AVAssetTracks owned by the target AVAssetReader's asset.
        #[unsafe(method(videoTracks))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoTracks(&self) -> Retained<NSArray<AVAssetTrack>>;

        /// The video settings used by the receiver.
        ///
        ///
        /// The value of this property is an NSDictionary that contains values for keys as specified by AVVideoSettings.h.  A value of nil indicates that the receiver will return video frames in a convenient uncompressed format, with properties determined according to the properties of the receiver's video tracks.
        #[unsafe(method(videoSettings))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoSettings(&self) -> Option<Retained<NSDictionary<NSString, AnyObject>>>;

        #[cfg(feature = "AVVideoComposition")]
        /// The composition of video used by the receiver.
        ///
        ///
        /// The value of this property is an AVVideoComposition that can be used to specify the visual arrangement of video frames read from each source track over the timeline of the source asset.
        ///
        /// This property throws an exception if a value is set after reading has started.
        #[unsafe(method(videoComposition))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoComposition(&self) -> Option<Retained<AVVideoComposition>>;

        #[cfg(feature = "AVVideoComposition")]
        /// Setter for [`videoComposition`][Self::videoComposition].
        #[unsafe(method(setVideoComposition:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setVideoComposition(&self, video_composition: Option<&AVVideoComposition>);

        #[cfg(feature = "AVVideoCompositing")]
        /// Indicates the custom video compositor instance used by the receiver.
        ///
        ///
        /// This property is nil if there is no video compositor, or if the internal video compositor is in use.
        #[unsafe(method(customVideoCompositor))]
        #[unsafe(method_family = none)]
        pub unsafe fn customVideoCompositor(
            &self,
        ) -> Option<Retained<ProtocolObject<dyn AVVideoCompositing>>>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreaderoutputmetadataadaptor?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderOutputMetadataAdaptor;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderOutputMetadataAdaptor {}
);

impl AVAssetReaderOutputMetadataAdaptor {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// Creates a new timed metadata group adaptor for retrieving timed metadata group objects from an asset reader output.
        ///
        ///
        /// Parameter `assetReaderOutput`: An instance of AVAssetReaderTrackOutput that vends sample buffers containing metadata, e.g. an AVAssetReaderTrackOutput object initialized with a track of media type AVMediaTypeMetadata and nil outputSettings.
        ///
        /// Returns: An instance of AVAssetReaderOutputMetadataAdaptor
        ///
        ///
        /// It is an error to create a timed metadata group adaptor with an asset reader output that does not vend metadata.  It is also an error to create a timed metadata group adaptor with an asset reader output whose asset reader has already started reading, or an asset reader output that already has been used to initialize another timed metadata group adaptor.
        ///
        /// Clients should not mix calls to -[AVAssetReaderTrackOutput copyNextSampleBuffer] and -[AVAssetReaderOutputMetadataAdaptor nextTimedMetadataGroup].  Once an AVAssetReaderTrackOutput instance has been used to initialize an AVAssetReaderOutputMetadataAdaptor, calling -copyNextSampleBuffer on that instance will result in an exception being thrown.
        #[unsafe(method(assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput(
            track_output: &AVAssetReaderTrackOutput,
        ) -> Retained<Self>;

        /// Creates a new timed metadata group adaptor for retrieving timed metadata group objects from an asset reader output.
        ///
        ///
        /// Parameter `assetReaderOutput`: An instance of AVAssetReaderTrackOutput that vends sample buffers containing metadata, e.g. an AVAssetReaderTrackOutput object initialized with a track of media type AVMediaTypeMetadata and nil outputSettings.
        ///
        /// Returns: An instance of AVAssetReaderOutputMetadataAdaptor
        ///
        ///
        /// It is an error to create a timed metadata group adaptor with an asset reader output that does not vend metadata.  It is also an error to create a timed metadata group adaptor with an asset reader output whose asset reader has already started reading, or an asset reader output that already has been used to initialize another timed metadata group adaptor.
        ///
        /// Clients should not mix calls to -[AVAssetReaderTrackOutput copyNextSampleBuffer] and -[AVAssetReaderOutputMetadataAdaptor nextTimedMetadataGroup].  Once an AVAssetReaderTrackOutput instance has been used to initialize an AVAssetReaderOutputMetadataAdaptor, calling -copyNextSampleBuffer on that instance will result in an exception being thrown.
        ///
        /// This method throws an exception if the track's output was used to initialize another adaptor or if the track output's asset reader has already started reading.
        #[unsafe(method(initWithAssetReaderTrackOutput:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithAssetReaderTrackOutput(
            this: Allocated<Self>,
            track_output: &AVAssetReaderTrackOutput,
        ) -> Retained<Self>;

        /// The asset reader track output from which the receiver pulls timed metadata groups.
        #[unsafe(method(assetReaderTrackOutput))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderTrackOutput(&self) -> Retained<AVAssetReaderTrackOutput>;

        #[cfg(feature = "AVTimedMetadataGroup")]
        /// Returns the next timed metadata group for the asset reader output, synchronously.
        ///
        ///
        /// Returns: An instance of AVTimedMetadataGroup, representing the next logical segment of metadata coming from the source asset reader output.
        ///
        ///
        /// This method will return nil when all timed metadata groups have been read from the asset reader output, or if there is an error that prevents the timed metadata group adaptor from reading more timed metadata groups.  When this method returns nil, clients should check the value of the associated AVAssetReader's status property to determine why no more samples could be read.
        ///
        /// Unlike -[AVAssetReaderTrackOutput copyNextSampleBuffer], this method returns an autoreleased object.
        ///
        /// Before calling this method, you must ensure that the output which underlies the receiver is attached to an AVAssetReader via a prior call to -addOutput: and that -startReading has been called on the asset reader.
        ///
        /// This method throws an exception if track output is not attached to an asset reader and reading has not yet begun.
        #[unsafe(method(nextTimedMetadataGroup))]
        #[unsafe(method_family = none)]
        pub unsafe fn nextTimedMetadataGroup(&self) -> Option<Retained<AVTimedMetadataGroup>>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreaderoutputcaptionadaptor?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderOutputCaptionAdaptor;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderOutputCaptionAdaptor {}
);

impl AVAssetReaderOutputCaptionAdaptor {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// Creates a new caption adaptor for reading from the given track output.
        ///
        /// Parameter `trackOutput`: The track output from which to read captions.
        ///
        /// Returns: A new instance of AVAssetReaderOutputCaptionAdaptor, configured to read captions from the given AVAssetReaderTrackOutput.
        ///
        /// It is an error to pass nil to this method.
        #[unsafe(method(assetReaderOutputCaptionAdaptorWithAssetReaderTrackOutput:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderOutputCaptionAdaptorWithAssetReaderTrackOutput(
            track_output: &AVAssetReaderTrackOutput,
        ) -> Retained<Self>;

        /// Creates a new caption adaptor for reading from the given track output.
        ///
        /// Parameter `trackOutput`: The track output from which to read captions.
        ///
        /// Returns: A new instance of AVAssetReaderOutputCaptionAdaptor, configured to read captions from the given AVAssetReaderTrackOutput.
        ///
        /// It is an error to pass nil to this method.
        #[unsafe(method(initWithAssetReaderTrackOutput:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithAssetReaderTrackOutput(
            this: Allocated<Self>,
            track_output: &AVAssetReaderTrackOutput,
        ) -> Retained<Self>;

        /// The track output used to create the receiver.
        #[unsafe(method(assetReaderTrackOutput))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderTrackOutput(&self) -> Retained<AVAssetReaderTrackOutput>;

        #[cfg(feature = "AVCaptionGroup")]
        /// Returns the next caption.
        ///
        /// Returns: An instance of AVCaption representing the next caption.
        ///
        /// The method returns the next caption group.
        ///
        /// This method throws an exception if the track output is not attached to an asset reader and reading has not yet begun.
        #[unsafe(method(nextCaptionGroup))]
        #[unsafe(method_family = none)]
        pub unsafe fn nextCaptionGroup(&self) -> Option<Retained<AVCaptionGroup>>;

        #[cfg(all(feature = "AVCaption", feature = "AVCaptionGroup"))]
        /// Returns the set of captions that are present in the given group but were not present in any group previously vended by calls to -nextCaptionGroup: on the receiver.
        ///
        /// Parameter `captionGroup`: The group containing the captions of interest.
        ///
        /// Returns: An array of AVCaption objects.
        ///
        /// The returned array contains the set of captions in the given group whose time ranges have the same start time as the group.  This method is provided as a convenience for clients who want to process captions one-by-one and do not need a complete view of the set of captions active at a given time.
        #[unsafe(method(captionsNotPresentInPreviousGroupsInCaptionGroup:))]
        #[unsafe(method_family = none)]
        pub unsafe fn captionsNotPresentInPreviousGroupsInCaptionGroup(
            &self,
            caption_group: &AVCaptionGroup,
        ) -> Retained<NSArray<AVCaption>>;
    );
}

/// AVAssetReaderCaptionValidation.
/// Category of AVAssetReaderOutputCaptionAdaptor for caption validation handling
impl AVAssetReaderOutputCaptionAdaptor {
    extern_methods!(
        /// Register caption validation handling callback protocol to the caption adaptor.
        #[unsafe(method(validationDelegate))]
        #[unsafe(method_family = none)]
        pub unsafe fn validationDelegate(
            &self,
        ) -> Option<Retained<ProtocolObject<dyn AVAssetReaderCaptionValidationHandling>>>;

        /// This is a [weak property][objc2::topics::weak_property].
        /// Setter for [`validationDelegate`][Self::validationDelegate].
        #[unsafe(method(setValidationDelegate:))]
        #[unsafe(method_family = none)]
        pub unsafe fn setValidationDelegate(
            &self,
            validation_delegate: Option<
                &ProtocolObject<dyn AVAssetReaderCaptionValidationHandling>,
            >,
        );
    );
}

extern_protocol!(
    /// A protocol to receive caption validation notifications
    ///
    /// A client can implement the protocol on its own class which processes the caption validation calls.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreadercaptionvalidationhandling?language=objc)
    pub unsafe trait AVAssetReaderCaptionValidationHandling: NSObjectProtocol {
        #[cfg(feature = "AVCaption")]
        /// Called when one or more syntax elements were ignored in the process of creating the caption object.
        ///
        ///
        /// Parameter `adaptor`: The caption adaptor object
        ///
        /// Parameter `caption`: The caption object. The parser skipped unsupported syntax elements when creating this object.
        ///
        /// Parameter `syntaxElements`: Array of NSString to represent the skipped syntax.
        ///
        ///
        /// While the reported string content is human readable, it is highly technical and probably meaningful only to clients who are familiar with the source caption format. It is primarily designed for logging purpose and would not be suitable for UI purpose.
        #[optional]
        #[unsafe(method(captionAdaptor:didVendCaption:skippingUnsupportedSourceSyntaxElements:))]
        #[unsafe(method_family = none)]
        unsafe fn captionAdaptor_didVendCaption_skippingUnsupportedSourceSyntaxElements(
            &self,
            adaptor: &AVAssetReaderOutputCaptionAdaptor,
            caption: &AVCaption,
            syntax_elements: &NSArray<NSString>,
        );
    }
);

extern_class!(
    /// AVAssetReaderSampleReferenceOutput is a concrete subclass of AVAssetReaderOutput that defines an interface for reading sample references from a single AVAssetTrack of an AVAssetReader's AVAsset.
    ///
    /// Clients can extract information about the location (file URL and offset) of samples in a track by adding an instance of AVAssetReaderSampleReferenceOutput to an AVAssetReader using the -[AVAssetReader addOutput:] method. No actual sample data can be extracted using this class. The location of the sample data is described by the kCMSampleBufferAttachmentKey_SampleReferenceURL and kCMSampleBufferAttachmentKey_SampleReferenceByteOffset attachments on the extracted sample buffers. More information about sample buffers describing sample references can be found in the CMSampleBuffer documentation.
    ///
    /// Sample buffers extracted using this class can also be appended to an AVAssetWriterInput to create movie tracks that are not self-contained and reference data in the original file instead.  Currently, only instances of AVAssetWriter configured to write files of type AVFileTypeQuickTimeMovie can be used to write tracks that are not self-contained.
    ///
    /// Since no sample data is ever returned by instances of AVAssetReaderSampleReferenceOutput, the value of the alwaysCopiesSampleData property is ignored.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avassetreadersamplereferenceoutput?language=objc)
    #[unsafe(super(AVAssetReaderOutput, NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAssetReaderSampleReferenceOutput;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAssetReaderSampleReferenceOutput {}
);

impl AVAssetReaderSampleReferenceOutput {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Returns an instance of AVAssetReaderSampleReferenceOutput for supplying sample references.
        ///
        ///
        /// Parameter `track`: The AVAssetTrack for which the resulting AVAssetReaderSampleReferenceOutput should provide sample references.
        ///
        /// Returns: An instance of AVAssetReaderSampleReferenceOutput.
        ///
        ///
        /// The track must be one of the tracks contained by the target AVAssetReader's asset.
        #[unsafe(method(assetReaderSampleReferenceOutputWithTrack:))]
        #[unsafe(method_family = none)]
        pub unsafe fn assetReaderSampleReferenceOutputWithTrack(
            track: &AVAssetTrack,
        ) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// Returns an instance of AVAssetReaderSampleReferenceOutput for supplying sample references.
        ///
        ///
        /// Parameter `track`: The AVAssetTrack for which the resulting AVAssetReaderSampleReferenceOutput should provide sample references.
        ///
        /// Returns: An instance of AVAssetReaderTrackOutput.
        ///
        ///
        /// The track must be one of the tracks contained by the target AVAssetReader's asset.
        #[unsafe(method(initWithTrack:))]
        #[unsafe(method_family = init)]
        pub unsafe fn initWithTrack(this: Allocated<Self>, track: &AVAssetTrack) -> Retained<Self>;

        #[cfg(feature = "AVAssetTrack")]
        /// The track from which the receiver extracts sample references.
        ///
        ///
        /// The value of this property is an AVAssetTrack owned by the target AVAssetReader's asset.
        #[unsafe(method(track))]
        #[unsafe(method_family = none)]
        pub unsafe fn track(&self) -> Retained<AVAssetTrack>;
    );
}
