//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-video")]
use objc2_core_video::*;
use objc2_foundation::*;
#[cfg(feature = "objc2-image-io")]
use objc2_image_io::*;

use crate::*;

/// Values indicating the overall quality of a depth data map.
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, Default)]
pub struct AVDepthDataQuality(pub NSInteger);
impl AVDepthDataQuality {
    /// The depth map is a poor candidate for rendering high-quality depth effects or reconstructing a 3D scene.
    ///
    /// ## Discussion
    ///
    /// Low quality occurs when the process generating the depth map (such as inference of depth from disparity on a device with dual cameras) cannot find enough distinct key points in the input images, resulting in a large number of invalid depth values in the (pre-filtered) map.
    ///
    ///
    #[doc(alias = "AVDepthDataQualityLow")]
    pub const Low: Self = Self(0);
    /// The depth map is a good candidate for rendering high-quality depth effects or reconstructing a 3D scene.
    ///
    /// ## Discussion
    ///
    ///
    #[doc(alias = "AVDepthDataQualityHigh")]
    pub const High: Self = Self(1);
}

unsafe impl Encode for AVDepthDataQuality {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for AVDepthDataQuality {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// Values indicating the general accuracy of a depth data map.
///
/// ## Overview
///
/// The accuracy of a depth data map is highly dependent on the camera calibration data used to generate it. If the camera’s focal length cannot be precisely determined at the time of capture, a scaling error in the z (depth) plane is introduced. If the camera’s optical center can’t be precisely determined at capture time, a principal point error is introduced, leading to an offset error in the disparity estimate.
///
/// These values report the accuracy of a map’s values with respect to its reported units.
///
///
// NS_ENUM
#[repr(transparent)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, Default)]
pub struct AVDepthDataAccuracy(pub NSInteger);
impl AVDepthDataAccuracy {
    /// Values within the depth data map are usable for foreground/background separation, but are not absolutely accurate in the physical world.
    ///
    /// ## Discussion
    ///
    /// This level of accuracy indicates that values within a depth map are usable relative to one another (that is, a depth value of 2 is twice as far as a depth value of 1), but do not accurately convey real-world distance.
    ///
    ///
    #[doc(alias = "AVDepthDataAccuracyRelative")]
    pub const Relative: Self = Self(0);
    /// Values within the depth map are absolutely accurate within the physical world.
    #[doc(alias = "AVDepthDataAccuracyAbsolute")]
    pub const Absolute: Self = Self(1);
}

unsafe impl Encode for AVDepthDataAccuracy {
    const ENCODING: Encoding = NSInteger::ENCODING;
}

unsafe impl RefEncode for AVDepthDataAccuracy {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// A container for per-pixel distance or disparity information captured by compatible camera devices.
    ///
    /// ## Overview
    ///
    /// _Depth data_ is a generic term for a map of per-pixel data containing depth-related information. A depth data object wraps a disparity or depth map and provides conversion methods, focus information, and camera calibration data to aid in using the map for rendering or computer vision tasks.
    ///
    /// A depth map describes at each pixel the distance to an object, in meters.
    ///
    /// A disparity map describes normalized shift values for use in comparing two images. The value for each pixel in the map is in units of 1/meters: (`pixelShift / (pixelFocalLength * baselineInMeters)`).
    ///
    /// The capture pipeline generates disparity or depth maps from camera images containing nonrectilinear data. Camera lenses have small imperfections that cause small distortions in their resultant images compared to an ideal pinhole camera model, so [`AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata) maps contain nonrectilinear (nondistortion-corrected) data as well. The maps’ values are warped to match the lens distortion characteristics present in the YUV image pixel buffers captured at the same time.
    ///
    /// Because a depth data map is nonrectilinear, you can use an [`AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata) map as a proxy for depth when rendering effects to its accompanying image, but not to correlate points in 3D space. To use depth data for computer vision tasks, use the data in the [`cameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avdepthdata/cameracalibrationdata) property to rectify the depth data.
    ///
    /// There are two ways to capture depth data:
    ///
    /// - The [`AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput) class captures and delivers depth data in a stream (similar to how the [`AVCaptureVideoDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturevideodataoutput) delivers video data).
    ///
    /// - The [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) class delivers depth data as a property of an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object containing the captured image.
    ///
    /// You can also create [`AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata) objects using information obtained from image files with the [`Image I/O`](https://developer.apple.com/documentation/imageio) framework.
    ///
    /// When editing images containing depth information, use the methods listed in Transforming and Processing to generate derivative [`AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata) objects reflecting the edits that have been performed.
    ///
    ///
    /// An object wrapping a map of disparity or depth pixel data, plus metadata.
    ///
    ///
    /// "Depth Data" is a generic term for a map of pixel data containing depth-related information. AVDepthData wraps a disparity or depth map and provides conversion methods, focus information, and camera calibration data to aid in using the map for rendering or computer vision tasks. CoreVideo supports the following four depth data pixel formats:
    /// kCVPixelFormatType_DisparityFloat16    = 'hdis'
    /// kCVPixelFormatType_DisparityFloat32    = 'fdis'
    /// kCVPixelFormatType_DepthFloat16        = 'hdep'
    /// kCVPixelFormatType_DepthFloat32        = 'fdep'
    ///
    /// The disparity formats describe normalized shift values when comparing two images. Units are 1/meters: ( pixelShift / (pixelFocalLength * baselineInMeters) ).
    /// The depth formats describe the distance to an object in meters.
    ///
    /// Disparity / depth maps are generated from camera images containing non-rectilinear data. Camera lenses have small imperfections that cause small distortions in their resultant images compared to a pinhole camera. AVDepthData maps contain non-rectilinear (non-distortion-corrected) data as well. Their values are warped to match the lens distortion characteristics present in their accompanying YUV image. Therefore an AVDepthData map can be used as a proxy for depth when rendering effects to its accompanying image, but not to correlate points in 3D space. In order to use AVDepthData for computer vision tasks, you should use its accompanying camera calibration data to rectify the depth data (see AVCameraCalibrationData).
    ///
    /// When capturing depth data from a camera using AVCaptureDepthDataOutput, AVDepthData objects are delivered to your AVCaptureDepthDataOutputDelegate in a streaming fashion. When capturing depth data along with photos using AVCapturePhotoOutput, depth data is delivered to your AVCapturePhotoCaptureDelegate as a property of an AVCapturePhoto (see -[AVCapturePhotoCaptureDelegate captureOutput:didFinishProcessingPhoto:error:]). When working with image files containing depth information, AVDepthData may be instantiated using information obtained from ImageIO. When editing images containing depth information, derivative AVDepthData objects may be instantiated reflecting the edits that have been performed.
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVDepthData;
);

extern_conformance!(
    unsafe impl NSObjectProtocol for AVDepthData {}
);

impl AVDepthData {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;

        /// Returns an AVDepthData instance from depth information in an image file.
        ///
        ///
        /// Parameter `imageSourceAuxDataInfoDictionary`: A dictionary of primitive depth-related information obtained from CGImageSourceCopyAuxiliaryDataInfoAtIndex.
        ///
        /// Parameter `outError`: On return, if the depth data cannot be created, points to an NSError describing the problem.
        ///
        /// Returns: An AVDepthData instance, or nil if the auxiliary data info dictionary was malformed.
        ///
        ///
        /// When using ImageIO framework's CGImageSource API to read from a HEIF or JPEG file containing depth data, AVDepthData can be instantiated using the result of CGImageSourceCopyAuxiliaryDataInfoAtIndex, which returns a CFDictionary of primitive map information.
        ///
        /// # Safety
        ///
        /// `image_source_aux_data_info_dictionary` generic should be of the correct type.
        #[unsafe(method(depthDataFromDictionaryRepresentation:error:_))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataFromDictionaryRepresentation_error(
            image_source_aux_data_info_dictionary: &NSDictionary,
        ) -> Result<Retained<Self>, Retained<NSError>>;

        /// Returns a converted, derivative AVDepthData instance in the specified depthDataType.
        ///
        ///
        /// Parameter `depthDataType`: The OSType of depthData object to which you'd like to convert. Must be present in availableDepthDataTypes.
        ///
        /// Returns: An AVDepthData instance.
        ///
        ///
        /// This method throws an NSInvalidArgumentException if you pass an unrecognized depthDataType. See
        #[unsafe(method(depthDataByConvertingToDepthDataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataByConvertingToDepthDataType(
            &self,
            depth_data_type: OSType,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-image-io")]
        /// Returns a derivative AVDepthData instance in which the specified Exif orientation has been applied.
        ///
        ///
        /// Parameter `exifOrientation`: One of the 8 standard Exif orientation tags expressing how the depth data should be rotated / mirrored.
        ///
        /// Returns: An AVDepthData instance.
        ///
        ///
        /// When applying simple 90 degree rotation or mirroring edits to media containing depth data, you may use this initializer to create a derivative copy of the depth in which the specified orientation is applied to both the underlying pixel map data and the camera calibration data. This method throws an NSInvalidArgumentException if you pass an unrecognized exifOrientation.
        #[unsafe(method(depthDataByApplyingExifOrientation:))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataByApplyingExifOrientation(
            &self,
            exif_orientation: CGImagePropertyOrientation,
        ) -> Retained<Self>;

        #[cfg(feature = "objc2-core-video")]
        /// Returns an AVDepthData instance wrapping the replacement depth data map pixel buffer.
        ///
        ///
        /// Parameter `pixelBuffer`: A pixel buffer containing depth data information in one of the 4 supported disparity / depth pixel formats.
        ///
        /// Parameter `outError`: On return, if the depth data cannot be created, points to an NSError describing the problem.
        ///
        /// Returns: An AVDepthData instance, or nil if the pixel buffer is malformed.
        ///
        ///
        /// When applying complex edits to media containing depth data, you may create a derivative map with arbitrary transforms applied to it, then use this initializer to create a new AVDepthData. Note that this new depth data object has no camera calibration data, so its cameraCalibrationData property always returns nil.
        #[unsafe(method(depthDataByReplacingDepthDataMapWithPixelBuffer:error:_))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataByReplacingDepthDataMapWithPixelBuffer_error(
            &self,
            pixel_buffer: &CVPixelBuffer,
        ) -> Result<Retained<Self>, Retained<NSError>>;

        /// Specifies which depth data pixel formats may be used with depthDataByConvertingToDepthDataType:.
        ///
        ///
        /// This property presents the available pixel format types as an array of NSNumbers, each wrapping an OSType (CV pixel format type).
        #[unsafe(method(availableDepthDataTypes))]
        #[unsafe(method_family = none)]
        pub unsafe fn availableDepthDataTypes(&self) -> Retained<NSArray<NSNumber>>;

        /// Returns a dictionary of primitive map information to be used when writing an image file with depth data.
        ///
        ///
        /// Parameter `outAuxDataType`: On output, either kCGImageAuxiliaryDataTypeDisparity or kCGImageAuxiliaryDataTypeDepth, depending on the depth data's file.
        ///
        /// Returns: A dictionary of CGImageDestination compatible depth information, or nil if the auxDataType is unsupported.
        ///
        ///
        /// When using ImageIO framework's CGImageDestination API to write depth data to a HEIF or JPEG file, you may use this method to generate a dictionary of primitive map information consumed by CGImageDestinationAddAuxiliaryDataInfo.
        #[unsafe(method(dictionaryRepresentationForAuxiliaryDataType:))]
        #[unsafe(method_family = none)]
        pub unsafe fn dictionaryRepresentationForAuxiliaryDataType(
            &self,
            out_aux_data_type: Option<&mut Option<Retained<NSString>>>,
        ) -> Option<Retained<NSDictionary>>;

        /// Specifies the pixel format type of this depth data object's internal map.
        ///
        ///
        /// One of kCVPixelFormatType_DisparityFloat16, kCVPixelFormatType_DisparityFloat32, kCVPixelFormatType_DepthFloat16, or kCVPixelFormatType_DepthFloat32.
        #[unsafe(method(depthDataType))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataType(&self) -> OSType;

        #[cfg(feature = "objc2-core-video")]
        /// Provides access to the depth data object's internal map.
        ///
        ///
        /// The depth data map's pixel format can be queried using the depthDataType property.
        #[unsafe(method(depthDataMap))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataMap(&self) -> Retained<CVPixelBuffer>;

        /// Specifies the overall quality of the depth data map's values.
        ///
        ///
        /// See AVDepthDataQuality documentation for more information.
        #[unsafe(method(depthDataQuality))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataQuality(&self) -> AVDepthDataQuality;

        /// Specifies whether the depth data pixel buffer map contains filtered (hole-filled) data.
        ///
        ///
        /// By setting either AVCaptureDepthDataOutput's filteringEnabled property or AVCapturePhotoSettings' depthDataFiltered property to YES, the resulting depth data are filtered to remove invalid pixel values that may be present due to a variety of factors including low light and lens occlusion. If you've requested depth data filtering, all depth data holes are filled. Note that filtering the depth data makes it more usable for applying effects, but alters the data such that it may no longer be suitable for computer vision tasks. Unfiltered depth maps present missing data as NaN.
        #[unsafe(method(isDepthDataFiltered))]
        #[unsafe(method_family = none)]
        pub unsafe fn isDepthDataFiltered(&self) -> bool;

        /// Specifies the accuracy of the units in the depth data map's values.
        ///
        ///
        /// See AVDepthDataAccuracy documentation for more information.
        #[unsafe(method(depthDataAccuracy))]
        #[unsafe(method_family = none)]
        pub unsafe fn depthDataAccuracy(&self) -> AVDepthDataAccuracy;

        #[cfg(feature = "AVCameraCalibrationData")]
        /// The calibration data of the camera with which AVDepthData map's values are aligned.
        ///
        ///
        /// See AVCameraCalibrationData for more information. This property may return nil if no camera calibration data is available for the depth data.
        #[unsafe(method(cameraCalibrationData))]
        #[unsafe(method_family = none)]
        pub unsafe fn cameraCalibrationData(&self) -> Option<Retained<AVCameraCalibrationData>>;
    );
}
