//! This file has been automatically generated by `objc2`'s `header-translator`.
//! DO NOT EDIT
use core::ffi::*;
use core::ptr::NonNull;
use objc2::__framework_prelude::*;
#[cfg(feature = "objc2-core-foundation")]
use objc2_core_foundation::*;
#[cfg(feature = "objc2-core-image")]
#[cfg(not(target_os = "watchos"))]
use objc2_core_image::*;
#[cfg(feature = "objc2-core-media")]
use objc2_core_media::*;
#[cfg(feature = "objc2-core-video")]
use objc2_core_video::*;
use objc2_foundation::*;

use crate::*;

/// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avpixelaspectratio?language=objc)
#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct AVPixelAspectRatio {
    pub horizontalSpacing: NSInteger,
    pub verticalSpacing: NSInteger,
}

unsafe impl Encode for AVPixelAspectRatio {
    const ENCODING: Encoding =
        Encoding::Struct("?", &[<NSInteger>::ENCODING, <NSInteger>::ENCODING]);
}

unsafe impl RefEncode for AVPixelAspectRatio {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

/// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avedgewidths?language=objc)
#[cfg(feature = "objc2-core-foundation")]
#[repr(C)]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct AVEdgeWidths {
    pub left: CGFloat,
    pub top: CGFloat,
    pub right: CGFloat,
    pub bottom: CGFloat,
}

#[cfg(feature = "objc2-core-foundation")]
unsafe impl Encode for AVEdgeWidths {
    const ENCODING: Encoding = Encoding::Struct(
        "?",
        &[
            <CGFloat>::ENCODING,
            <CGFloat>::ENCODING,
            <CGFloat>::ENCODING,
            <CGFloat>::ENCODING,
        ],
    );
}

#[cfg(feature = "objc2-core-foundation")]
unsafe impl RefEncode for AVEdgeWidths {
    const ENCODING_REF: Encoding = Encoding::Pointer(&Self::ENCODING);
}

extern_class!(
    /// The context in which custom compositors render pixel buffers.
    ///
    /// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionrendercontext?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionRenderContext;
);

unsafe impl Send for AVVideoCompositionRenderContext {}

unsafe impl Sync for AVVideoCompositionRenderContext {}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoCompositionRenderContext {}
);

impl AVVideoCompositionRenderContext {
    extern_methods!(
        #[cfg(feature = "objc2-core-foundation")]
        #[unsafe(method(size))]
        #[unsafe(method_family = none)]
        pub unsafe fn size(&self) -> CGSize;

        #[cfg(feature = "objc2-core-foundation")]
        #[unsafe(method(renderTransform))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderTransform(&self) -> CGAffineTransform;

        #[unsafe(method(renderScale))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderScale(&self) -> c_float;

        #[unsafe(method(pixelAspectRatio))]
        #[unsafe(method_family = none)]
        pub unsafe fn pixelAspectRatio(&self) -> AVPixelAspectRatio;

        #[cfg(feature = "objc2-core-foundation")]
        #[unsafe(method(edgeWidths))]
        #[unsafe(method_family = none)]
        pub unsafe fn edgeWidths(&self) -> AVEdgeWidths;

        #[unsafe(method(highQualityRendering))]
        #[unsafe(method_family = none)]
        pub unsafe fn highQualityRendering(&self) -> bool;

        #[cfg(feature = "AVVideoComposition")]
        #[unsafe(method(videoComposition))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoComposition(&self) -> Retained<AVVideoComposition>;

        #[cfg(feature = "objc2-core-video")]
        /// Vends a CVPixelBuffer to use for rendering
        ///
        /// The buffer will have its kCVImageBufferCleanApertureKey and kCVImageBufferPixelAspectRatioKey attachments set to match the current composition processor properties.
        #[unsafe(method(newPixelBuffer))]
        #[unsafe(method_family = new)]
        pub unsafe fn newPixelBuffer(&self) -> Option<Retained<CVPixelBuffer>>;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoCompositionRenderContext {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositionrenderhint?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVVideoCompositionRenderHint;
);

unsafe impl Send for AVVideoCompositionRenderHint {}

unsafe impl Sync for AVVideoCompositionRenderHint {}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVVideoCompositionRenderHint {}
);

impl AVVideoCompositionRenderHint {
    extern_methods!(
        #[cfg(feature = "objc2-core-media")]
        /// The start time of the upcoming composition requests.
        #[unsafe(method(startCompositionTime))]
        #[unsafe(method_family = none)]
        pub unsafe fn startCompositionTime(&self) -> CMTime;

        #[cfg(feature = "objc2-core-media")]
        /// The end time of the upcoming composition requests.
        #[unsafe(method(endCompositionTime))]
        #[unsafe(method_family = none)]
        pub unsafe fn endCompositionTime(&self) -> CMTime;
    );
}

/// Methods declared on superclass `NSObject`.
impl AVVideoCompositionRenderHint {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_protocol!(
    /// Defines properties and methods for custom video compositors
    ///
    /// For each AVFoundation object of class AVPlayerItem, AVAssetExportSession, AVAssetImageGenerator, or AVAssetReaderVideoCompositionOutput that has a non-nil value for its videoComposition property, when the value of the customVideoCompositorClass property of the AVVideoComposition is not Nil, AVFoundation creates and uses an instance of that custom video compositor class to process the instructions contained in the AVVideoComposition. The custom video compositor instance will be created when you invoke -setVideoComposition: with an instance of AVVideoComposition that's associated with a different custom video compositor class than the object was previously using.
    ///
    /// When creating instances of custom video compositors, AVFoundation initializes them by calling -init and then makes them available to you for further set-up or communication, if any is needed, as the value of the customVideoCompositor property of the object on which -setVideoComposition: was invoked.
    ///
    /// Custom video compositor instances will then be retained by the AVFoundation object for as long as the value of its videoComposition property indicates that an instance of the same custom video compositor class should be used, even if the value is changed from one instance of AVVideoComposition to another instance that's associated with the same custom video compositor class.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositing?language=objc)
    pub unsafe trait AVVideoCompositing: NSObjectProtocol {
        #[unsafe(method(sourcePixelBufferAttributes))]
        #[unsafe(method_family = none)]
        unsafe fn sourcePixelBufferAttributes(
            &self,
        ) -> Option<Retained<NSDictionary<NSString, AnyObject>>>;

        #[unsafe(method(requiredPixelBufferAttributesForRenderContext))]
        #[unsafe(method_family = none)]
        unsafe fn requiredPixelBufferAttributesForRenderContext(
            &self,
        ) -> Retained<NSDictionary<NSString, AnyObject>>;

        /// Called to notify the custom compositor that a composition will switch to a different render context
        ///
        /// Parameter `newRenderContext`: The render context that will be handling the video composition from this point
        ///
        /// Instances of classes implementing the AVVideoComposting protocol can implement this method to be notified when
        /// the AVVideoCompositionRenderContext instance handing a video composition changes. AVVideoCompositionRenderContext instances
        /// being immutable, such a change will occur every time there is a change in the video composition parameters.
        #[unsafe(method(renderContextChanged:))]
        #[unsafe(method_family = none)]
        unsafe fn renderContextChanged(&self, new_render_context: &AVVideoCompositionRenderContext);

        /// Directs a custom video compositor object to create a new pixel buffer composed asynchronously from a collection of sources.
        ///
        /// Parameter `asyncVideoCompositionRequest`: An instance of AVAsynchronousVideoCompositionRequest that provides context for the requested composition.
        ///
        /// The custom compositor is expected to invoke, either subsequently or immediately, either:
        /// -[AVAsynchronousVideoCompositionRequest finishWithComposedVideoFrame:] or
        /// -[AVAsynchronousVideoCompositionRequest finishWithError:]. If you intend to finish rendering the frame after your
        /// handling of this message returns, you must retain the instance of AVAsynchronousVideoCompositionRequest until after composition is finished.
        /// Note that if the custom compositor's implementation of -startVideoCompositionRequest: returns without finishing the composition immediately,
        /// it may be invoked again with another composition request before the prior request is finished; therefore in such cases the custom compositor should
        /// be prepared to manage multiple composition requests.
        ///
        /// If the rendered frame is exactly the same as one of the source frames, with no letterboxing, pillboxing or cropping needed,
        /// then the appropriate source pixel buffer may be returned (after CFRetain has been called on it).
        #[unsafe(method(startVideoCompositionRequest:))]
        #[unsafe(method_family = none)]
        unsafe fn startVideoCompositionRequest(
            &self,
            async_video_composition_request: &AVAsynchronousVideoCompositionRequest,
        );

        /// Directs a custom video compositor object to cancel or finish all pending video composition requests
        ///
        /// When receiving this message, a custom video compositor must block until it has either cancelled all pending frame requests,
        /// and called the finishCancelledRequest callback for each of them, or, if cancellation is not possible, finished processing of all the frames
        /// and called the finishWithComposedVideoFrame: callback for each of them.
        #[optional]
        #[unsafe(method(cancelAllPendingVideoCompositionRequests))]
        #[unsafe(method_family = none)]
        unsafe fn cancelAllPendingVideoCompositionRequests(&self);

        /// Indicates that clients can handle frames that contains wide color properties.
        ///
        ///
        /// Controls whether the client will receive frames that contain wide color information. Care should be taken to avoid clamping.
        #[optional]
        #[unsafe(method(supportsWideColorSourceFrames))]
        #[unsafe(method_family = none)]
        unsafe fn supportsWideColorSourceFrames(&self) -> bool;

        /// Indicates that the client's video compositor can handle frames that contain high dynamic range (HDR) properties.
        ///
        ///
        /// Controls whether the client will receive frames that contain HDR information.
        /// If this field is omitted or set to NO, the framework will convert HDR frames to standard dynamic range (SDR) with BT.709 transfer function before sending to the client.
        /// If this field is set to YES, the value of supportsWideColorSourceFrames will be ignored and assumed to be YES.
        #[optional]
        #[unsafe(method(supportsHDRSourceFrames))]
        #[unsafe(method_family = none)]
        unsafe fn supportsHDRSourceFrames(&self) -> bool;

        #[optional]
        #[unsafe(method(canConformColorOfSourceFrames))]
        #[unsafe(method_family = none)]
        unsafe fn canConformColorOfSourceFrames(&self) -> bool;

        /// Informs a custom video compositor about upcoming rendering requests.
        ///
        /// Parameter `renderHint`: Information about the upcoming composition requests.
        ///
        /// In the method the compositor can load composition resources such as overlay images which will be needed in the anticipated rendering time range.
        ///
        /// Unlike -startVideoCompositionRequest, which is invoked only when the frame compositing is necessary, the framework typically calls this method every frame duration. It allows the custom compositor to load and unload a composition resource such as overlay images at an appropriate timing.
        ///
        /// In forward playback, renderHint's startCompositionTime is less than endCompositionTime. In reverse playback, its endCompositionTime is less than startCompositionTime. For seeking, startCompositionTime == endCompositionTime, which means the upcoming composition request time range is unknown and the compositor shouldnâ€™t preload time associated composition resources eagerly.
        ///
        /// The method is guaranteed to be called before -startVideoCompositionRequest: for a given composition time.
        ///
        /// The method is synchronous. The implementation should return quickly because otherwise the playback would stall and cause frame drops.
        #[optional]
        #[unsafe(method(anticipateRenderingUsingHint:))]
        #[unsafe(method_family = none)]
        unsafe fn anticipateRenderingUsingHint(&self, render_hint: &AVVideoCompositionRenderHint);

        /// Tell a custom video compositor to perform any work in prerolling phase.
        ///
        /// Parameter `renderHint`: Information about the upcoming composition requests.
        ///
        /// The framework may perform prerolling to load media data to prime the render pipelines for smoother playback. This method is called in the prerolling phase so that the compositor can load composition resources such as overlay images which will be needed as soon as the playback starts.
        ///
        /// Not all rendering scenarios use prerolling. For example, the method won't be called while seeking.
        ///
        /// If called, the method is guaranteed to be invoked before the first -startVideoCompositionRequest: call.
        ///
        /// The method is synchronous. The prerolling won't finish until the method returns.
        #[optional]
        #[unsafe(method(prerollForRenderingUsingHint:))]
        #[unsafe(method_family = none)]
        unsafe fn prerollForRenderingUsingHint(&self, render_hint: &AVVideoCompositionRenderHint);
    }
);

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avasynchronousvideocompositionrequest?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAsynchronousVideoCompositionRequest;
);

extern_conformance!(
    unsafe impl NSCopying for AVAsynchronousVideoCompositionRequest {}
);

unsafe impl CopyingHelper for AVAsynchronousVideoCompositionRequest {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAsynchronousVideoCompositionRequest {}
);

impl AVAsynchronousVideoCompositionRequest {
    extern_methods!(
        #[unsafe(method(renderContext))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderContext(&self) -> Retained<AVVideoCompositionRenderContext>;

        #[cfg(feature = "objc2-core-media")]
        #[unsafe(method(compositionTime))]
        #[unsafe(method_family = none)]
        pub unsafe fn compositionTime(&self) -> CMTime;

        #[unsafe(method(sourceTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        #[unsafe(method(sourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;

        #[unsafe(method(videoCompositionInstruction))]
        #[unsafe(method_family = none)]
        pub unsafe fn videoCompositionInstruction(
            &self,
        ) -> Retained<ProtocolObject<dyn AVVideoCompositionInstructionProtocol>>;

        #[cfg(all(feature = "objc2-core-media", feature = "objc2-core-video"))]
        /// Returns the source CVPixelBufferRef for the given track ID
        ///
        /// Parameter `trackID`: The track ID for the requested source frame
        #[unsafe(method(sourceFrameByTrackID:))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceFrameByTrackID(
            &self,
            track_id: CMPersistentTrackID,
        ) -> Option<Retained<CVPixelBuffer>>;

        #[cfg(feature = "objc2-core-media")]
        /// Returns the source CMSampleBufferRef for the given track ID
        ///
        /// Parameter `trackID`: The track ID for the requested source sample buffer
        #[unsafe(method(sourceSampleBufferByTrackID:))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceSampleBufferByTrackID(
            &self,
            track_id: CMPersistentTrackID,
        ) -> Option<Retained<CMSampleBuffer>>;

        #[cfg(all(feature = "AVTimedMetadataGroup", feature = "objc2-core-media"))]
        /// Returns the source AVTimedMetadataGroup * for the given track ID
        ///
        /// Parameter `trackID`: The track ID for the requested source timed metadata group.
        #[unsafe(method(sourceTimedMetadataByTrackID:))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceTimedMetadataByTrackID(
            &self,
            track_id: CMPersistentTrackID,
        ) -> Option<Retained<AVTimedMetadataGroup>>;

        #[cfg(feature = "objc2-core-video")]
        /// The method that the custom compositor calls when composition succeeds.
        ///
        /// Parameter `composedVideoFrame`: The video frame to finish with.
        #[unsafe(method(finishWithComposedVideoFrame:))]
        #[unsafe(method_family = none)]
        pub unsafe fn finishWithComposedVideoFrame(&self, composed_video_frame: &CVPixelBuffer);

        #[unsafe(method(finishWithError:))]
        #[unsafe(method_family = none)]
        pub unsafe fn finishWithError(&self, error: &NSError);

        #[unsafe(method(finishCancelledRequest))]
        #[unsafe(method_family = none)]
        pub unsafe fn finishCancelledRequest(&self);
    );
}

/// Methods declared on superclass `NSObject`.
impl AVAsynchronousVideoCompositionRequest {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_class!(
    /// [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avasynchronousciimagefilteringrequest?language=objc)
    #[unsafe(super(NSObject))]
    #[derive(Debug, PartialEq, Eq, Hash)]
    pub struct AVAsynchronousCIImageFilteringRequest;
);

extern_conformance!(
    unsafe impl NSCopying for AVAsynchronousCIImageFilteringRequest {}
);

unsafe impl CopyingHelper for AVAsynchronousCIImageFilteringRequest {
    type Result = Self;
}

extern_conformance!(
    unsafe impl NSObjectProtocol for AVAsynchronousCIImageFilteringRequest {}
);

impl AVAsynchronousCIImageFilteringRequest {
    extern_methods!(
        #[cfg(feature = "objc2-core-foundation")]
        #[unsafe(method(renderSize))]
        #[unsafe(method_family = none)]
        pub unsafe fn renderSize(&self) -> CGSize;

        #[cfg(feature = "objc2-core-media")]
        #[unsafe(method(compositionTime))]
        #[unsafe(method_family = none)]
        pub unsafe fn compositionTime(&self) -> CMTime;

        #[cfg(feature = "objc2-core-image")]
        #[cfg(not(target_os = "watchos"))]
        #[unsafe(method(sourceImage))]
        #[unsafe(method_family = none)]
        pub unsafe fn sourceImage(&self) -> Retained<CIImage>;

        #[cfg(feature = "objc2-core-image")]
        #[cfg(not(target_os = "watchos"))]
        #[unsafe(method(finishWithImage:context:))]
        #[unsafe(method_family = none)]
        pub unsafe fn finishWithImage_context(
            &self,
            filtered_image: &CIImage,
            context: Option<&CIContext>,
        );

        #[unsafe(method(finishWithError:))]
        #[unsafe(method_family = none)]
        pub unsafe fn finishWithError(&self, error: &NSError);
    );
}

/// Methods declared on superclass `NSObject`.
impl AVAsynchronousCIImageFilteringRequest {
    extern_methods!(
        #[unsafe(method(init))]
        #[unsafe(method_family = init)]
        pub unsafe fn init(this: Allocated<Self>) -> Retained<Self>;

        #[unsafe(method(new))]
        #[unsafe(method_family = new)]
        pub unsafe fn new() -> Retained<Self>;
    );
}

extern_protocol!(
    /// The AVVideoCompositionInstruction protocol is implemented by objects to represent operations to be performed by a compositor.
    ///
    /// See also [Apple's documentation](https://developer.apple.com/documentation/avfoundation/avvideocompositioninstructionprotocol?language=objc)
    #[name = "AVVideoCompositionInstruction"]
    pub unsafe trait AVVideoCompositionInstructionProtocol: NSObjectProtocol {
        #[cfg(feature = "objc2-core-media")]
        #[unsafe(method(timeRange))]
        #[unsafe(method_family = none)]
        unsafe fn timeRange(&self) -> CMTimeRange;

        #[unsafe(method(enablePostProcessing))]
        #[unsafe(method_family = none)]
        unsafe fn enablePostProcessing(&self) -> bool;

        #[unsafe(method(containsTweening))]
        #[unsafe(method_family = none)]
        unsafe fn containsTweening(&self) -> bool;

        #[unsafe(method(requiredSourceTrackIDs))]
        #[unsafe(method_family = none)]
        unsafe fn requiredSourceTrackIDs(&self) -> Option<Retained<NSArray<NSValue>>>;

        #[cfg(feature = "objc2-core-media")]
        #[unsafe(method(passthroughTrackID))]
        #[unsafe(method_family = none)]
        unsafe fn passthroughTrackID(&self) -> CMPersistentTrackID;

        #[optional]
        #[unsafe(method(requiredSourceSampleDataTrackIDs))]
        #[unsafe(method_family = none)]
        unsafe fn requiredSourceSampleDataTrackIDs(&self) -> Retained<NSArray<NSNumber>>;
    }
);
